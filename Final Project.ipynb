{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe75a97",
   "metadata": {},
   "source": [
    "## Steam Game Recommended Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb8d017",
   "metadata": {},
   "source": [
    "**CSC 180 Intelligent Systems (Fall 2021)**<br>\n",
    "**Dr.Haiquan Chen, Dept of Computer Science**<br>\n",
    "**California State University, Sacramento**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b1e9ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Christopher Sin (Student ID: 220039041)\n",
    "# Inigo Jaque     (Student ID: 219976420)\n",
    "# Final Project\n",
    "# CSC 180-01 Intelligent Systems Computer Science\n",
    "# November 28, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86042b30",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c703706",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import random\n",
    "\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D, Flatten, Conv1D, MaxPool1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from collections.abc import Sequence\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc41eb6",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0218b8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>language</th>\n",
       "      <th>review</th>\n",
       "      <th>recommended</th>\n",
       "      <th>votes_helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>292030</td>\n",
       "      <td>The Witcher 3: Wild Hunt</td>\n",
       "      <td>brazilian</td>\n",
       "      <td>ta bom\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292030</td>\n",
       "      <td>The Witcher 3: Wild Hunt</td>\n",
       "      <td>english</td>\n",
       "      <td>.</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>292030</td>\n",
       "      <td>The Witcher 3: Wild Hunt</td>\n",
       "      <td>brazilian</td>\n",
       "      <td>Jogo muito divertido, uma vez q começa, não da...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>292030</td>\n",
       "      <td>The Witcher 3: Wild Hunt</td>\n",
       "      <td>polish</td>\n",
       "      <td>Sztos gierka. Gorąco polecam &lt;3</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>292030</td>\n",
       "      <td>The Witcher 3: Wild Hunt</td>\n",
       "      <td>schinese</td>\n",
       "      <td>好玩！</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>517630</td>\n",
       "      <td>Just Cause 4</td>\n",
       "      <td>english</td>\n",
       "      <td>Its not a great game I'm afraid. The constant ...</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>517630</td>\n",
       "      <td>Just Cause 4</td>\n",
       "      <td>french</td>\n",
       "      <td>ne pas acheter temps qu'il n'y a pas de correc...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>517630</td>\n",
       "      <td>Just Cause 4</td>\n",
       "      <td>english</td>\n",
       "      <td>2/10 the original half life looks and function...</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>517630</td>\n",
       "      <td>Just Cause 4</td>\n",
       "      <td>english</td>\n",
       "      <td>After futher review, this game is boring and h...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>517630</td>\n",
       "      <td>Just Cause 4</td>\n",
       "      <td>english</td>\n",
       "      <td>Was really hoping for this to be good...\\n\\nI ...</td>\n",
       "      <td>False</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      app_id                  app_name   language  \\\n",
       "0     292030  The Witcher 3: Wild Hunt  brazilian   \n",
       "1     292030  The Witcher 3: Wild Hunt    english   \n",
       "2     292030  The Witcher 3: Wild Hunt  brazilian   \n",
       "3     292030  The Witcher 3: Wild Hunt     polish   \n",
       "4     292030  The Witcher 3: Wild Hunt   schinese   \n",
       "...      ...                       ...        ...   \n",
       "4995  517630              Just Cause 4    english   \n",
       "4996  517630              Just Cause 4     french   \n",
       "4997  517630              Just Cause 4    english   \n",
       "4998  517630              Just Cause 4    english   \n",
       "4999  517630              Just Cause 4    english   \n",
       "\n",
       "                                                 review  recommended  \\\n",
       "0                                              ta bom\\n         True   \n",
       "1                                                     .         True   \n",
       "2     Jogo muito divertido, uma vez q começa, não da...         True   \n",
       "3                       Sztos gierka. Gorąco polecam <3         True   \n",
       "4                                                   好玩！         True   \n",
       "...                                                 ...          ...   \n",
       "4995  Its not a great game I'm afraid. The constant ...        False   \n",
       "4996  ne pas acheter temps qu'il n'y a pas de correc...        False   \n",
       "4997  2/10 the original half life looks and function...        False   \n",
       "4998  After futher review, this game is boring and h...        False   \n",
       "4999  Was really hoping for this to be good...\\n\\nI ...        False   \n",
       "\n",
       "      votes_helpful  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 1  \n",
       "4                 0  \n",
       "...             ...  \n",
       "4995              5  \n",
       "4996              3  \n",
       "4997              6  \n",
       "4998              0  \n",
       "4999            734  \n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column names that are wanted from the CSV file\n",
    "columns = ['app_id', 'app_name', 'language', 'review', 'recommended', 'votes_helpful']\n",
    "\n",
    "#Skips every _____ rows\n",
    "n_rows = 21000000\n",
    "skip = np.arange(n_rows)\n",
    "skip = np.delete(skip, np.arange(0,n_rows, 5000))\n",
    "\n",
    "#Creates DataFrame (df) and saves every _____ row from steam_reviews.csv into it\n",
    "#Uses specific columns from the variable columns, reads only _____ rows from the csv file, skips every _____ rows\n",
    "df = pd.read_csv('steam_reviews.csv', usecols = columns, low_memory = True, nrows = 5000, skiprows = skip)\n",
    "\n",
    "#displays DataFrame df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc86189b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-7411668fe75d>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['app_id'] = df['app_id'].astype(str)\n",
      "<ipython-input-4-7411668fe75d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['review'] = df['review'].astype(str)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>language</th>\n",
       "      <th>review</th>\n",
       "      <th>recommended</th>\n",
       "      <th>votes_helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292030</td>\n",
       "      <td>The Witcher 3: Wild Hunt</td>\n",
       "      <td>english</td>\n",
       "      <td>.</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>292030</td>\n",
       "      <td>The Witcher 3: Wild Hunt</td>\n",
       "      <td>english</td>\n",
       "      <td>Is an amazin game, every detail. Yes is 2015 g...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>292030</td>\n",
       "      <td>The Witcher 3: Wild Hunt</td>\n",
       "      <td>english</td>\n",
       "      <td>Bare Bangin</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>292030</td>\n",
       "      <td>The Witcher 3: Wild Hunt</td>\n",
       "      <td>english</td>\n",
       "      <td>nice</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>292030</td>\n",
       "      <td>The Witcher 3: Wild Hunt</td>\n",
       "      <td>english</td>\n",
       "      <td>yes.</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>517630</td>\n",
       "      <td>Just Cause 4</td>\n",
       "      <td>english</td>\n",
       "      <td>Good god this game is a shit show so far.\\n\\nS...</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>517630</td>\n",
       "      <td>Just Cause 4</td>\n",
       "      <td>english</td>\n",
       "      <td>Its not a great game I'm afraid. The constant ...</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>517630</td>\n",
       "      <td>Just Cause 4</td>\n",
       "      <td>english</td>\n",
       "      <td>2/10 the original half life looks and function...</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>517630</td>\n",
       "      <td>Just Cause 4</td>\n",
       "      <td>english</td>\n",
       "      <td>After futher review, this game is boring and h...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>517630</td>\n",
       "      <td>Just Cause 4</td>\n",
       "      <td>english</td>\n",
       "      <td>Was really hoping for this to be good...\\n\\nI ...</td>\n",
       "      <td>False</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2222 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      app_id                  app_name language  \\\n",
       "1     292030  The Witcher 3: Wild Hunt  english   \n",
       "10    292030  The Witcher 3: Wild Hunt  english   \n",
       "11    292030  The Witcher 3: Wild Hunt  english   \n",
       "16    292030  The Witcher 3: Wild Hunt  english   \n",
       "20    292030  The Witcher 3: Wild Hunt  english   \n",
       "...      ...                       ...      ...   \n",
       "4993  517630              Just Cause 4  english   \n",
       "4995  517630              Just Cause 4  english   \n",
       "4997  517630              Just Cause 4  english   \n",
       "4998  517630              Just Cause 4  english   \n",
       "4999  517630              Just Cause 4  english   \n",
       "\n",
       "                                                 review  recommended  \\\n",
       "1                                                     .         True   \n",
       "10    Is an amazin game, every detail. Yes is 2015 g...         True   \n",
       "11                                          Bare Bangin         True   \n",
       "16                                                 nice         True   \n",
       "20                                                 yes.         True   \n",
       "...                                                 ...          ...   \n",
       "4993  Good god this game is a shit show so far.\\n\\nS...        False   \n",
       "4995  Its not a great game I'm afraid. The constant ...        False   \n",
       "4997  2/10 the original half life looks and function...        False   \n",
       "4998  After futher review, this game is boring and h...        False   \n",
       "4999  Was really hoping for this to be good...\\n\\nI ...        False   \n",
       "\n",
       "      votes_helpful  \n",
       "1                 0  \n",
       "10                0  \n",
       "11                0  \n",
       "16                0  \n",
       "20                0  \n",
       "...             ...  \n",
       "4993             15  \n",
       "4995              5  \n",
       "4997              6  \n",
       "4998              0  \n",
       "4999            734  \n",
       "\n",
       "[2222 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saves reviews only if they are written in English\n",
    "df = df[df['language'] == 'english']\n",
    "df['app_id'] = df['app_id'].astype(str)\n",
    "df['review'] = df['review'].astype(str)\n",
    "\n",
    "#displays DataFrame df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1179c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>review</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1017900</td>\n",
       "      <td>great game beautiful rts</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1055540</td>\n",
       "      <td>A beautiful little game. Buttery smooth contro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105600</td>\n",
       "      <td>Had hours of fun during lockdown, is a great g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056960</td>\n",
       "      <td>Not sure what happened to this game. Did the o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1057090</td>\n",
       "      <td>Not sure what to say.... can't put it into wor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>8870</td>\n",
       "      <td>Wow. This game is absolutely stunning. It dese...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>8930</td>\n",
       "      <td>best civ is best civNo off line playing. Dehhh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>899440</td>\n",
       "      <td>if you are a fan of the series definitely pick...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>945360</td>\n",
       "      <td>I don't know, Pretty fine.\\n  Quite unique i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>960090</td>\n",
       "      <td>good game for relaxing and messing around with...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      app_id                                             review  review_count\n",
       "0    1017900                           great game beautiful rts             0\n",
       "1    1055540  A beautiful little game. Buttery smooth contro...             0\n",
       "2     105600  Had hours of fun during lockdown, is a great g...             0\n",
       "3    1056960  Not sure what happened to this game. Did the o...             0\n",
       "4    1057090  Not sure what to say.... can't put it into wor...             0\n",
       "..       ...                                                ...           ...\n",
       "214     8870  Wow. This game is absolutely stunning. It dese...             0\n",
       "215     8930  best civ is best civNo off line playing. Dehhh...             0\n",
       "216   899440  if you are a fan of the series definitely pick...             0\n",
       "217   945360    I don't know, Pretty fine.\\n  Quite unique i...             0\n",
       "218   960090  good game for relaxing and messing around with...             0\n",
       "\n",
       "[219 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Groups together the app_id, review, and sets the amount of reviews per app_id = 0\n",
    "df_review_agg = df.groupby('app_id')['review'].sum()\n",
    "df_ready_for_sklearn = pd.DataFrame({'app_id': df_review_agg.index, 'review': df_review_agg.values})\n",
    "df_ready_for_sklearn['review_count'] = 0\n",
    "\n",
    "#displays DataFrame df_ready_for_sklearn\n",
    "df_ready_for_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7bb8324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-7406afe179a9>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ready_for_sklearn['review_count'][j] += 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>review</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1017900</td>\n",
       "      <td>great game beautiful rts</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1055540</td>\n",
       "      <td>A beautiful little game. Buttery smooth contro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105600</td>\n",
       "      <td>Had hours of fun during lockdown, is a great g...</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056960</td>\n",
       "      <td>Not sure what happened to this game. Did the o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1057090</td>\n",
       "      <td>Not sure what to say.... can't put it into wor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>8870</td>\n",
       "      <td>Wow. This game is absolutely stunning. It dese...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>8930</td>\n",
       "      <td>best civ is best civNo off line playing. Dehhh...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>899440</td>\n",
       "      <td>if you are a fan of the series definitely pick...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>945360</td>\n",
       "      <td>I don't know, Pretty fine.\\n  Quite unique i...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>960090</td>\n",
       "      <td>good game for relaxing and messing around with...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      app_id                                             review  review_count\n",
       "0    1017900                           great game beautiful rts             1\n",
       "1    1055540  A beautiful little game. Buttery smooth contro...             1\n",
       "2     105600  Had hours of fun during lockdown, is a great g...            74\n",
       "3    1056960  Not sure what happened to this game. Did the o...             1\n",
       "4    1057090  Not sure what to say.... can't put it into wor...             1\n",
       "..       ...                                                ...           ...\n",
       "214     8870  Wow. This game is absolutely stunning. It dese...             8\n",
       "215     8930  best civ is best civNo off line playing. Dehhh...            23\n",
       "216   899440  if you are a fan of the series definitely pick...             1\n",
       "217   945360    I don't know, Pretty fine.\\n  Quite unique i...            58\n",
       "218   960090  good game for relaxing and messing around with...            10\n",
       "\n",
       "[219 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gets the length of df and df_ready_for_sklearn\n",
    "index_df = len(df)\n",
    "index_df_sklearn = len(df_ready_for_sklearn)\n",
    "\n",
    "#Loop to count the amount of reviews per Steam Game\n",
    "for i in range(index_df):\n",
    "    for j in range(index_df_sklearn):\n",
    "        if df_ready_for_sklearn['app_id'][j] == df.iloc[i, 0]:\n",
    "            df_ready_for_sklearn['review_count'][j] += 1\n",
    "            \n",
    "#displays DataFrame df_ready_for_sklearn\n",
    "df_ready_for_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c968112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1017900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1055540</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105600</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1057090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>8870</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>8930</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>899440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>945360</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>960090</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      app_id  recommended\n",
       "0    1017900            1\n",
       "1    1055540            1\n",
       "2     105600           72\n",
       "3    1056960            0\n",
       "4    1057090            1\n",
       "..       ...          ...\n",
       "214     8870            7\n",
       "215     8930           21\n",
       "216   899440            1\n",
       "217   945360           55\n",
       "218   960090           10\n",
       "\n",
       "[219 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Groups together app_id and recommended\n",
    "df_review_agg_2 = df.groupby('app_id')['recommended'].sum()\n",
    "df_ready_for_sklearn_2 = pd.DataFrame({'app_id': df_review_agg_2.index, 'recommended': df_review_agg_2.values})\n",
    "df_ready_for_sklearn_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6737921f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great game beautiful rts\n"
     ]
    }
   ],
   "source": [
    "#Test to see if the reviews have been grouped\n",
    "print(df_ready_for_sklearn['review'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c813c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = sk_text.TfidfVectorizer(stop_words = 'english', max_features = 4000, min_df = 2, max_df = .95)\n",
    "matrix = vectorizer.fit_transform(df_ready_for_sklearn['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46d24639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 3504)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_data = matrix.toarray()\n",
    "tfidf_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5a9eca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       1\n",
      "2      74\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "214     8\n",
      "215    23\n",
      "216     1\n",
      "217    58\n",
      "218    10\n",
      "Name: review_count, Length: 219, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "review_array = df_ready_for_sklearn['review_count'].values\n",
    "review_array.shape\n",
    "print(df_ready_for_sklearn['review_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e20fb537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 3505)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertical_array = np.vstack(review_array)\n",
    "x = np.concatenate((tfidf_data, vertical_array), axis = 1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26c863c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_ready_for_sklearn_2['recommended']\n",
    "y.shape\n",
    "y.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7a7156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    b = plt.plot(t['pred'].tolist(), label='prediction')\n",
    "    a = plt.plot(t['y'].tolist(), label='expected')\n",
    "    \n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c0fae",
   "metadata": {},
   "source": [
    "## Fully Connected Convolutional Neural Network  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c183e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "(175, 3505)\n",
      "(175,)\n",
      "(44, 3505)\n",
      "(44,)\n"
     ]
    }
   ],
   "source": [
    "#Setting up x_train, x_test, y_train, y_test and training them\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 11)\n",
    "x_array_train = x_train\n",
    "x_array_test = x_test\n",
    "y_array_train = y_train\n",
    "y_array_test = y_test\n",
    "print(type(x_train))\n",
    "print(type(x_test))\n",
    "print(type(y_train))\n",
    "print(type(y_test))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389486a1",
   "metadata": {},
   "source": [
    "**Activation = Relu**<br>\n",
    "**Optimizer = Adam**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9f821f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run  1\n",
      "Activation: Relu\n",
      "Optimizer: Adam\n",
      "\n",
      "Epoch 1/1000\n",
      "6/6 - 0s - loss: 168.7997 - val_loss: 707.4981\n",
      "Epoch 2/1000\n",
      "6/6 - 0s - loss: 160.2277 - val_loss: 655.3005\n",
      "Epoch 3/1000\n",
      "6/6 - 0s - loss: 153.2955 - val_loss: 604.3624\n",
      "Epoch 4/1000\n",
      "6/6 - 0s - loss: 145.3026 - val_loss: 558.6218\n",
      "Epoch 5/1000\n",
      "6/6 - 0s - loss: 139.6094 - val_loss: 512.5157\n",
      "Epoch 6/1000\n",
      "6/6 - 0s - loss: 131.8855 - val_loss: 469.4140\n",
      "Epoch 7/1000\n",
      "6/6 - 0s - loss: 124.8750 - val_loss: 425.8884\n",
      "Epoch 8/1000\n",
      "6/6 - 0s - loss: 117.4914 - val_loss: 381.5862\n",
      "Epoch 9/1000\n",
      "6/6 - 0s - loss: 110.4285 - val_loss: 335.7054\n",
      "Epoch 10/1000\n",
      "6/6 - 0s - loss: 101.2587 - val_loss: 292.7377\n",
      "Epoch 11/1000\n",
      "6/6 - 0s - loss: 92.7404 - val_loss: 249.5338\n",
      "Epoch 12/1000\n",
      "6/6 - 0s - loss: 82.9416 - val_loss: 210.8996\n",
      "Epoch 13/1000\n",
      "6/6 - 0s - loss: 75.6446 - val_loss: 173.0468\n",
      "Epoch 14/1000\n",
      "6/6 - 0s - loss: 66.3524 - val_loss: 143.4340\n",
      "Epoch 15/1000\n",
      "6/6 - 0s - loss: 58.0080 - val_loss: 120.7993\n",
      "Epoch 16/1000\n",
      "6/6 - 0s - loss: 51.3461 - val_loss: 104.2050\n",
      "Epoch 17/1000\n",
      "6/6 - 0s - loss: 43.4094 - val_loss: 97.0481\n",
      "Epoch 18/1000\n",
      "6/6 - 0s - loss: 36.6230 - val_loss: 98.4546\n",
      "Epoch 19/1000\n",
      "6/6 - 0s - loss: 30.5250 - val_loss: 108.0895\n",
      "Epoch 20/1000\n",
      "6/6 - 0s - loss: 26.0633 - val_loss: 127.9855\n",
      "Epoch 00020: early stopping\n",
      "Score (MSE): 127.98549732846145\n",
      "Score(RMSE): 11.313067547242058\n",
      "\n",
      "Run  2\n",
      "Activation: Relu\n",
      "Optimizer: Adam\n",
      "\n",
      "Epoch 1/1000\n",
      "6/6 - 0s - loss: 180.1074 - val_loss: 786.4894\n",
      "Epoch 2/1000\n",
      "6/6 - 0s - loss: 170.4558 - val_loss: 723.4810\n",
      "Epoch 3/1000\n",
      "6/6 - 0s - loss: 161.3172 - val_loss: 655.2916\n",
      "Epoch 4/1000\n",
      "6/6 - 0s - loss: 152.5124 - val_loss: 600.3045\n",
      "Epoch 5/1000\n",
      "6/6 - 0s - loss: 146.2710 - val_loss: 545.2021\n",
      "Epoch 6/1000\n",
      "6/6 - 0s - loss: 140.5202 - val_loss: 507.6519\n",
      "Epoch 7/1000\n",
      "6/6 - 0s - loss: 133.6737 - val_loss: 469.2489\n",
      "Epoch 8/1000\n",
      "6/6 - 0s - loss: 126.1052 - val_loss: 427.9081\n",
      "Epoch 9/1000\n",
      "6/6 - 0s - loss: 118.6283 - val_loss: 374.5704\n",
      "Epoch 10/1000\n",
      "6/6 - 0s - loss: 106.2823 - val_loss: 308.9744\n",
      "Epoch 11/1000\n",
      "6/6 - 0s - loss: 92.8548 - val_loss: 244.1828\n",
      "Epoch 12/1000\n",
      "6/6 - 0s - loss: 82.7754 - val_loss: 187.4981\n",
      "Epoch 13/1000\n",
      "6/6 - 0s - loss: 69.2389 - val_loss: 147.4308\n",
      "Epoch 14/1000\n",
      "6/6 - 0s - loss: 59.9029 - val_loss: 116.8290\n",
      "Epoch 15/1000\n",
      "6/6 - 0s - loss: 48.6822 - val_loss: 100.8703\n",
      "Epoch 16/1000\n",
      "6/6 - 0s - loss: 40.5085 - val_loss: 97.1283\n",
      "Epoch 17/1000\n",
      "6/6 - 0s - loss: 33.0327 - val_loss: 106.6537\n",
      "Epoch 18/1000\n",
      "6/6 - 0s - loss: 27.2019 - val_loss: 129.5271\n",
      "Epoch 19/1000\n",
      "6/6 - 0s - loss: 20.6023 - val_loss: 159.3812\n",
      "Epoch 00019: early stopping\n",
      "Score (MSE): 159.38117226869988\n",
      "Score(RMSE): 12.624625628853313\n",
      "\n",
      "Run  3\n",
      "Activation: Relu\n",
      "Optimizer: Adam\n",
      "\n",
      "Epoch 1/1000\n",
      "6/6 - 0s - loss: 161.6097 - val_loss: 645.5128\n",
      "Epoch 2/1000\n",
      "6/6 - 0s - loss: 153.3999 - val_loss: 592.1848\n",
      "Epoch 3/1000\n",
      "6/6 - 0s - loss: 145.3348 - val_loss: 541.3518\n",
      "Epoch 4/1000\n",
      "6/6 - 0s - loss: 136.5937 - val_loss: 480.8201\n",
      "Epoch 5/1000\n",
      "6/6 - 0s - loss: 125.0127 - val_loss: 420.1334\n",
      "Epoch 6/1000\n",
      "6/6 - 0s - loss: 118.0107 - val_loss: 361.2160\n",
      "Epoch 7/1000\n",
      "6/6 - 0s - loss: 106.5427 - val_loss: 304.5236\n",
      "Epoch 8/1000\n",
      "6/6 - 0s - loss: 93.7636 - val_loss: 246.1200\n",
      "Epoch 9/1000\n",
      "6/6 - 0s - loss: 81.6720 - val_loss: 184.5155\n",
      "Epoch 10/1000\n",
      "6/6 - 0s - loss: 67.4566 - val_loss: 136.5006\n",
      "Epoch 11/1000\n",
      "6/6 - 0s - loss: 54.6061 - val_loss: 105.8918\n",
      "Epoch 12/1000\n",
      "6/6 - 0s - loss: 42.3664 - val_loss: 95.6797\n",
      "Epoch 13/1000\n",
      "6/6 - 0s - loss: 31.8454 - val_loss: 107.4388\n",
      "Epoch 14/1000\n",
      "6/6 - 0s - loss: 25.6516 - val_loss: 143.5134\n",
      "Epoch 15/1000\n",
      "6/6 - 0s - loss: 18.6624 - val_loss: 193.9070\n",
      "Epoch 00015: early stopping\n",
      "Score (MSE): 193.9070273135272\n",
      "Score(RMSE): 13.92505035227978\n"
     ]
    }
   ],
   "source": [
    "#Fully Connected Neural Network?\n",
    "for i in range (3):\n",
    "    print(\"\\nRun \", i+1)\n",
    "    print(\"Activation: Relu\")\n",
    "    print(\"Optimizer: Adam\\n\")\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(25, input_dim = x.shape[1], activation = 'relu'))\n",
    "    model.add(Dense(10, activation = 'relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "    monitor = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 3, verbose = 1, mode = 'auto')\n",
    "    model.fit(x_array_train, y_array_train, validation_data = (x_array_test, y_array_test), callbacks = [monitor], verbose = 2, epochs = 1000)\n",
    "\n",
    "    pred = model.predict(x_test)\n",
    "    score_mse = metrics.mean_squared_error(pred, y_test)\n",
    "    print(\"Score (MSE): {}\".format(score_mse))\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    score_rmse = np.sqrt(metrics.mean_squared_error(pred, y_test))\n",
    "    print(\"Score(RMSE): {}\".format(score_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "634169f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chart_regression(pred.flatten(), y_test, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b89ad96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>recommended</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>2.607911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>1.623165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>5.031623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>217</td>\n",
       "      <td>55</td>\n",
       "      <td>34.797199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>6.023920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>4.834821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>144</td>\n",
       "      <td>2</td>\n",
       "      <td>4.053123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>141</td>\n",
       "      <td>3</td>\n",
       "      <td>3.519709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>151</td>\n",
       "      <td>17</td>\n",
       "      <td>15.735341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>213</td>\n",
       "      <td>3</td>\n",
       "      <td>4.471392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>5.152316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>2.902127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>1.817364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>2.258358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>170</td>\n",
       "      <td>4</td>\n",
       "      <td>5.130611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>4.472449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>6.221038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94</td>\n",
       "      <td>10</td>\n",
       "      <td>9.527883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>149</td>\n",
       "      <td>36</td>\n",
       "      <td>38.732128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>98</td>\n",
       "      <td>26</td>\n",
       "      <td>21.279299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>135</td>\n",
       "      <td>127</td>\n",
       "      <td>209.934998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>5.818490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.862972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>3.912395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>5.614738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>44.804386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>4.399953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3.700663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>97</td>\n",
       "      <td>11</td>\n",
       "      <td>11.836099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2.167750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>2.814762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>69</td>\n",
       "      <td>5</td>\n",
       "      <td>5.729888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.127342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>8.490266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>95</td>\n",
       "      <td>26</td>\n",
       "      <td>24.757322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>3.119032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>4.592147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>146</td>\n",
       "      <td>5</td>\n",
       "      <td>7.466989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>1.892938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>35.087635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>127</td>\n",
       "      <td>6</td>\n",
       "      <td>5.621406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>139</td>\n",
       "      <td>4</td>\n",
       "      <td>3.229935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>5.553265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>3.397245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    app_id  recommended  Prediction\n",
       "0       73            0    2.607911\n",
       "1      202            1    1.623165\n",
       "2       36            5    5.031623\n",
       "3      217           55   34.797199\n",
       "4       60            6    6.023920\n",
       "5      112            3    4.834821\n",
       "6      144            2    4.053123\n",
       "7      141            3    3.519709\n",
       "8      151           17   15.735341\n",
       "9      213            3    4.471392\n",
       "10     108            4    5.152316\n",
       "11     181            0    2.902127\n",
       "12     165            1    1.817364\n",
       "13     148            0    2.258358\n",
       "14     170            4    5.130611\n",
       "15     115            0    4.472449\n",
       "16     120            4    6.221038\n",
       "17      94           10    9.527883\n",
       "18     149           36   38.732128\n",
       "19      98           26   21.279299\n",
       "20     135          127  209.934998\n",
       "21      46            5    5.818490\n",
       "22       3            0    2.862972\n",
       "23      22            3    3.912395\n",
       "24      33            5    5.614738\n",
       "25       2           72   44.804386\n",
       "26      53            5    4.399953\n",
       "27      14            1    3.700663\n",
       "28      97           11   11.836099\n",
       "29      16            0    2.167750\n",
       "30      41            3    2.814762\n",
       "31      69            5    5.729888\n",
       "32       0            1    2.127342\n",
       "33      56            9    8.490266\n",
       "34      95           26   24.757322\n",
       "35      63            3    3.119032\n",
       "36     169            0    4.592147\n",
       "37     146            5    7.466989\n",
       "38     180            1    1.892938\n",
       "39      52           54   35.087635\n",
       "40     127            6    5.621406\n",
       "41     139            4    3.229935\n",
       "42      29            5    5.553265\n",
       "43      25            2    3.397245"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(pred, columns = ['Prediction'])\n",
    "df_x = pd.DataFrame(x_test).sort_index().reset_index()\n",
    "true_recommended = y_test.reset_index()\n",
    "\n",
    "result = pd.concat([df_x, true_recommended, predictions], axis = 1)\n",
    "show = result\n",
    "show = show.drop(show.loc[:, ~show.columns.isin(['index', 'recommended', 'Prediction'])], axis = 1)\n",
    "show.columns = ['index', 'app_id', 'recommended', 'Prediction']\n",
    "show = show.drop(['index'], axis = 1)\n",
    "show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf867d7",
   "metadata": {},
   "source": [
    "**Activation = Sigmoid**<br>\n",
    "**Optimizer = Adam**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f2ac53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run  1\n",
      "Activation: Sigmoid\n",
      "Optimizer: Adam\n",
      "\n",
      "Epoch 1/1000\n",
      "6/6 - 0s - loss: 169.0460 - val_loss: 706.6260\n",
      "Epoch 2/1000\n",
      "6/6 - 0s - loss: 166.9811 - val_loss: 702.8476\n",
      "Epoch 3/1000\n",
      "6/6 - 0s - loss: 165.0373 - val_loss: 698.8474\n",
      "Epoch 4/1000\n",
      "6/6 - 0s - loss: 163.0212 - val_loss: 695.2444\n",
      "Epoch 5/1000\n",
      "6/6 - 0s - loss: 161.3077 - val_loss: 691.6044\n",
      "Epoch 6/1000\n",
      "6/6 - 0s - loss: 159.5069 - val_loss: 688.2360\n",
      "Epoch 7/1000\n",
      "6/6 - 0s - loss: 157.8768 - val_loss: 685.4350\n",
      "Epoch 8/1000\n",
      "6/6 - 0s - loss: 156.3934 - val_loss: 682.8264\n",
      "Epoch 9/1000\n",
      "6/6 - 0s - loss: 155.0471 - val_loss: 680.4556\n",
      "Epoch 10/1000\n",
      "6/6 - 0s - loss: 153.7306 - val_loss: 678.3257\n",
      "Epoch 11/1000\n",
      "6/6 - 0s - loss: 152.5164 - val_loss: 676.3589\n",
      "Epoch 12/1000\n",
      "6/6 - 0s - loss: 151.3664 - val_loss: 674.5569\n",
      "Epoch 13/1000\n",
      "6/6 - 0s - loss: 150.3794 - val_loss: 672.7867\n",
      "Epoch 14/1000\n",
      "6/6 - 0s - loss: 149.3674 - val_loss: 671.1046\n",
      "Epoch 15/1000\n",
      "6/6 - 0s - loss: 148.4352 - val_loss: 669.4744\n",
      "Epoch 16/1000\n",
      "6/6 - 0s - loss: 147.5460 - val_loss: 667.9280\n",
      "Epoch 17/1000\n",
      "6/6 - 0s - loss: 146.6831 - val_loss: 666.5181\n",
      "Epoch 18/1000\n",
      "6/6 - 0s - loss: 145.9211 - val_loss: 665.1614\n",
      "Epoch 19/1000\n",
      "6/6 - 0s - loss: 145.1703 - val_loss: 663.8644\n",
      "Epoch 20/1000\n",
      "6/6 - 0s - loss: 144.4436 - val_loss: 662.6168\n",
      "Epoch 21/1000\n",
      "6/6 - 0s - loss: 143.7807 - val_loss: 661.3549\n",
      "Epoch 22/1000\n",
      "6/6 - 0s - loss: 143.0898 - val_loss: 660.2065\n",
      "Epoch 23/1000\n",
      "6/6 - 0s - loss: 142.4937 - val_loss: 659.0887\n",
      "Epoch 24/1000\n",
      "6/6 - 0s - loss: 141.9320 - val_loss: 658.0166\n",
      "Epoch 25/1000\n",
      "6/6 - 0s - loss: 141.3644 - val_loss: 657.0273\n",
      "Epoch 26/1000\n",
      "6/6 - 0s - loss: 140.8498 - val_loss: 656.0693\n",
      "Epoch 27/1000\n",
      "6/6 - 0s - loss: 140.3562 - val_loss: 655.1357\n",
      "Epoch 28/1000\n",
      "6/6 - 0s - loss: 139.8671 - val_loss: 654.2371\n",
      "Epoch 29/1000\n",
      "6/6 - 0s - loss: 139.3807 - val_loss: 653.3786\n",
      "Epoch 30/1000\n",
      "6/6 - 0s - loss: 138.9488 - val_loss: 652.4891\n",
      "Epoch 31/1000\n",
      "6/6 - 0s - loss: 138.5407 - val_loss: 651.6156\n",
      "Epoch 32/1000\n",
      "6/6 - 0s - loss: 138.0717 - val_loss: 650.8191\n",
      "Epoch 33/1000\n",
      "6/6 - 0s - loss: 137.6716 - val_loss: 650.0089\n",
      "Epoch 34/1000\n",
      "6/6 - 0s - loss: 137.2666 - val_loss: 649.2206\n",
      "Epoch 35/1000\n",
      "6/6 - 0s - loss: 136.8816 - val_loss: 648.4478\n",
      "Epoch 36/1000\n",
      "6/6 - 0s - loss: 136.5030 - val_loss: 647.6833\n",
      "Epoch 37/1000\n",
      "6/6 - 0s - loss: 136.1434 - val_loss: 646.9060\n",
      "Epoch 38/1000\n",
      "6/6 - 0s - loss: 135.7623 - val_loss: 646.1680\n",
      "Epoch 39/1000\n",
      "6/6 - 0s - loss: 135.3885 - val_loss: 645.4908\n",
      "Epoch 40/1000\n",
      "6/6 - 0s - loss: 135.0933 - val_loss: 644.7636\n",
      "Epoch 41/1000\n",
      "6/6 - 0s - loss: 134.7648 - val_loss: 644.0595\n",
      "Epoch 42/1000\n",
      "6/6 - 0s - loss: 134.4033 - val_loss: 643.3934\n",
      "Epoch 43/1000\n",
      "6/6 - 0s - loss: 134.0961 - val_loss: 642.7081\n",
      "Epoch 44/1000\n",
      "6/6 - 0s - loss: 133.7629 - val_loss: 642.0552\n",
      "Epoch 45/1000\n",
      "6/6 - 0s - loss: 133.4594 - val_loss: 641.3930\n",
      "Epoch 46/1000\n",
      "6/6 - 0s - loss: 133.1551 - val_loss: 640.7216\n",
      "Epoch 47/1000\n",
      "6/6 - 0s - loss: 132.8607 - val_loss: 640.0426\n",
      "Epoch 48/1000\n",
      "6/6 - 0s - loss: 132.5531 - val_loss: 639.4213\n",
      "Epoch 49/1000\n",
      "6/6 - 0s - loss: 132.2782 - val_loss: 638.8129\n",
      "Epoch 50/1000\n",
      "6/6 - 0s - loss: 131.9780 - val_loss: 638.2368\n",
      "Epoch 51/1000\n",
      "6/6 - 0s - loss: 131.7580 - val_loss: 637.5867\n",
      "Epoch 52/1000\n",
      "6/6 - 0s - loss: 131.4623 - val_loss: 636.9938\n",
      "Epoch 53/1000\n",
      "6/6 - 0s - loss: 131.1824 - val_loss: 636.4150\n",
      "Epoch 54/1000\n",
      "6/6 - 0s - loss: 130.9272 - val_loss: 635.8443\n",
      "Epoch 55/1000\n",
      "6/6 - 0s - loss: 130.6530 - val_loss: 635.2964\n",
      "Epoch 56/1000\n",
      "6/6 - 0s - loss: 130.4122 - val_loss: 634.7413\n",
      "Epoch 57/1000\n",
      "6/6 - 0s - loss: 130.1946 - val_loss: 634.1557\n",
      "Epoch 58/1000\n",
      "6/6 - 0s - loss: 129.9241 - val_loss: 633.6133\n",
      "Epoch 59/1000\n",
      "6/6 - 0s - loss: 129.6688 - val_loss: 633.0850\n",
      "Epoch 60/1000\n",
      "6/6 - 0s - loss: 129.4579 - val_loss: 632.5201\n",
      "Epoch 61/1000\n",
      "6/6 - 0s - loss: 129.2009 - val_loss: 632.0048\n",
      "Epoch 62/1000\n",
      "6/6 - 0s - loss: 128.9712 - val_loss: 631.4934\n",
      "Epoch 63/1000\n",
      "6/6 - 0s - loss: 128.7463 - val_loss: 630.9667\n",
      "Epoch 64/1000\n",
      "6/6 - 0s - loss: 128.5248 - val_loss: 630.4448\n",
      "Epoch 65/1000\n",
      "6/6 - 0s - loss: 128.3007 - val_loss: 629.9448\n",
      "Epoch 66/1000\n",
      "6/6 - 0s - loss: 128.0884 - val_loss: 629.4354\n",
      "Epoch 67/1000\n",
      "6/6 - 0s - loss: 127.8688 - val_loss: 628.9382\n",
      "Epoch 68/1000\n",
      "6/6 - 0s - loss: 127.6471 - val_loss: 628.4732\n",
      "Epoch 69/1000\n",
      "6/6 - 0s - loss: 127.4539 - val_loss: 628.0002\n",
      "Epoch 70/1000\n",
      "6/6 - 0s - loss: 127.2446 - val_loss: 627.5156\n",
      "Epoch 71/1000\n",
      "6/6 - 0s - loss: 127.0406 - val_loss: 627.0002\n",
      "Epoch 72/1000\n",
      "6/6 - 0s - loss: 126.8149 - val_loss: 626.4892\n",
      "Epoch 73/1000\n",
      "6/6 - 0s - loss: 126.6106 - val_loss: 625.9593\n",
      "Epoch 74/1000\n",
      "6/6 - 0s - loss: 126.3940 - val_loss: 625.4507\n",
      "Epoch 75/1000\n",
      "6/6 - 0s - loss: 126.1767 - val_loss: 624.9692\n",
      "Epoch 76/1000\n",
      "6/6 - 0s - loss: 125.9668 - val_loss: 624.4949\n",
      "Epoch 77/1000\n",
      "6/6 - 0s - loss: 125.7806 - val_loss: 624.0042\n",
      "Epoch 78/1000\n",
      "6/6 - 0s - loss: 125.5868 - val_loss: 623.5100\n",
      "Epoch 79/1000\n",
      "6/6 - 0s - loss: 125.3864 - val_loss: 623.0372\n",
      "Epoch 80/1000\n",
      "6/6 - 0s - loss: 125.1861 - val_loss: 622.5923\n",
      "Epoch 81/1000\n",
      "6/6 - 0s - loss: 124.9855 - val_loss: 622.1743\n",
      "Epoch 82/1000\n",
      "6/6 - 0s - loss: 124.8019 - val_loss: 621.7557\n",
      "Epoch 83/1000\n",
      "6/6 - 0s - loss: 124.6509 - val_loss: 621.3091\n",
      "Epoch 84/1000\n",
      "6/6 - 0s - loss: 124.4599 - val_loss: 620.8885\n",
      "Epoch 85/1000\n",
      "6/6 - 0s - loss: 124.2862 - val_loss: 620.4641\n",
      "Epoch 86/1000\n",
      "6/6 - 0s - loss: 124.0827 - val_loss: 620.0637\n",
      "Epoch 87/1000\n",
      "6/6 - 0s - loss: 123.9139 - val_loss: 619.6218\n",
      "Epoch 88/1000\n",
      "6/6 - 0s - loss: 123.7474 - val_loss: 619.1699\n",
      "Epoch 89/1000\n",
      "6/6 - 0s - loss: 123.5493 - val_loss: 618.7493\n",
      "Epoch 90/1000\n",
      "6/6 - 0s - loss: 123.3613 - val_loss: 618.3295\n",
      "Epoch 91/1000\n",
      "6/6 - 0s - loss: 123.1734 - val_loss: 617.9186\n",
      "Epoch 92/1000\n",
      "6/6 - 0s - loss: 122.9938 - val_loss: 617.4839\n",
      "Epoch 93/1000\n",
      "6/6 - 0s - loss: 122.8111 - val_loss: 617.0113\n",
      "Epoch 94/1000\n",
      "6/6 - 0s - loss: 122.6029 - val_loss: 616.5778\n",
      "Epoch 95/1000\n",
      "6/6 - 0s - loss: 122.4320 - val_loss: 616.1381\n",
      "Epoch 96/1000\n",
      "6/6 - 0s - loss: 122.2346 - val_loss: 615.7179\n",
      "Epoch 97/1000\n",
      "6/6 - 0s - loss: 122.0473 - val_loss: 615.2966\n",
      "Epoch 98/1000\n",
      "6/6 - 0s - loss: 121.8407 - val_loss: 614.8987\n",
      "Epoch 99/1000\n",
      "6/6 - 0s - loss: 121.6528 - val_loss: 614.4902\n",
      "Epoch 100/1000\n",
      "6/6 - 0s - loss: 121.4455 - val_loss: 614.0781\n",
      "Epoch 101/1000\n",
      "6/6 - 0s - loss: 121.2568 - val_loss: 613.6116\n",
      "Epoch 102/1000\n",
      "6/6 - 0s - loss: 121.0412 - val_loss: 613.1702\n",
      "Epoch 103/1000\n",
      "6/6 - 0s - loss: 120.8340 - val_loss: 612.7421\n",
      "Epoch 104/1000\n",
      "6/6 - 0s - loss: 120.6236 - val_loss: 612.3253\n",
      "Epoch 105/1000\n",
      "6/6 - 0s - loss: 120.4149 - val_loss: 611.9133\n",
      "Epoch 106/1000\n",
      "6/6 - 0s - loss: 120.1982 - val_loss: 611.5021\n",
      "Epoch 107/1000\n",
      "6/6 - 0s - loss: 119.9929 - val_loss: 611.0795\n",
      "Epoch 108/1000\n",
      "6/6 - 0s - loss: 119.7698 - val_loss: 610.6714\n",
      "Epoch 109/1000\n",
      "6/6 - 0s - loss: 119.5377 - val_loss: 610.2862\n",
      "Epoch 110/1000\n",
      "6/6 - 0s - loss: 119.3198 - val_loss: 609.8541\n",
      "Epoch 111/1000\n",
      "6/6 - 0s - loss: 119.0844 - val_loss: 609.3990\n",
      "Epoch 112/1000\n",
      "6/6 - 0s - loss: 118.8415 - val_loss: 608.9335\n",
      "Epoch 113/1000\n",
      "6/6 - 0s - loss: 118.5799 - val_loss: 608.4999\n",
      "Epoch 114/1000\n",
      "6/6 - 0s - loss: 118.3285 - val_loss: 608.0591\n",
      "Epoch 115/1000\n",
      "6/6 - 0s - loss: 118.0888 - val_loss: 607.5789\n",
      "Epoch 116/1000\n",
      "6/6 - 0s - loss: 117.8192 - val_loss: 607.1077\n",
      "Epoch 117/1000\n",
      "6/6 - 0s - loss: 117.5259 - val_loss: 606.6644\n",
      "Epoch 118/1000\n",
      "6/6 - 0s - loss: 117.2620 - val_loss: 606.1801\n",
      "Epoch 119/1000\n",
      "6/6 - 0s - loss: 116.9949 - val_loss: 605.6709\n",
      "Epoch 120/1000\n",
      "6/6 - 0s - loss: 116.6898 - val_loss: 605.1920\n",
      "Epoch 121/1000\n",
      "6/6 - 0s - loss: 116.4181 - val_loss: 604.6928\n",
      "Epoch 122/1000\n",
      "6/6 - 0s - loss: 116.1108 - val_loss: 604.1986\n",
      "Epoch 123/1000\n",
      "6/6 - 0s - loss: 115.8498 - val_loss: 603.6513\n",
      "Epoch 124/1000\n",
      "6/6 - 0s - loss: 115.5407 - val_loss: 603.1376\n",
      "Epoch 125/1000\n",
      "6/6 - 0s - loss: 115.2415 - val_loss: 602.6335\n",
      "Epoch 126/1000\n",
      "6/6 - 0s - loss: 114.9555 - val_loss: 602.0926\n",
      "Epoch 127/1000\n",
      "6/6 - 0s - loss: 114.6657 - val_loss: 601.5463\n",
      "Epoch 128/1000\n",
      "6/6 - 0s - loss: 114.3808 - val_loss: 601.0066\n",
      "Epoch 129/1000\n",
      "6/6 - 0s - loss: 114.0916 - val_loss: 600.4821\n",
      "Epoch 130/1000\n",
      "6/6 - 0s - loss: 113.8077 - val_loss: 599.9615\n",
      "Epoch 131/1000\n",
      "6/6 - 0s - loss: 113.5160 - val_loss: 599.4591\n",
      "Epoch 132/1000\n",
      "6/6 - 0s - loss: 113.2456 - val_loss: 598.9027\n",
      "Epoch 133/1000\n",
      "6/6 - 0s - loss: 112.9462 - val_loss: 598.3539\n",
      "Epoch 134/1000\n",
      "6/6 - 0s - loss: 112.6855 - val_loss: 597.7576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/1000\n",
      "6/6 - 0s - loss: 112.3855 - val_loss: 597.1926\n",
      "Epoch 136/1000\n",
      "6/6 - 0s - loss: 112.0984 - val_loss: 596.6470\n",
      "Epoch 137/1000\n",
      "6/6 - 0s - loss: 111.8254 - val_loss: 596.1130\n",
      "Epoch 138/1000\n",
      "6/6 - 0s - loss: 111.5732 - val_loss: 595.5551\n",
      "Epoch 139/1000\n",
      "6/6 - 0s - loss: 111.2820 - val_loss: 595.0237\n",
      "Epoch 140/1000\n",
      "6/6 - 0s - loss: 111.0633 - val_loss: 594.4399\n",
      "Epoch 141/1000\n",
      "6/6 - 0s - loss: 110.7677 - val_loss: 593.9055\n",
      "Epoch 142/1000\n",
      "6/6 - 0s - loss: 110.4891 - val_loss: 593.3944\n",
      "Epoch 143/1000\n",
      "6/6 - 0s - loss: 110.2416 - val_loss: 592.8607\n",
      "Epoch 144/1000\n",
      "6/6 - 0s - loss: 109.9935 - val_loss: 592.3212\n",
      "Epoch 145/1000\n",
      "6/6 - 0s - loss: 109.7514 - val_loss: 591.7637\n",
      "Epoch 146/1000\n",
      "6/6 - 0s - loss: 109.4890 - val_loss: 591.2126\n",
      "Epoch 147/1000\n",
      "6/6 - 0s - loss: 109.2373 - val_loss: 590.6635\n",
      "Epoch 148/1000\n",
      "6/6 - 0s - loss: 108.9726 - val_loss: 590.1299\n",
      "Epoch 149/1000\n",
      "6/6 - 0s - loss: 108.7408 - val_loss: 589.5596\n",
      "Epoch 150/1000\n",
      "6/6 - 0s - loss: 108.4803 - val_loss: 589.0149\n",
      "Epoch 151/1000\n",
      "6/6 - 0s - loss: 108.2416 - val_loss: 588.4669\n",
      "Epoch 152/1000\n",
      "6/6 - 0s - loss: 107.9966 - val_loss: 587.9405\n",
      "Epoch 153/1000\n",
      "6/6 - 0s - loss: 107.7578 - val_loss: 587.4214\n",
      "Epoch 154/1000\n",
      "6/6 - 0s - loss: 107.5126 - val_loss: 586.9099\n",
      "Epoch 155/1000\n",
      "6/6 - 0s - loss: 107.2893 - val_loss: 586.3527\n",
      "Epoch 156/1000\n",
      "6/6 - 0s - loss: 107.0377 - val_loss: 585.8048\n",
      "Epoch 157/1000\n",
      "6/6 - 0s - loss: 106.8098 - val_loss: 585.2307\n",
      "Epoch 158/1000\n",
      "6/6 - 0s - loss: 106.5653 - val_loss: 584.6896\n",
      "Epoch 159/1000\n",
      "6/6 - 0s - loss: 106.3238 - val_loss: 584.1744\n",
      "Epoch 160/1000\n",
      "6/6 - 0s - loss: 106.1000 - val_loss: 583.6395\n",
      "Epoch 161/1000\n",
      "6/6 - 0s - loss: 105.8602 - val_loss: 583.1284\n",
      "Epoch 162/1000\n",
      "6/6 - 0s - loss: 105.6530 - val_loss: 582.5903\n",
      "Epoch 163/1000\n",
      "6/6 - 0s - loss: 105.4417 - val_loss: 582.0471\n",
      "Epoch 164/1000\n",
      "6/6 - 0s - loss: 105.2022 - val_loss: 581.5347\n",
      "Epoch 165/1000\n",
      "6/6 - 0s - loss: 104.9827 - val_loss: 581.0175\n",
      "Epoch 166/1000\n",
      "6/6 - 0s - loss: 104.7558 - val_loss: 580.4994\n",
      "Epoch 167/1000\n",
      "6/6 - 0s - loss: 104.5442 - val_loss: 579.9659\n",
      "Epoch 168/1000\n",
      "6/6 - 0s - loss: 104.3295 - val_loss: 579.4472\n",
      "Epoch 169/1000\n",
      "6/6 - 0s - loss: 104.1176 - val_loss: 578.9407\n",
      "Epoch 170/1000\n",
      "6/6 - 0s - loss: 103.9009 - val_loss: 578.4498\n",
      "Epoch 171/1000\n",
      "6/6 - 0s - loss: 103.6679 - val_loss: 577.9726\n",
      "Epoch 172/1000\n",
      "6/6 - 0s - loss: 103.4656 - val_loss: 577.4449\n",
      "Epoch 173/1000\n",
      "6/6 - 0s - loss: 103.2704 - val_loss: 576.8959\n",
      "Epoch 174/1000\n",
      "6/6 - 0s - loss: 103.0493 - val_loss: 576.3633\n",
      "Epoch 175/1000\n",
      "6/6 - 0s - loss: 102.8398 - val_loss: 575.8517\n",
      "Epoch 176/1000\n",
      "6/6 - 0s - loss: 102.6250 - val_loss: 575.3698\n",
      "Epoch 177/1000\n",
      "6/6 - 0s - loss: 102.4397 - val_loss: 574.8828\n",
      "Epoch 178/1000\n",
      "6/6 - 0s - loss: 102.2399 - val_loss: 574.4161\n",
      "Epoch 179/1000\n",
      "6/6 - 0s - loss: 102.0534 - val_loss: 573.9383\n",
      "Epoch 180/1000\n",
      "6/6 - 0s - loss: 101.8586 - val_loss: 573.4688\n",
      "Epoch 181/1000\n",
      "6/6 - 0s - loss: 101.6777 - val_loss: 572.9875\n",
      "Epoch 182/1000\n",
      "6/6 - 0s - loss: 101.4765 - val_loss: 572.5085\n",
      "Epoch 183/1000\n",
      "6/6 - 0s - loss: 101.2781 - val_loss: 572.0310\n",
      "Epoch 184/1000\n",
      "6/6 - 0s - loss: 101.0960 - val_loss: 571.5328\n",
      "Epoch 185/1000\n",
      "6/6 - 0s - loss: 100.8843 - val_loss: 571.0507\n",
      "Epoch 186/1000\n",
      "6/6 - 0s - loss: 100.6994 - val_loss: 570.5648\n",
      "Epoch 187/1000\n",
      "6/6 - 0s - loss: 100.4924 - val_loss: 570.0964\n",
      "Epoch 188/1000\n",
      "6/6 - 0s - loss: 100.3099 - val_loss: 569.6223\n",
      "Epoch 189/1000\n",
      "6/6 - 0s - loss: 100.1086 - val_loss: 569.1502\n",
      "Epoch 190/1000\n",
      "6/6 - 0s - loss: 99.9334 - val_loss: 568.6347\n",
      "Epoch 191/1000\n",
      "6/6 - 0s - loss: 99.7411 - val_loss: 568.1246\n",
      "Epoch 192/1000\n",
      "6/6 - 0s - loss: 99.5209 - val_loss: 567.6500\n",
      "Epoch 193/1000\n",
      "6/6 - 0s - loss: 99.3553 - val_loss: 567.1661\n",
      "Epoch 194/1000\n",
      "6/6 - 0s - loss: 99.1507 - val_loss: 566.7096\n",
      "Epoch 195/1000\n",
      "6/6 - 0s - loss: 98.9742 - val_loss: 566.2437\n",
      "Epoch 196/1000\n",
      "6/6 - 0s - loss: 98.7916 - val_loss: 565.7790\n",
      "Epoch 197/1000\n",
      "6/6 - 0s - loss: 98.6059 - val_loss: 565.3012\n",
      "Epoch 198/1000\n",
      "6/6 - 0s - loss: 98.4294 - val_loss: 564.8054\n",
      "Epoch 199/1000\n",
      "6/6 - 0s - loss: 98.2206 - val_loss: 564.3502\n",
      "Epoch 200/1000\n",
      "6/6 - 0s - loss: 98.0525 - val_loss: 563.8797\n",
      "Epoch 201/1000\n",
      "6/6 - 0s - loss: 97.8782 - val_loss: 563.4042\n",
      "Epoch 202/1000\n",
      "6/6 - 0s - loss: 97.6836 - val_loss: 562.9512\n",
      "Epoch 203/1000\n",
      "6/6 - 0s - loss: 97.5140 - val_loss: 562.4897\n",
      "Epoch 204/1000\n",
      "6/6 - 0s - loss: 97.3245 - val_loss: 562.0488\n",
      "Epoch 205/1000\n",
      "6/6 - 0s - loss: 97.1545 - val_loss: 561.5984\n",
      "Epoch 206/1000\n",
      "6/6 - 0s - loss: 96.9777 - val_loss: 561.1264\n",
      "Epoch 207/1000\n",
      "6/6 - 0s - loss: 96.7990 - val_loss: 560.6390\n",
      "Epoch 208/1000\n",
      "6/6 - 0s - loss: 96.6182 - val_loss: 560.1427\n",
      "Epoch 209/1000\n",
      "6/6 - 0s - loss: 96.4350 - val_loss: 559.6661\n",
      "Epoch 210/1000\n",
      "6/6 - 0s - loss: 96.2653 - val_loss: 559.1906\n",
      "Epoch 211/1000\n",
      "6/6 - 0s - loss: 96.0764 - val_loss: 558.7369\n",
      "Epoch 212/1000\n",
      "6/6 - 0s - loss: 95.8939 - val_loss: 558.3046\n",
      "Epoch 213/1000\n",
      "6/6 - 0s - loss: 95.7347 - val_loss: 557.8686\n",
      "Epoch 214/1000\n",
      "6/6 - 0s - loss: 95.5746 - val_loss: 557.4433\n",
      "Epoch 215/1000\n",
      "6/6 - 0s - loss: 95.4097 - val_loss: 557.0005\n",
      "Epoch 216/1000\n",
      "6/6 - 0s - loss: 95.2425 - val_loss: 556.5591\n",
      "Epoch 217/1000\n",
      "6/6 - 0s - loss: 95.0650 - val_loss: 556.1277\n",
      "Epoch 218/1000\n",
      "6/6 - 0s - loss: 94.9098 - val_loss: 555.6804\n",
      "Epoch 219/1000\n",
      "6/6 - 0s - loss: 94.7390 - val_loss: 555.2383\n",
      "Epoch 220/1000\n",
      "6/6 - 0s - loss: 94.5713 - val_loss: 554.7830\n",
      "Epoch 221/1000\n",
      "6/6 - 0s - loss: 94.4125 - val_loss: 554.3118\n",
      "Epoch 222/1000\n",
      "6/6 - 0s - loss: 94.2336 - val_loss: 553.8679\n",
      "Epoch 223/1000\n",
      "6/6 - 0s - loss: 94.0592 - val_loss: 553.4460\n",
      "Epoch 224/1000\n",
      "6/6 - 0s - loss: 93.9016 - val_loss: 553.0192\n",
      "Epoch 225/1000\n",
      "6/6 - 0s - loss: 93.7401 - val_loss: 552.6012\n",
      "Epoch 226/1000\n",
      "6/6 - 0s - loss: 93.5920 - val_loss: 552.1707\n",
      "Epoch 227/1000\n",
      "6/6 - 0s - loss: 93.4222 - val_loss: 551.7387\n",
      "Epoch 228/1000\n",
      "6/6 - 0s - loss: 93.2494 - val_loss: 551.3054\n",
      "Epoch 229/1000\n",
      "6/6 - 0s - loss: 93.0798 - val_loss: 550.8742\n",
      "Epoch 230/1000\n",
      "6/6 - 0s - loss: 92.9251 - val_loss: 550.4103\n",
      "Epoch 231/1000\n",
      "6/6 - 0s - loss: 92.7704 - val_loss: 549.9685\n",
      "Epoch 232/1000\n",
      "6/6 - 0s - loss: 92.6071 - val_loss: 549.5466\n",
      "Epoch 233/1000\n",
      "6/6 - 0s - loss: 92.4636 - val_loss: 549.1080\n",
      "Epoch 234/1000\n",
      "6/6 - 0s - loss: 92.2897 - val_loss: 548.7035\n",
      "Epoch 235/1000\n",
      "6/6 - 0s - loss: 92.1582 - val_loss: 548.2632\n",
      "Epoch 236/1000\n",
      "6/6 - 0s - loss: 91.9776 - val_loss: 547.8570\n",
      "Epoch 237/1000\n",
      "6/6 - 0s - loss: 91.8264 - val_loss: 547.4348\n",
      "Epoch 238/1000\n",
      "6/6 - 0s - loss: 91.6672 - val_loss: 547.0045\n",
      "Epoch 239/1000\n",
      "6/6 - 0s - loss: 91.5167 - val_loss: 546.5864\n",
      "Epoch 240/1000\n",
      "6/6 - 0s - loss: 91.3648 - val_loss: 546.1705\n",
      "Epoch 241/1000\n",
      "6/6 - 0s - loss: 91.2063 - val_loss: 545.7802\n",
      "Epoch 242/1000\n",
      "6/6 - 0s - loss: 91.0543 - val_loss: 545.3690\n",
      "Epoch 243/1000\n",
      "6/6 - 0s - loss: 90.8985 - val_loss: 544.9412\n",
      "Epoch 244/1000\n",
      "6/6 - 0s - loss: 90.7613 - val_loss: 544.4902\n",
      "Epoch 245/1000\n",
      "6/6 - 0s - loss: 90.5950 - val_loss: 544.0603\n",
      "Epoch 246/1000\n",
      "6/6 - 0s - loss: 90.4295 - val_loss: 543.6542\n",
      "Epoch 247/1000\n",
      "6/6 - 0s - loss: 90.3066 - val_loss: 543.2060\n",
      "Epoch 248/1000\n",
      "6/6 - 0s - loss: 90.1314 - val_loss: 542.8044\n",
      "Epoch 249/1000\n",
      "6/6 - 0s - loss: 89.9802 - val_loss: 542.4010\n",
      "Epoch 250/1000\n",
      "6/6 - 0s - loss: 89.8434 - val_loss: 541.9673\n",
      "Epoch 251/1000\n",
      "6/6 - 0s - loss: 89.6886 - val_loss: 541.5396\n",
      "Epoch 252/1000\n",
      "6/6 - 0s - loss: 89.5322 - val_loss: 541.1133\n",
      "Epoch 253/1000\n",
      "6/6 - 0s - loss: 89.3860 - val_loss: 540.6895\n",
      "Epoch 254/1000\n",
      "6/6 - 0s - loss: 89.2234 - val_loss: 540.2639\n",
      "Epoch 255/1000\n",
      "6/6 - 0s - loss: 89.0842 - val_loss: 539.8016\n",
      "Epoch 256/1000\n",
      "6/6 - 0s - loss: 88.9265 - val_loss: 539.3696\n",
      "Epoch 257/1000\n",
      "6/6 - 0s - loss: 88.7837 - val_loss: 538.9331\n",
      "Epoch 258/1000\n",
      "6/6 - 0s - loss: 88.6193 - val_loss: 538.5284\n",
      "Epoch 259/1000\n",
      "6/6 - 0s - loss: 88.4745 - val_loss: 538.1156\n",
      "Epoch 260/1000\n",
      "6/6 - 0s - loss: 88.3380 - val_loss: 537.6930\n",
      "Epoch 261/1000\n",
      "6/6 - 0s - loss: 88.2003 - val_loss: 537.2657\n",
      "Epoch 262/1000\n",
      "6/6 - 0s - loss: 88.0512 - val_loss: 536.8637\n",
      "Epoch 263/1000\n",
      "6/6 - 0s - loss: 87.9036 - val_loss: 536.4615\n",
      "Epoch 264/1000\n",
      "6/6 - 0s - loss: 87.7653 - val_loss: 536.0442\n",
      "Epoch 265/1000\n",
      "6/6 - 0s - loss: 87.6313 - val_loss: 535.6205\n",
      "Epoch 266/1000\n",
      "6/6 - 0s - loss: 87.4773 - val_loss: 535.2084\n",
      "Epoch 267/1000\n",
      "6/6 - 0s - loss: 87.3358 - val_loss: 534.8091\n",
      "Epoch 268/1000\n",
      "6/6 - 0s - loss: 87.1864 - val_loss: 534.4064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269/1000\n",
      "6/6 - 0s - loss: 87.0528 - val_loss: 533.9727\n",
      "Epoch 270/1000\n",
      "6/6 - 0s - loss: 86.9001 - val_loss: 533.5801\n",
      "Epoch 271/1000\n",
      "6/6 - 0s - loss: 86.7854 - val_loss: 533.1887\n",
      "Epoch 272/1000\n",
      "6/6 - 0s - loss: 86.6286 - val_loss: 532.8224\n",
      "Epoch 273/1000\n",
      "6/6 - 0s - loss: 86.5022 - val_loss: 532.4274\n",
      "Epoch 274/1000\n",
      "6/6 - 0s - loss: 86.3635 - val_loss: 532.0176\n",
      "Epoch 275/1000\n",
      "6/6 - 0s - loss: 86.2304 - val_loss: 531.5967\n",
      "Epoch 276/1000\n",
      "6/6 - 0s - loss: 86.0800 - val_loss: 531.1630\n",
      "Epoch 277/1000\n",
      "6/6 - 0s - loss: 85.9612 - val_loss: 530.7285\n",
      "Epoch 278/1000\n",
      "6/6 - 0s - loss: 85.8057 - val_loss: 530.3377\n",
      "Epoch 279/1000\n",
      "6/6 - 0s - loss: 85.6731 - val_loss: 529.9571\n",
      "Epoch 280/1000\n",
      "6/6 - 0s - loss: 85.5273 - val_loss: 529.5832\n",
      "Epoch 281/1000\n",
      "6/6 - 0s - loss: 85.4121 - val_loss: 529.1535\n",
      "Epoch 282/1000\n",
      "6/6 - 0s - loss: 85.2578 - val_loss: 528.7778\n",
      "Epoch 283/1000\n",
      "6/6 - 0s - loss: 85.1195 - val_loss: 528.3942\n",
      "Epoch 284/1000\n",
      "6/6 - 0s - loss: 85.0074 - val_loss: 527.9463\n",
      "Epoch 285/1000\n",
      "6/6 - 0s - loss: 84.8671 - val_loss: 527.5229\n",
      "Epoch 286/1000\n",
      "6/6 - 0s - loss: 84.7100 - val_loss: 527.1519\n",
      "Epoch 287/1000\n",
      "6/6 - 0s - loss: 84.5860 - val_loss: 526.7611\n",
      "Epoch 288/1000\n",
      "6/6 - 0s - loss: 84.4734 - val_loss: 526.3621\n",
      "Epoch 289/1000\n",
      "6/6 - 0s - loss: 84.3337 - val_loss: 525.9846\n",
      "Epoch 290/1000\n",
      "6/6 - 0s - loss: 84.2088 - val_loss: 525.6065\n",
      "Epoch 291/1000\n",
      "6/6 - 0s - loss: 84.0837 - val_loss: 525.2295\n",
      "Epoch 292/1000\n",
      "6/6 - 0s - loss: 83.9495 - val_loss: 524.8466\n",
      "Epoch 293/1000\n",
      "6/6 - 0s - loss: 83.8317 - val_loss: 524.4636\n",
      "Epoch 294/1000\n",
      "6/6 - 0s - loss: 83.7132 - val_loss: 524.0678\n",
      "Epoch 295/1000\n",
      "6/6 - 0s - loss: 83.5713 - val_loss: 523.6983\n",
      "Epoch 296/1000\n",
      "6/6 - 0s - loss: 83.4593 - val_loss: 523.3356\n",
      "Epoch 297/1000\n",
      "6/6 - 0s - loss: 83.3435 - val_loss: 522.9684\n",
      "Epoch 298/1000\n",
      "6/6 - 0s - loss: 83.2315 - val_loss: 522.5936\n",
      "Epoch 299/1000\n",
      "6/6 - 0s - loss: 83.0958 - val_loss: 522.2151\n",
      "Epoch 300/1000\n",
      "6/6 - 0s - loss: 82.9754 - val_loss: 521.8556\n",
      "Epoch 301/1000\n",
      "6/6 - 0s - loss: 82.8679 - val_loss: 521.5043\n",
      "Epoch 302/1000\n",
      "6/6 - 0s - loss: 82.7332 - val_loss: 521.1687\n",
      "Epoch 303/1000\n",
      "6/6 - 0s - loss: 82.6279 - val_loss: 520.7835\n",
      "Epoch 304/1000\n",
      "6/6 - 0s - loss: 82.5013 - val_loss: 520.4088\n",
      "Epoch 305/1000\n",
      "6/6 - 0s - loss: 82.3699 - val_loss: 520.0848\n",
      "Epoch 306/1000\n",
      "6/6 - 0s - loss: 82.2612 - val_loss: 519.6989\n",
      "Epoch 307/1000\n",
      "6/6 - 0s - loss: 82.1229 - val_loss: 519.2883\n",
      "Epoch 308/1000\n",
      "6/6 - 0s - loss: 81.9905 - val_loss: 518.8785\n",
      "Epoch 309/1000\n",
      "6/6 - 0s - loss: 81.8630 - val_loss: 518.4977\n",
      "Epoch 310/1000\n",
      "6/6 - 0s - loss: 81.7391 - val_loss: 518.1332\n",
      "Epoch 311/1000\n",
      "6/6 - 0s - loss: 81.6034 - val_loss: 517.8046\n",
      "Epoch 312/1000\n",
      "6/6 - 0s - loss: 81.4897 - val_loss: 517.4483\n",
      "Epoch 313/1000\n",
      "6/6 - 0s - loss: 81.3762 - val_loss: 517.0808\n",
      "Epoch 314/1000\n",
      "6/6 - 0s - loss: 81.2458 - val_loss: 516.7206\n",
      "Epoch 315/1000\n",
      "6/6 - 0s - loss: 81.1274 - val_loss: 516.3580\n",
      "Epoch 316/1000\n",
      "6/6 - 0s - loss: 81.0211 - val_loss: 516.0026\n",
      "Epoch 317/1000\n",
      "6/6 - 0s - loss: 80.8913 - val_loss: 515.6823\n",
      "Epoch 318/1000\n",
      "6/6 - 0s - loss: 80.7738 - val_loss: 515.3340\n",
      "Epoch 319/1000\n",
      "6/6 - 0s - loss: 80.6627 - val_loss: 514.9624\n",
      "Epoch 320/1000\n",
      "6/6 - 0s - loss: 80.5408 - val_loss: 514.5940\n",
      "Epoch 321/1000\n",
      "6/6 - 0s - loss: 80.4289 - val_loss: 514.2528\n",
      "Epoch 322/1000\n",
      "6/6 - 0s - loss: 80.3035 - val_loss: 513.9265\n",
      "Epoch 323/1000\n",
      "6/6 - 0s - loss: 80.1886 - val_loss: 513.5681\n",
      "Epoch 324/1000\n",
      "6/6 - 0s - loss: 80.0774 - val_loss: 513.1577\n",
      "Epoch 325/1000\n",
      "6/6 - 0s - loss: 79.9356 - val_loss: 512.7617\n",
      "Epoch 326/1000\n",
      "6/6 - 0s - loss: 79.8015 - val_loss: 512.3733\n",
      "Epoch 327/1000\n",
      "6/6 - 0s - loss: 79.7012 - val_loss: 511.9784\n",
      "Epoch 328/1000\n",
      "6/6 - 0s - loss: 79.5576 - val_loss: 511.6369\n",
      "Epoch 329/1000\n",
      "6/6 - 0s - loss: 79.4513 - val_loss: 511.2412\n",
      "Epoch 330/1000\n",
      "6/6 - 0s - loss: 79.3212 - val_loss: 510.8656\n",
      "Epoch 331/1000\n",
      "6/6 - 0s - loss: 79.2114 - val_loss: 510.5115\n",
      "Epoch 332/1000\n",
      "6/6 - 0s - loss: 79.0907 - val_loss: 510.1754\n",
      "Epoch 333/1000\n",
      "6/6 - 0s - loss: 78.9813 - val_loss: 509.8219\n",
      "Epoch 334/1000\n",
      "6/6 - 0s - loss: 78.8651 - val_loss: 509.4599\n",
      "Epoch 335/1000\n",
      "6/6 - 0s - loss: 78.7513 - val_loss: 509.0779\n",
      "Epoch 336/1000\n",
      "6/6 - 0s - loss: 78.6277 - val_loss: 508.7342\n",
      "Epoch 337/1000\n",
      "6/6 - 0s - loss: 78.5136 - val_loss: 508.3620\n",
      "Epoch 338/1000\n",
      "6/6 - 0s - loss: 78.3863 - val_loss: 507.9828\n",
      "Epoch 339/1000\n",
      "6/6 - 0s - loss: 78.2850 - val_loss: 507.5900\n",
      "Epoch 340/1000\n",
      "6/6 - 0s - loss: 78.1522 - val_loss: 507.2537\n",
      "Epoch 341/1000\n",
      "6/6 - 0s - loss: 78.0437 - val_loss: 506.8658\n",
      "Epoch 342/1000\n",
      "6/6 - 0s - loss: 77.9248 - val_loss: 506.5001\n",
      "Epoch 343/1000\n",
      "6/6 - 0s - loss: 77.8172 - val_loss: 506.1404\n",
      "Epoch 344/1000\n",
      "6/6 - 0s - loss: 77.6851 - val_loss: 505.8050\n",
      "Epoch 345/1000\n",
      "6/6 - 0s - loss: 77.5938 - val_loss: 505.4596\n",
      "Epoch 346/1000\n",
      "6/6 - 0s - loss: 77.4621 - val_loss: 505.1213\n",
      "Epoch 347/1000\n",
      "6/6 - 0s - loss: 77.3587 - val_loss: 504.7652\n",
      "Epoch 348/1000\n",
      "6/6 - 0s - loss: 77.2475 - val_loss: 504.3904\n",
      "Epoch 349/1000\n",
      "6/6 - 0s - loss: 77.1305 - val_loss: 504.0534\n",
      "Epoch 350/1000\n",
      "6/6 - 0s - loss: 77.0207 - val_loss: 503.7216\n",
      "Epoch 351/1000\n",
      "6/6 - 0s - loss: 76.9239 - val_loss: 503.3625\n",
      "Epoch 352/1000\n",
      "6/6 - 0s - loss: 76.8078 - val_loss: 502.9728\n",
      "Epoch 353/1000\n",
      "6/6 - 0s - loss: 76.6787 - val_loss: 502.6266\n",
      "Epoch 354/1000\n",
      "6/6 - 0s - loss: 76.5811 - val_loss: 502.2556\n",
      "Epoch 355/1000\n",
      "6/6 - 0s - loss: 76.4476 - val_loss: 501.9170\n",
      "Epoch 356/1000\n",
      "6/6 - 0s - loss: 76.3357 - val_loss: 501.5642\n",
      "Epoch 357/1000\n",
      "6/6 - 0s - loss: 76.2355 - val_loss: 501.2062\n",
      "Epoch 358/1000\n",
      "6/6 - 0s - loss: 76.1186 - val_loss: 500.8578\n",
      "Epoch 359/1000\n",
      "6/6 - 0s - loss: 76.0016 - val_loss: 500.5173\n",
      "Epoch 360/1000\n",
      "6/6 - 0s - loss: 75.8943 - val_loss: 500.1844\n",
      "Epoch 361/1000\n",
      "6/6 - 0s - loss: 75.7950 - val_loss: 499.8667\n",
      "Epoch 362/1000\n",
      "6/6 - 0s - loss: 75.6933 - val_loss: 499.5371\n",
      "Epoch 363/1000\n",
      "6/6 - 0s - loss: 75.5956 - val_loss: 499.2078\n",
      "Epoch 364/1000\n",
      "6/6 - 0s - loss: 75.4900 - val_loss: 498.8826\n",
      "Epoch 365/1000\n",
      "6/6 - 0s - loss: 75.3747 - val_loss: 498.5638\n",
      "Epoch 366/1000\n",
      "6/6 - 0s - loss: 75.2749 - val_loss: 498.2369\n",
      "Epoch 367/1000\n",
      "6/6 - 0s - loss: 75.1767 - val_loss: 497.8943\n",
      "Epoch 368/1000\n",
      "6/6 - 0s - loss: 75.0754 - val_loss: 497.5444\n",
      "Epoch 369/1000\n",
      "6/6 - 0s - loss: 74.9526 - val_loss: 497.1990\n",
      "Epoch 370/1000\n",
      "6/6 - 0s - loss: 74.8513 - val_loss: 496.8514\n",
      "Epoch 371/1000\n",
      "6/6 - 0s - loss: 74.7547 - val_loss: 496.4963\n",
      "Epoch 372/1000\n",
      "6/6 - 0s - loss: 74.6217 - val_loss: 496.1618\n",
      "Epoch 373/1000\n",
      "6/6 - 0s - loss: 74.5089 - val_loss: 495.8438\n",
      "Epoch 374/1000\n",
      "6/6 - 0s - loss: 74.3946 - val_loss: 495.4840\n",
      "Epoch 375/1000\n",
      "6/6 - 0s - loss: 74.2916 - val_loss: 495.0939\n",
      "Epoch 376/1000\n",
      "6/6 - 0s - loss: 74.1707 - val_loss: 494.7029\n",
      "Epoch 377/1000\n",
      "6/6 - 0s - loss: 74.0541 - val_loss: 494.3592\n",
      "Epoch 378/1000\n",
      "6/6 - 0s - loss: 73.9443 - val_loss: 493.9924\n",
      "Epoch 379/1000\n",
      "6/6 - 0s - loss: 73.8463 - val_loss: 493.5986\n",
      "Epoch 380/1000\n",
      "6/6 - 0s - loss: 73.7119 - val_loss: 493.2634\n",
      "Epoch 381/1000\n",
      "6/6 - 0s - loss: 73.6253 - val_loss: 492.9131\n",
      "Epoch 382/1000\n",
      "6/6 - 0s - loss: 73.4993 - val_loss: 492.6027\n",
      "Epoch 383/1000\n",
      "6/6 - 0s - loss: 73.3937 - val_loss: 492.2769\n",
      "Epoch 384/1000\n",
      "6/6 - 0s - loss: 73.2872 - val_loss: 491.9249\n",
      "Epoch 385/1000\n",
      "6/6 - 0s - loss: 73.1923 - val_loss: 491.5466\n",
      "Epoch 386/1000\n",
      "6/6 - 0s - loss: 73.0809 - val_loss: 491.1773\n",
      "Epoch 387/1000\n",
      "6/6 - 0s - loss: 72.9593 - val_loss: 490.8776\n",
      "Epoch 388/1000\n",
      "6/6 - 0s - loss: 72.8617 - val_loss: 490.5468\n",
      "Epoch 389/1000\n",
      "6/6 - 0s - loss: 72.7612 - val_loss: 490.1953\n",
      "Epoch 390/1000\n",
      "6/6 - 0s - loss: 72.6624 - val_loss: 489.8403\n",
      "Epoch 391/1000\n",
      "6/6 - 0s - loss: 72.5455 - val_loss: 489.5102\n",
      "Epoch 392/1000\n",
      "6/6 - 0s - loss: 72.4477 - val_loss: 489.1727\n",
      "Epoch 393/1000\n",
      "6/6 - 0s - loss: 72.3400 - val_loss: 488.8611\n",
      "Epoch 394/1000\n",
      "6/6 - 0s - loss: 72.2398 - val_loss: 488.5222\n",
      "Epoch 395/1000\n",
      "6/6 - 0s - loss: 72.1386 - val_loss: 488.1631\n",
      "Epoch 396/1000\n",
      "6/6 - 0s - loss: 72.0230 - val_loss: 487.8478\n",
      "Epoch 397/1000\n",
      "6/6 - 0s - loss: 71.9148 - val_loss: 487.5423\n",
      "Epoch 398/1000\n",
      "6/6 - 0s - loss: 71.8304 - val_loss: 487.1450\n",
      "Epoch 399/1000\n",
      "6/6 - 0s - loss: 71.7108 - val_loss: 486.7868\n",
      "Epoch 400/1000\n",
      "6/6 - 0s - loss: 71.5872 - val_loss: 486.4493\n",
      "Epoch 401/1000\n",
      "6/6 - 0s - loss: 71.4921 - val_loss: 486.0971\n",
      "Epoch 402/1000\n",
      "6/6 - 0s - loss: 71.3781 - val_loss: 485.7188\n",
      "Epoch 403/1000\n",
      "6/6 - 0s - loss: 71.2656 - val_loss: 485.3771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404/1000\n",
      "6/6 - 0s - loss: 71.1489 - val_loss: 485.0680\n",
      "Epoch 405/1000\n",
      "6/6 - 0s - loss: 71.0720 - val_loss: 484.7139\n",
      "Epoch 406/1000\n",
      "6/6 - 0s - loss: 70.9521 - val_loss: 484.3781\n",
      "Epoch 407/1000\n",
      "6/6 - 0s - loss: 70.8519 - val_loss: 484.0376\n",
      "Epoch 408/1000\n",
      "6/6 - 0s - loss: 70.7433 - val_loss: 483.7328\n",
      "Epoch 409/1000\n",
      "6/6 - 0s - loss: 70.6431 - val_loss: 483.4054\n",
      "Epoch 410/1000\n",
      "6/6 - 0s - loss: 70.5493 - val_loss: 483.0700\n",
      "Epoch 411/1000\n",
      "6/6 - 0s - loss: 70.4583 - val_loss: 482.7084\n",
      "Epoch 412/1000\n",
      "6/6 - 0s - loss: 70.3418 - val_loss: 482.4234\n",
      "Epoch 413/1000\n",
      "6/6 - 0s - loss: 70.2418 - val_loss: 482.1309\n",
      "Epoch 414/1000\n",
      "6/6 - 0s - loss: 70.1526 - val_loss: 481.7895\n",
      "Epoch 415/1000\n",
      "6/6 - 0s - loss: 70.0599 - val_loss: 481.4734\n",
      "Epoch 416/1000\n",
      "6/6 - 0s - loss: 69.9504 - val_loss: 481.1613\n",
      "Epoch 417/1000\n",
      "6/6 - 0s - loss: 69.8500 - val_loss: 480.8352\n",
      "Epoch 418/1000\n",
      "6/6 - 0s - loss: 69.7448 - val_loss: 480.5363\n",
      "Epoch 419/1000\n",
      "6/6 - 0s - loss: 69.6631 - val_loss: 480.1934\n",
      "Epoch 420/1000\n",
      "6/6 - 0s - loss: 69.5563 - val_loss: 479.8660\n",
      "Epoch 421/1000\n",
      "6/6 - 0s - loss: 69.4480 - val_loss: 479.5595\n",
      "Epoch 422/1000\n",
      "6/6 - 0s - loss: 69.3570 - val_loss: 479.2750\n",
      "Epoch 423/1000\n",
      "6/6 - 0s - loss: 69.2551 - val_loss: 478.9177\n",
      "Epoch 424/1000\n",
      "6/6 - 0s - loss: 69.1638 - val_loss: 478.5859\n",
      "Epoch 425/1000\n",
      "6/6 - 0s - loss: 69.0686 - val_loss: 478.2668\n",
      "Epoch 426/1000\n",
      "6/6 - 0s - loss: 68.9579 - val_loss: 477.9555\n",
      "Epoch 427/1000\n",
      "6/6 - 0s - loss: 68.8497 - val_loss: 477.6545\n",
      "Epoch 428/1000\n",
      "6/6 - 0s - loss: 68.7522 - val_loss: 477.2633\n",
      "Epoch 429/1000\n",
      "6/6 - 0s - loss: 68.6399 - val_loss: 476.8465\n",
      "Epoch 430/1000\n",
      "6/6 - 0s - loss: 68.5267 - val_loss: 476.4867\n",
      "Epoch 431/1000\n",
      "6/6 - 0s - loss: 68.4228 - val_loss: 476.1430\n",
      "Epoch 432/1000\n",
      "6/6 - 0s - loss: 68.3190 - val_loss: 475.7981\n",
      "Epoch 433/1000\n",
      "6/6 - 0s - loss: 68.2187 - val_loss: 475.4337\n",
      "Epoch 434/1000\n",
      "6/6 - 0s - loss: 68.1049 - val_loss: 475.1117\n",
      "Epoch 435/1000\n",
      "6/6 - 0s - loss: 68.0242 - val_loss: 474.7958\n",
      "Epoch 436/1000\n",
      "6/6 - 0s - loss: 67.9088 - val_loss: 474.4612\n",
      "Epoch 437/1000\n",
      "6/6 - 0s - loss: 67.8225 - val_loss: 474.0996\n",
      "Epoch 438/1000\n",
      "6/6 - 0s - loss: 67.7185 - val_loss: 473.7557\n",
      "Epoch 439/1000\n",
      "6/6 - 0s - loss: 67.6247 - val_loss: 473.4067\n",
      "Epoch 440/1000\n",
      "6/6 - 0s - loss: 67.5270 - val_loss: 473.0888\n",
      "Epoch 441/1000\n",
      "6/6 - 0s - loss: 67.4246 - val_loss: 472.7555\n",
      "Epoch 442/1000\n",
      "6/6 - 0s - loss: 67.3303 - val_loss: 472.3993\n",
      "Epoch 443/1000\n",
      "6/6 - 0s - loss: 67.2348 - val_loss: 472.1013\n",
      "Epoch 444/1000\n",
      "6/6 - 0s - loss: 67.1271 - val_loss: 471.7898\n",
      "Epoch 445/1000\n",
      "6/6 - 0s - loss: 67.0535 - val_loss: 471.4706\n",
      "Epoch 446/1000\n",
      "6/6 - 0s - loss: 66.9610 - val_loss: 471.1637\n",
      "Epoch 447/1000\n",
      "6/6 - 0s - loss: 66.8745 - val_loss: 470.8560\n",
      "Epoch 448/1000\n",
      "6/6 - 0s - loss: 66.7783 - val_loss: 470.5668\n",
      "Epoch 449/1000\n",
      "6/6 - 0s - loss: 66.6923 - val_loss: 470.2826\n",
      "Epoch 450/1000\n",
      "6/6 - 0s - loss: 66.5999 - val_loss: 470.0046\n",
      "Epoch 451/1000\n",
      "6/6 - 0s - loss: 66.5112 - val_loss: 469.7147\n",
      "Epoch 452/1000\n",
      "6/6 - 0s - loss: 66.4274 - val_loss: 469.4131\n",
      "Epoch 453/1000\n",
      "6/6 - 0s - loss: 66.3426 - val_loss: 469.1174\n",
      "Epoch 454/1000\n",
      "6/6 - 0s - loss: 66.2630 - val_loss: 468.8045\n",
      "Epoch 455/1000\n",
      "6/6 - 0s - loss: 66.1642 - val_loss: 468.5080\n",
      "Epoch 456/1000\n",
      "6/6 - 0s - loss: 66.0703 - val_loss: 468.2463\n",
      "Epoch 457/1000\n",
      "6/6 - 0s - loss: 65.9831 - val_loss: 467.9535\n",
      "Epoch 458/1000\n",
      "6/6 - 0s - loss: 65.9079 - val_loss: 467.6349\n",
      "Epoch 459/1000\n",
      "6/6 - 0s - loss: 65.8084 - val_loss: 467.3226\n",
      "Epoch 460/1000\n",
      "6/6 - 0s - loss: 65.7245 - val_loss: 467.0088\n",
      "Epoch 461/1000\n",
      "6/6 - 0s - loss: 65.6336 - val_loss: 466.6980\n",
      "Epoch 462/1000\n",
      "6/6 - 0s - loss: 65.5391 - val_loss: 466.4170\n",
      "Epoch 463/1000\n",
      "6/6 - 0s - loss: 65.4516 - val_loss: 466.1473\n",
      "Epoch 464/1000\n",
      "6/6 - 0s - loss: 65.3731 - val_loss: 465.8264\n",
      "Epoch 465/1000\n",
      "6/6 - 0s - loss: 65.2835 - val_loss: 465.5037\n",
      "Epoch 466/1000\n",
      "6/6 - 0s - loss: 65.1795 - val_loss: 465.2421\n",
      "Epoch 467/1000\n",
      "6/6 - 0s - loss: 65.0962 - val_loss: 464.9090\n",
      "Epoch 468/1000\n",
      "6/6 - 0s - loss: 65.0103 - val_loss: 464.6118\n",
      "Epoch 469/1000\n",
      "6/6 - 0s - loss: 64.9250 - val_loss: 464.3130\n",
      "Epoch 470/1000\n",
      "6/6 - 0s - loss: 64.8439 - val_loss: 463.9861\n",
      "Epoch 471/1000\n",
      "6/6 - 0s - loss: 64.7468 - val_loss: 463.7010\n",
      "Epoch 472/1000\n",
      "6/6 - 0s - loss: 64.6577 - val_loss: 463.4073\n",
      "Epoch 473/1000\n",
      "6/6 - 0s - loss: 64.5802 - val_loss: 463.0960\n",
      "Epoch 474/1000\n",
      "6/6 - 0s - loss: 64.4840 - val_loss: 462.8173\n",
      "Epoch 475/1000\n",
      "6/6 - 0s - loss: 64.4115 - val_loss: 462.5074\n",
      "Epoch 476/1000\n",
      "6/6 - 0s - loss: 64.3143 - val_loss: 462.1757\n",
      "Epoch 477/1000\n",
      "6/6 - 0s - loss: 64.2226 - val_loss: 461.9023\n",
      "Epoch 478/1000\n",
      "6/6 - 0s - loss: 64.1460 - val_loss: 461.5860\n",
      "Epoch 479/1000\n",
      "6/6 - 0s - loss: 64.0564 - val_loss: 461.2863\n",
      "Epoch 480/1000\n",
      "6/6 - 0s - loss: 63.9786 - val_loss: 460.9690\n",
      "Epoch 481/1000\n",
      "6/6 - 0s - loss: 63.8782 - val_loss: 460.6844\n",
      "Epoch 482/1000\n",
      "6/6 - 0s - loss: 63.8038 - val_loss: 460.3904\n",
      "Epoch 483/1000\n",
      "6/6 - 0s - loss: 63.7081 - val_loss: 460.1043\n",
      "Epoch 484/1000\n",
      "6/6 - 0s - loss: 63.6245 - val_loss: 459.8215\n",
      "Epoch 485/1000\n",
      "6/6 - 0s - loss: 63.5421 - val_loss: 459.5372\n",
      "Epoch 486/1000\n",
      "6/6 - 0s - loss: 63.4516 - val_loss: 459.2632\n",
      "Epoch 487/1000\n",
      "6/6 - 0s - loss: 63.3809 - val_loss: 458.9367\n",
      "Epoch 488/1000\n",
      "6/6 - 0s - loss: 63.2851 - val_loss: 458.6136\n",
      "Epoch 489/1000\n",
      "6/6 - 0s - loss: 63.1972 - val_loss: 458.3271\n",
      "Epoch 490/1000\n",
      "6/6 - 0s - loss: 63.1046 - val_loss: 458.0411\n",
      "Epoch 491/1000\n",
      "6/6 - 0s - loss: 63.0191 - val_loss: 457.6961\n",
      "Epoch 492/1000\n",
      "6/6 - 0s - loss: 62.9358 - val_loss: 457.3935\n",
      "Epoch 493/1000\n",
      "6/6 - 0s - loss: 62.8436 - val_loss: 457.0512\n",
      "Epoch 494/1000\n",
      "6/6 - 0s - loss: 62.7307 - val_loss: 456.7720\n",
      "Epoch 495/1000\n",
      "6/6 - 0s - loss: 62.6545 - val_loss: 456.5488\n",
      "Epoch 496/1000\n",
      "6/6 - 0s - loss: 62.5770 - val_loss: 456.2015\n",
      "Epoch 497/1000\n",
      "6/6 - 0s - loss: 62.5047 - val_loss: 455.9572\n",
      "Epoch 498/1000\n",
      "6/6 - 0s - loss: 62.4105 - val_loss: 455.6038\n",
      "Epoch 499/1000\n",
      "6/6 - 0s - loss: 62.3246 - val_loss: 455.3767\n",
      "Epoch 500/1000\n",
      "6/6 - 0s - loss: 62.2322 - val_loss: 455.0464\n",
      "Epoch 501/1000\n",
      "6/6 - 0s - loss: 62.1523 - val_loss: 454.8153\n",
      "Epoch 502/1000\n",
      "6/6 - 0s - loss: 62.0698 - val_loss: 454.5133\n",
      "Epoch 503/1000\n",
      "6/6 - 0s - loss: 61.9966 - val_loss: 454.2187\n",
      "Epoch 504/1000\n",
      "6/6 - 0s - loss: 61.9114 - val_loss: 453.9367\n",
      "Epoch 505/1000\n",
      "6/6 - 0s - loss: 61.8155 - val_loss: 453.6628\n",
      "Epoch 506/1000\n",
      "6/6 - 0s - loss: 61.7445 - val_loss: 453.4032\n",
      "Epoch 507/1000\n",
      "6/6 - 0s - loss: 61.6765 - val_loss: 453.1006\n",
      "Epoch 508/1000\n",
      "6/6 - 0s - loss: 61.5820 - val_loss: 452.8631\n",
      "Epoch 509/1000\n",
      "6/6 - 0s - loss: 61.5129 - val_loss: 452.5791\n",
      "Epoch 510/1000\n",
      "6/6 - 0s - loss: 61.4271 - val_loss: 452.3133\n",
      "Epoch 511/1000\n",
      "6/6 - 0s - loss: 61.3406 - val_loss: 452.0198\n",
      "Epoch 512/1000\n",
      "6/6 - 0s - loss: 61.2542 - val_loss: 451.7316\n",
      "Epoch 513/1000\n",
      "6/6 - 0s - loss: 61.1677 - val_loss: 451.4101\n",
      "Epoch 514/1000\n",
      "6/6 - 0s - loss: 61.0839 - val_loss: 451.1140\n",
      "Epoch 515/1000\n",
      "6/6 - 0s - loss: 60.9896 - val_loss: 450.7972\n",
      "Epoch 516/1000\n",
      "6/6 - 0s - loss: 60.9062 - val_loss: 450.4695\n",
      "Epoch 517/1000\n",
      "6/6 - 0s - loss: 60.8257 - val_loss: 450.1974\n",
      "Epoch 518/1000\n",
      "6/6 - 0s - loss: 60.7435 - val_loss: 449.8739\n",
      "Epoch 519/1000\n",
      "6/6 - 0s - loss: 60.6467 - val_loss: 449.6428\n",
      "Epoch 520/1000\n",
      "6/6 - 0s - loss: 60.5736 - val_loss: 449.3000\n",
      "Epoch 521/1000\n",
      "6/6 - 0s - loss: 60.4896 - val_loss: 449.0391\n",
      "Epoch 522/1000\n",
      "6/6 - 0s - loss: 60.3997 - val_loss: 448.7611\n",
      "Epoch 523/1000\n",
      "6/6 - 0s - loss: 60.3330 - val_loss: 448.4435\n",
      "Epoch 524/1000\n",
      "6/6 - 0s - loss: 60.2438 - val_loss: 448.1804\n",
      "Epoch 525/1000\n",
      "6/6 - 0s - loss: 60.1692 - val_loss: 447.8951\n",
      "Epoch 526/1000\n",
      "6/6 - 0s - loss: 60.0891 - val_loss: 447.6426\n",
      "Epoch 527/1000\n",
      "6/6 - 0s - loss: 60.0106 - val_loss: 447.3940\n",
      "Epoch 528/1000\n",
      "6/6 - 0s - loss: 59.9370 - val_loss: 447.1242\n",
      "Epoch 529/1000\n",
      "6/6 - 0s - loss: 59.8698 - val_loss: 446.8576\n",
      "Epoch 530/1000\n",
      "6/6 - 0s - loss: 59.7935 - val_loss: 446.5800\n",
      "Epoch 531/1000\n",
      "6/6 - 0s - loss: 59.7094 - val_loss: 446.3354\n",
      "Epoch 532/1000\n",
      "6/6 - 0s - loss: 59.6150 - val_loss: 445.9706\n",
      "Epoch 533/1000\n",
      "6/6 - 0s - loss: 59.5330 - val_loss: 445.8170\n",
      "Epoch 534/1000\n",
      "6/6 - 0s - loss: 59.4461 - val_loss: 445.3929\n",
      "Epoch 535/1000\n",
      "6/6 - 0s - loss: 59.3582 - val_loss: 445.2246\n",
      "Epoch 536/1000\n",
      "6/6 - 0s - loss: 59.2779 - val_loss: 444.9426\n",
      "Epoch 537/1000\n",
      "6/6 - 0s - loss: 59.1993 - val_loss: 444.7140\n",
      "Epoch 538/1000\n",
      "6/6 - 0s - loss: 59.1352 - val_loss: 444.4719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 539/1000\n",
      "6/6 - 0s - loss: 59.0530 - val_loss: 444.1579\n",
      "Epoch 540/1000\n",
      "6/6 - 0s - loss: 58.9762 - val_loss: 443.9601\n",
      "Epoch 541/1000\n",
      "6/6 - 0s - loss: 58.9144 - val_loss: 443.6216\n",
      "Epoch 542/1000\n",
      "6/6 - 0s - loss: 58.8220 - val_loss: 443.4428\n",
      "Epoch 543/1000\n",
      "6/6 - 0s - loss: 58.7478 - val_loss: 443.1073\n",
      "Epoch 544/1000\n",
      "6/6 - 0s - loss: 58.6792 - val_loss: 442.8755\n",
      "Epoch 545/1000\n",
      "6/6 - 0s - loss: 58.5934 - val_loss: 442.5402\n",
      "Epoch 546/1000\n",
      "6/6 - 0s - loss: 58.5042 - val_loss: 442.2871\n",
      "Epoch 547/1000\n",
      "6/6 - 0s - loss: 58.4286 - val_loss: 441.9901\n",
      "Epoch 548/1000\n",
      "6/6 - 0s - loss: 58.3366 - val_loss: 441.7731\n",
      "Epoch 549/1000\n",
      "6/6 - 0s - loss: 58.2792 - val_loss: 441.4150\n",
      "Epoch 550/1000\n",
      "6/6 - 0s - loss: 58.1918 - val_loss: 441.1602\n",
      "Epoch 551/1000\n",
      "6/6 - 0s - loss: 58.1048 - val_loss: 440.8435\n",
      "Epoch 552/1000\n",
      "6/6 - 0s - loss: 58.0281 - val_loss: 440.6266\n",
      "Epoch 553/1000\n",
      "6/6 - 0s - loss: 57.9559 - val_loss: 440.2718\n",
      "Epoch 554/1000\n",
      "6/6 - 0s - loss: 57.8655 - val_loss: 440.1635\n",
      "Epoch 555/1000\n",
      "6/6 - 0s - loss: 57.7956 - val_loss: 439.7196\n",
      "Epoch 556/1000\n",
      "6/6 - 0s - loss: 57.7094 - val_loss: 439.5049\n",
      "Epoch 557/1000\n",
      "6/6 - 0s - loss: 57.6386 - val_loss: 439.1720\n",
      "Epoch 558/1000\n",
      "6/6 - 0s - loss: 57.5484 - val_loss: 438.9559\n",
      "Epoch 559/1000\n",
      "6/6 - 0s - loss: 57.4718 - val_loss: 438.6143\n",
      "Epoch 560/1000\n",
      "6/6 - 0s - loss: 57.3896 - val_loss: 438.4177\n",
      "Epoch 561/1000\n",
      "6/6 - 0s - loss: 57.3154 - val_loss: 438.1114\n",
      "Epoch 562/1000\n",
      "6/6 - 0s - loss: 57.2416 - val_loss: 437.9223\n",
      "Epoch 563/1000\n",
      "6/6 - 0s - loss: 57.1750 - val_loss: 437.5803\n",
      "Epoch 564/1000\n",
      "6/6 - 0s - loss: 57.0931 - val_loss: 437.4266\n",
      "Epoch 565/1000\n",
      "6/6 - 0s - loss: 57.0175 - val_loss: 437.0680\n",
      "Epoch 566/1000\n",
      "6/6 - 0s - loss: 56.9465 - val_loss: 436.8621\n",
      "Epoch 567/1000\n",
      "6/6 - 0s - loss: 56.8562 - val_loss: 436.4924\n",
      "Epoch 568/1000\n",
      "6/6 - 0s - loss: 56.7751 - val_loss: 436.2766\n",
      "Epoch 569/1000\n",
      "6/6 - 0s - loss: 56.6989 - val_loss: 435.9302\n",
      "Epoch 570/1000\n",
      "6/6 - 0s - loss: 56.6175 - val_loss: 435.7527\n",
      "Epoch 571/1000\n",
      "6/6 - 0s - loss: 56.5511 - val_loss: 435.4333\n",
      "Epoch 572/1000\n",
      "6/6 - 0s - loss: 56.4731 - val_loss: 435.2540\n",
      "Epoch 573/1000\n",
      "6/6 - 0s - loss: 56.4037 - val_loss: 434.9303\n",
      "Epoch 574/1000\n",
      "6/6 - 0s - loss: 56.3271 - val_loss: 434.7249\n",
      "Epoch 575/1000\n",
      "6/6 - 0s - loss: 56.2586 - val_loss: 434.4595\n",
      "Epoch 576/1000\n",
      "6/6 - 0s - loss: 56.1926 - val_loss: 434.2030\n",
      "Epoch 577/1000\n",
      "6/6 - 0s - loss: 56.1133 - val_loss: 433.9572\n",
      "Epoch 578/1000\n",
      "6/6 - 0s - loss: 56.0438 - val_loss: 433.7014\n",
      "Epoch 579/1000\n",
      "6/6 - 0s - loss: 55.9710 - val_loss: 433.4693\n",
      "Epoch 580/1000\n",
      "6/6 - 0s - loss: 55.9071 - val_loss: 433.1805\n",
      "Epoch 581/1000\n",
      "6/6 - 0s - loss: 55.8377 - val_loss: 432.9336\n",
      "Epoch 582/1000\n",
      "6/6 - 0s - loss: 55.7636 - val_loss: 432.6679\n",
      "Epoch 583/1000\n",
      "6/6 - 0s - loss: 55.6871 - val_loss: 432.4170\n",
      "Epoch 584/1000\n",
      "6/6 - 0s - loss: 55.6097 - val_loss: 432.1995\n",
      "Epoch 585/1000\n",
      "6/6 - 0s - loss: 55.5493 - val_loss: 431.8872\n",
      "Epoch 586/1000\n",
      "6/6 - 0s - loss: 55.4696 - val_loss: 431.6868\n",
      "Epoch 587/1000\n",
      "6/6 - 0s - loss: 55.4075 - val_loss: 431.3491\n",
      "Epoch 588/1000\n",
      "6/6 - 0s - loss: 55.3243 - val_loss: 431.1758\n",
      "Epoch 589/1000\n",
      "6/6 - 0s - loss: 55.2647 - val_loss: 430.8259\n",
      "Epoch 590/1000\n",
      "6/6 - 0s - loss: 55.1789 - val_loss: 430.6848\n",
      "Epoch 591/1000\n",
      "6/6 - 0s - loss: 55.1208 - val_loss: 430.2968\n",
      "Epoch 592/1000\n",
      "6/6 - 0s - loss: 55.0453 - val_loss: 430.1599\n",
      "Epoch 593/1000\n",
      "6/6 - 0s - loss: 54.9754 - val_loss: 429.7275\n",
      "Epoch 594/1000\n",
      "6/6 - 0s - loss: 54.9084 - val_loss: 429.6753\n",
      "Epoch 595/1000\n",
      "6/6 - 0s - loss: 54.8353 - val_loss: 429.1958\n",
      "Epoch 596/1000\n",
      "6/6 - 0s - loss: 54.7514 - val_loss: 429.1697\n",
      "Epoch 597/1000\n",
      "6/6 - 0s - loss: 54.6971 - val_loss: 428.6718\n",
      "Epoch 598/1000\n",
      "6/6 - 0s - loss: 54.6192 - val_loss: 428.6580\n",
      "Epoch 599/1000\n",
      "6/6 - 0s - loss: 54.5448 - val_loss: 428.0918\n",
      "Epoch 600/1000\n",
      "6/6 - 0s - loss: 54.4759 - val_loss: 428.1506\n",
      "Epoch 601/1000\n",
      "6/6 - 0s - loss: 54.4058 - val_loss: 427.5715\n",
      "Epoch 602/1000\n",
      "6/6 - 0s - loss: 54.3361 - val_loss: 427.6972\n",
      "Epoch 603/1000\n",
      "6/6 - 0s - loss: 54.2619 - val_loss: 426.9590\n",
      "Epoch 604/1000\n",
      "6/6 - 0s - loss: 54.2076 - val_loss: 427.1705\n",
      "Epoch 605/1000\n",
      "6/6 - 0s - loss: 54.1379 - val_loss: 426.4620\n",
      "Epoch 606/1000\n",
      "6/6 - 0s - loss: 54.0622 - val_loss: 426.7596\n",
      "Epoch 607/1000\n",
      "6/6 - 0s - loss: 54.0063 - val_loss: 425.7820\n",
      "Epoch 608/1000\n",
      "6/6 - 0s - loss: 53.9248 - val_loss: 426.2515\n",
      "Epoch 609/1000\n",
      "6/6 - 0s - loss: 53.8454 - val_loss: 425.1988\n",
      "Epoch 610/1000\n",
      "6/6 - 0s - loss: 53.7861 - val_loss: 425.7513\n",
      "Epoch 611/1000\n",
      "6/6 - 0s - loss: 53.7130 - val_loss: 424.6094\n",
      "Epoch 612/1000\n",
      "6/6 - 0s - loss: 53.6323 - val_loss: 425.2993\n",
      "Epoch 613/1000\n",
      "6/6 - 0s - loss: 53.5661 - val_loss: 423.9887\n",
      "Epoch 614/1000\n",
      "6/6 - 0s - loss: 53.4900 - val_loss: 424.5035\n",
      "Epoch 615/1000\n",
      "6/6 - 0s - loss: 53.4241 - val_loss: 423.5521\n",
      "Epoch 616/1000\n",
      "6/6 - 0s - loss: 53.3427 - val_loss: 423.8236\n",
      "Epoch 617/1000\n",
      "6/6 - 0s - loss: 53.2803 - val_loss: 423.2513\n",
      "Epoch 618/1000\n",
      "6/6 - 0s - loss: 53.1862 - val_loss: 422.9895\n",
      "Epoch 619/1000\n",
      "6/6 - 0s - loss: 53.1115 - val_loss: 423.0392\n",
      "Epoch 620/1000\n",
      "6/6 - 0s - loss: 53.0477 - val_loss: 422.3293\n",
      "Epoch 621/1000\n",
      "6/6 - 0s - loss: 52.9688 - val_loss: 422.6228\n",
      "Epoch 622/1000\n",
      "6/6 - 0s - loss: 52.9209 - val_loss: 421.7870\n",
      "Epoch 623/1000\n",
      "6/6 - 0s - loss: 52.8390 - val_loss: 421.9394\n",
      "Epoch 624/1000\n",
      "6/6 - 0s - loss: 52.7706 - val_loss: 421.4698\n",
      "Epoch 625/1000\n",
      "6/6 - 0s - loss: 52.7027 - val_loss: 421.2981\n",
      "Epoch 626/1000\n",
      "6/6 - 0s - loss: 52.6413 - val_loss: 421.0511\n",
      "Epoch 627/1000\n",
      "6/6 - 0s - loss: 52.5782 - val_loss: 420.8045\n",
      "Epoch 628/1000\n",
      "6/6 - 0s - loss: 52.5090 - val_loss: 420.5602\n",
      "Epoch 629/1000\n",
      "6/6 - 0s - loss: 52.4484 - val_loss: 420.2898\n",
      "Epoch 630/1000\n",
      "6/6 - 0s - loss: 52.3820 - val_loss: 420.0716\n",
      "Epoch 631/1000\n",
      "6/6 - 0s - loss: 52.3111 - val_loss: 419.7619\n",
      "Epoch 632/1000\n",
      "6/6 - 0s - loss: 52.2547 - val_loss: 419.5573\n",
      "Epoch 633/1000\n",
      "6/6 - 0s - loss: 52.1758 - val_loss: 419.2456\n",
      "Epoch 634/1000\n",
      "6/6 - 0s - loss: 52.1200 - val_loss: 419.0069\n",
      "Epoch 635/1000\n",
      "6/6 - 0s - loss: 52.0431 - val_loss: 418.7198\n",
      "Epoch 636/1000\n",
      "6/6 - 0s - loss: 51.9701 - val_loss: 418.4751\n",
      "Epoch 637/1000\n",
      "6/6 - 0s - loss: 51.9005 - val_loss: 418.1056\n",
      "Epoch 638/1000\n",
      "6/6 - 0s - loss: 51.8352 - val_loss: 417.8741\n",
      "Epoch 639/1000\n",
      "6/6 - 0s - loss: 51.7522 - val_loss: 417.4622\n",
      "Epoch 640/1000\n",
      "6/6 - 0s - loss: 51.6736 - val_loss: 417.1346\n",
      "Epoch 641/1000\n",
      "6/6 - 0s - loss: 51.5968 - val_loss: 416.9545\n",
      "Epoch 642/1000\n",
      "6/6 - 0s - loss: 51.5289 - val_loss: 416.5522\n",
      "Epoch 643/1000\n",
      "6/6 - 0s - loss: 51.4615 - val_loss: 416.3527\n",
      "Epoch 644/1000\n",
      "6/6 - 0s - loss: 51.3901 - val_loss: 415.9334\n",
      "Epoch 645/1000\n",
      "6/6 - 0s - loss: 51.3116 - val_loss: 415.7271\n",
      "Epoch 646/1000\n",
      "6/6 - 0s - loss: 51.2453 - val_loss: 415.4256\n",
      "Epoch 647/1000\n",
      "6/6 - 0s - loss: 51.1615 - val_loss: 415.0859\n",
      "Epoch 648/1000\n",
      "6/6 - 0s - loss: 51.0823 - val_loss: 414.8676\n",
      "Epoch 649/1000\n",
      "6/6 - 0s - loss: 51.0239 - val_loss: 414.6713\n",
      "Epoch 650/1000\n",
      "6/6 - 0s - loss: 50.9436 - val_loss: 414.3130\n",
      "Epoch 651/1000\n",
      "6/6 - 0s - loss: 50.8750 - val_loss: 414.1449\n",
      "Epoch 652/1000\n",
      "6/6 - 0s - loss: 50.8028 - val_loss: 413.7975\n",
      "Epoch 653/1000\n",
      "6/6 - 0s - loss: 50.7327 - val_loss: 413.6031\n",
      "Epoch 654/1000\n",
      "6/6 - 0s - loss: 50.6601 - val_loss: 413.3962\n",
      "Epoch 655/1000\n",
      "6/6 - 0s - loss: 50.5962 - val_loss: 413.1115\n",
      "Epoch 656/1000\n",
      "6/6 - 0s - loss: 50.5176 - val_loss: 412.9959\n",
      "Epoch 657/1000\n",
      "6/6 - 0s - loss: 50.4724 - val_loss: 412.6301\n",
      "Epoch 658/1000\n",
      "6/6 - 0s - loss: 50.3766 - val_loss: 412.4841\n",
      "Epoch 659/1000\n",
      "6/6 - 0s - loss: 50.3094 - val_loss: 412.1971\n",
      "Epoch 660/1000\n",
      "6/6 - 0s - loss: 50.2480 - val_loss: 412.0219\n",
      "Epoch 661/1000\n",
      "6/6 - 0s - loss: 50.1768 - val_loss: 411.7513\n",
      "Epoch 662/1000\n",
      "6/6 - 0s - loss: 50.1061 - val_loss: 411.5804\n",
      "Epoch 663/1000\n",
      "6/6 - 0s - loss: 50.0430 - val_loss: 411.3472\n",
      "Epoch 664/1000\n",
      "6/6 - 0s - loss: 49.9779 - val_loss: 411.1324\n",
      "Epoch 665/1000\n",
      "6/6 - 0s - loss: 49.9136 - val_loss: 410.8497\n",
      "Epoch 666/1000\n",
      "6/6 - 0s - loss: 49.8347 - val_loss: 410.6589\n",
      "Epoch 667/1000\n",
      "6/6 - 0s - loss: 49.7703 - val_loss: 410.3727\n",
      "Epoch 668/1000\n",
      "6/6 - 0s - loss: 49.7043 - val_loss: 410.2041\n",
      "Epoch 669/1000\n",
      "6/6 - 0s - loss: 49.6507 - val_loss: 409.8839\n",
      "Epoch 670/1000\n",
      "6/6 - 0s - loss: 49.5646 - val_loss: 409.7818\n",
      "Epoch 671/1000\n",
      "6/6 - 0s - loss: 49.5162 - val_loss: 409.4327\n",
      "Epoch 672/1000\n",
      "6/6 - 0s - loss: 49.4524 - val_loss: 409.2763\n",
      "Epoch 673/1000\n",
      "6/6 - 0s - loss: 49.3787 - val_loss: 408.9573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 674/1000\n",
      "6/6 - 0s - loss: 49.3068 - val_loss: 408.8451\n",
      "Epoch 675/1000\n",
      "6/6 - 0s - loss: 49.2472 - val_loss: 408.5107\n",
      "Epoch 676/1000\n",
      "6/6 - 0s - loss: 49.1761 - val_loss: 408.3915\n",
      "Epoch 677/1000\n",
      "6/6 - 0s - loss: 49.1162 - val_loss: 408.0753\n",
      "Epoch 678/1000\n",
      "6/6 - 0s - loss: 49.0685 - val_loss: 407.9312\n",
      "Epoch 679/1000\n",
      "6/6 - 0s - loss: 48.9907 - val_loss: 407.6313\n",
      "Epoch 680/1000\n",
      "6/6 - 0s - loss: 48.9377 - val_loss: 407.4749\n",
      "Epoch 681/1000\n",
      "6/6 - 0s - loss: 48.8681 - val_loss: 407.1949\n",
      "Epoch 682/1000\n",
      "6/6 - 0s - loss: 48.8069 - val_loss: 407.0720\n",
      "Epoch 683/1000\n",
      "6/6 - 0s - loss: 48.7495 - val_loss: 406.7479\n",
      "Epoch 684/1000\n",
      "6/6 - 0s - loss: 48.6849 - val_loss: 406.6364\n",
      "Epoch 685/1000\n",
      "6/6 - 0s - loss: 48.6274 - val_loss: 406.2697\n",
      "Epoch 686/1000\n",
      "6/6 - 0s - loss: 48.5588 - val_loss: 406.1782\n",
      "Epoch 687/1000\n",
      "6/6 - 0s - loss: 48.4993 - val_loss: 405.7961\n",
      "Epoch 688/1000\n",
      "6/6 - 0s - loss: 48.4309 - val_loss: 405.7549\n",
      "Epoch 689/1000\n",
      "6/6 - 0s - loss: 48.3679 - val_loss: 405.3240\n",
      "Epoch 690/1000\n",
      "6/6 - 0s - loss: 48.3155 - val_loss: 405.3181\n",
      "Epoch 691/1000\n",
      "6/6 - 0s - loss: 48.2470 - val_loss: 404.7600\n",
      "Epoch 692/1000\n",
      "6/6 - 0s - loss: 48.1794 - val_loss: 404.9073\n",
      "Epoch 693/1000\n",
      "6/6 - 0s - loss: 48.1167 - val_loss: 404.3003\n",
      "Epoch 694/1000\n",
      "6/6 - 0s - loss: 48.0567 - val_loss: 404.4715\n",
      "Epoch 695/1000\n",
      "6/6 - 0s - loss: 48.0106 - val_loss: 403.8754\n",
      "Epoch 696/1000\n",
      "6/6 - 0s - loss: 47.9385 - val_loss: 404.0533\n",
      "Epoch 697/1000\n",
      "6/6 - 0s - loss: 47.8912 - val_loss: 403.4295\n",
      "Epoch 698/1000\n",
      "6/6 - 0s - loss: 47.8245 - val_loss: 403.4705\n",
      "Epoch 699/1000\n",
      "6/6 - 0s - loss: 47.7685 - val_loss: 403.0495\n",
      "Epoch 700/1000\n",
      "6/6 - 0s - loss: 47.7059 - val_loss: 402.9529\n",
      "Epoch 701/1000\n",
      "6/6 - 0s - loss: 47.6364 - val_loss: 402.6262\n",
      "Epoch 702/1000\n",
      "6/6 - 0s - loss: 47.5668 - val_loss: 402.4459\n",
      "Epoch 703/1000\n",
      "6/6 - 0s - loss: 47.5039 - val_loss: 402.1671\n",
      "Epoch 704/1000\n",
      "6/6 - 0s - loss: 47.4509 - val_loss: 401.8401\n",
      "Epoch 705/1000\n",
      "6/6 - 0s - loss: 47.3740 - val_loss: 401.6668\n",
      "Epoch 706/1000\n",
      "6/6 - 0s - loss: 47.3062 - val_loss: 401.3658\n",
      "Epoch 707/1000\n",
      "6/6 - 0s - loss: 47.2565 - val_loss: 401.1811\n",
      "Epoch 708/1000\n",
      "6/6 - 0s - loss: 47.1913 - val_loss: 400.8068\n",
      "Epoch 709/1000\n",
      "6/6 - 0s - loss: 47.1378 - val_loss: 400.7134\n",
      "Epoch 710/1000\n",
      "6/6 - 0s - loss: 47.0668 - val_loss: 400.3828\n",
      "Epoch 711/1000\n",
      "6/6 - 0s - loss: 47.0163 - val_loss: 400.1984\n",
      "Epoch 712/1000\n",
      "6/6 - 0s - loss: 46.9530 - val_loss: 399.9302\n",
      "Epoch 713/1000\n",
      "6/6 - 0s - loss: 46.9007 - val_loss: 399.7615\n",
      "Epoch 714/1000\n",
      "6/6 - 0s - loss: 46.8512 - val_loss: 399.3972\n",
      "Epoch 715/1000\n",
      "6/6 - 0s - loss: 46.7867 - val_loss: 399.2958\n",
      "Epoch 716/1000\n",
      "6/6 - 0s - loss: 46.7285 - val_loss: 398.9348\n",
      "Epoch 717/1000\n",
      "6/6 - 0s - loss: 46.6628 - val_loss: 398.7487\n",
      "Epoch 718/1000\n",
      "6/6 - 0s - loss: 46.6169 - val_loss: 398.4319\n",
      "Epoch 719/1000\n",
      "6/6 - 0s - loss: 46.5351 - val_loss: 398.2173\n",
      "Epoch 720/1000\n",
      "6/6 - 0s - loss: 46.4764 - val_loss: 397.8698\n",
      "Epoch 721/1000\n",
      "6/6 - 0s - loss: 46.4256 - val_loss: 397.7754\n",
      "Epoch 722/1000\n",
      "6/6 - 0s - loss: 46.3548 - val_loss: 397.2073\n",
      "Epoch 723/1000\n",
      "6/6 - 0s - loss: 46.2944 - val_loss: 397.2524\n",
      "Epoch 724/1000\n",
      "6/6 - 0s - loss: 46.2303 - val_loss: 396.6785\n",
      "Epoch 725/1000\n",
      "6/6 - 0s - loss: 46.1556 - val_loss: 396.7320\n",
      "Epoch 726/1000\n",
      "6/6 - 0s - loss: 46.0969 - val_loss: 396.1711\n",
      "Epoch 727/1000\n",
      "6/6 - 0s - loss: 46.0397 - val_loss: 396.1783\n",
      "Epoch 728/1000\n",
      "6/6 - 0s - loss: 45.9728 - val_loss: 395.8299\n",
      "Epoch 729/1000\n",
      "6/6 - 0s - loss: 45.9300 - val_loss: 395.6594\n",
      "Epoch 730/1000\n",
      "6/6 - 0s - loss: 45.8484 - val_loss: 395.4026\n",
      "Epoch 731/1000\n",
      "6/6 - 0s - loss: 45.8113 - val_loss: 395.1894\n",
      "Epoch 732/1000\n",
      "6/6 - 0s - loss: 45.7336 - val_loss: 394.9000\n",
      "Epoch 733/1000\n",
      "6/6 - 0s - loss: 45.6629 - val_loss: 394.7708\n",
      "Epoch 734/1000\n",
      "6/6 - 0s - loss: 45.6068 - val_loss: 394.4113\n",
      "Epoch 735/1000\n",
      "6/6 - 0s - loss: 45.5465 - val_loss: 394.2763\n",
      "Epoch 736/1000\n",
      "6/6 - 0s - loss: 45.4778 - val_loss: 393.8379\n",
      "Epoch 737/1000\n",
      "6/6 - 0s - loss: 45.4141 - val_loss: 393.8228\n",
      "Epoch 738/1000\n",
      "6/6 - 0s - loss: 45.3628 - val_loss: 393.4204\n",
      "Epoch 739/1000\n",
      "6/6 - 0s - loss: 45.2974 - val_loss: 393.2000\n",
      "Epoch 740/1000\n",
      "6/6 - 0s - loss: 45.2248 - val_loss: 393.1237\n",
      "Epoch 741/1000\n",
      "6/6 - 0s - loss: 45.1794 - val_loss: 392.6229\n",
      "Epoch 742/1000\n",
      "6/6 - 0s - loss: 45.1102 - val_loss: 392.7578\n",
      "Epoch 743/1000\n",
      "6/6 - 0s - loss: 45.0580 - val_loss: 392.0065\n",
      "Epoch 744/1000\n",
      "6/6 - 0s - loss: 44.9896 - val_loss: 392.4046\n",
      "Epoch 745/1000\n",
      "6/6 - 0s - loss: 44.9383 - val_loss: 391.5471\n",
      "Epoch 746/1000\n",
      "6/6 - 0s - loss: 44.8666 - val_loss: 391.7279\n",
      "Epoch 747/1000\n",
      "6/6 - 0s - loss: 44.8015 - val_loss: 391.0200\n",
      "Epoch 748/1000\n",
      "6/6 - 0s - loss: 44.7318 - val_loss: 391.3561\n",
      "Epoch 749/1000\n",
      "6/6 - 0s - loss: 44.6755 - val_loss: 390.4014\n",
      "Epoch 750/1000\n",
      "6/6 - 0s - loss: 44.6010 - val_loss: 390.8242\n",
      "Epoch 751/1000\n",
      "6/6 - 0s - loss: 44.5348 - val_loss: 389.8433\n",
      "Epoch 752/1000\n",
      "6/6 - 0s - loss: 44.4957 - val_loss: 390.1580\n",
      "Epoch 753/1000\n",
      "6/6 - 0s - loss: 44.4161 - val_loss: 389.6721\n",
      "Epoch 754/1000\n",
      "6/6 - 0s - loss: 44.3561 - val_loss: 389.5641\n",
      "Epoch 755/1000\n",
      "6/6 - 0s - loss: 44.2892 - val_loss: 389.2572\n",
      "Epoch 756/1000\n",
      "6/6 - 0s - loss: 44.2133 - val_loss: 388.9045\n",
      "Epoch 757/1000\n",
      "6/6 - 0s - loss: 44.1496 - val_loss: 388.8075\n",
      "Epoch 758/1000\n",
      "6/6 - 0s - loss: 44.0733 - val_loss: 388.4830\n",
      "Epoch 759/1000\n",
      "6/6 - 0s - loss: 44.0077 - val_loss: 388.3337\n",
      "Epoch 760/1000\n",
      "6/6 - 0s - loss: 43.9379 - val_loss: 388.0200\n",
      "Epoch 761/1000\n",
      "6/6 - 0s - loss: 43.8836 - val_loss: 387.9159\n",
      "Epoch 762/1000\n",
      "6/6 - 0s - loss: 43.8107 - val_loss: 387.6408\n",
      "Epoch 763/1000\n",
      "6/6 - 0s - loss: 43.7459 - val_loss: 387.6485\n",
      "Epoch 764/1000\n",
      "6/6 - 0s - loss: 43.6934 - val_loss: 387.2685\n",
      "Epoch 765/1000\n",
      "6/6 - 0s - loss: 43.6373 - val_loss: 387.3007\n",
      "Epoch 766/1000\n",
      "6/6 - 0s - loss: 43.5756 - val_loss: 386.8794\n",
      "Epoch 767/1000\n",
      "6/6 - 0s - loss: 43.5250 - val_loss: 387.0147\n",
      "Epoch 768/1000\n",
      "6/6 - 0s - loss: 43.4598 - val_loss: 386.5616\n",
      "Epoch 769/1000\n",
      "6/6 - 0s - loss: 43.4033 - val_loss: 386.6960\n",
      "Epoch 770/1000\n",
      "6/6 - 0s - loss: 43.3531 - val_loss: 386.2052\n",
      "Epoch 771/1000\n",
      "6/6 - 0s - loss: 43.2944 - val_loss: 386.2840\n",
      "Epoch 772/1000\n",
      "6/6 - 0s - loss: 43.2423 - val_loss: 385.9465\n",
      "Epoch 773/1000\n",
      "6/6 - 0s - loss: 43.1761 - val_loss: 385.9979\n",
      "Epoch 774/1000\n",
      "6/6 - 0s - loss: 43.1297 - val_loss: 385.5723\n",
      "Epoch 775/1000\n",
      "6/6 - 0s - loss: 43.0708 - val_loss: 385.6229\n",
      "Epoch 776/1000\n",
      "6/6 - 0s - loss: 43.0123 - val_loss: 385.3120\n",
      "Epoch 777/1000\n",
      "6/6 - 0s - loss: 42.9611 - val_loss: 385.2746\n",
      "Epoch 778/1000\n",
      "6/6 - 0s - loss: 42.9092 - val_loss: 384.9220\n",
      "Epoch 779/1000\n",
      "6/6 - 0s - loss: 42.8459 - val_loss: 384.8845\n",
      "Epoch 780/1000\n",
      "6/6 - 0s - loss: 42.7818 - val_loss: 384.5938\n",
      "Epoch 781/1000\n",
      "6/6 - 0s - loss: 42.7220 - val_loss: 384.4436\n",
      "Epoch 782/1000\n",
      "6/6 - 0s - loss: 42.6677 - val_loss: 384.1769\n",
      "Epoch 783/1000\n",
      "6/6 - 0s - loss: 42.5978 - val_loss: 384.0134\n",
      "Epoch 784/1000\n",
      "6/6 - 0s - loss: 42.5424 - val_loss: 383.7528\n",
      "Epoch 785/1000\n",
      "6/6 - 0s - loss: 42.4749 - val_loss: 383.5998\n",
      "Epoch 786/1000\n",
      "6/6 - 0s - loss: 42.4105 - val_loss: 383.3985\n",
      "Epoch 787/1000\n",
      "6/6 - 0s - loss: 42.3595 - val_loss: 383.2357\n",
      "Epoch 788/1000\n",
      "6/6 - 0s - loss: 42.3075 - val_loss: 383.0388\n",
      "Epoch 789/1000\n",
      "6/6 - 0s - loss: 42.2603 - val_loss: 382.8398\n",
      "Epoch 790/1000\n",
      "6/6 - 0s - loss: 42.1936 - val_loss: 382.7061\n",
      "Epoch 791/1000\n",
      "6/6 - 0s - loss: 42.1513 - val_loss: 382.4938\n",
      "Epoch 792/1000\n",
      "6/6 - 0s - loss: 42.0907 - val_loss: 382.3510\n",
      "Epoch 793/1000\n",
      "6/6 - 0s - loss: 42.0353 - val_loss: 382.1543\n",
      "Epoch 794/1000\n",
      "6/6 - 0s - loss: 41.9855 - val_loss: 381.9870\n",
      "Epoch 795/1000\n",
      "6/6 - 0s - loss: 41.9323 - val_loss: 381.7978\n",
      "Epoch 796/1000\n",
      "6/6 - 0s - loss: 41.8734 - val_loss: 381.6068\n",
      "Epoch 797/1000\n",
      "6/6 - 0s - loss: 41.8255 - val_loss: 381.4040\n",
      "Epoch 798/1000\n",
      "6/6 - 0s - loss: 41.7639 - val_loss: 381.1847\n",
      "Epoch 799/1000\n",
      "6/6 - 0s - loss: 41.7077 - val_loss: 380.9882\n",
      "Epoch 800/1000\n",
      "6/6 - 0s - loss: 41.6391 - val_loss: 380.8427\n",
      "Epoch 801/1000\n",
      "6/6 - 0s - loss: 41.5931 - val_loss: 380.5955\n",
      "Epoch 802/1000\n",
      "6/6 - 0s - loss: 41.5435 - val_loss: 380.4053\n",
      "Epoch 803/1000\n",
      "6/6 - 0s - loss: 41.4778 - val_loss: 380.3088\n",
      "Epoch 804/1000\n",
      "6/6 - 0s - loss: 41.4234 - val_loss: 380.0022\n",
      "Epoch 805/1000\n",
      "6/6 - 0s - loss: 41.3703 - val_loss: 379.9605\n",
      "Epoch 806/1000\n",
      "6/6 - 0s - loss: 41.3227 - val_loss: 379.6760\n",
      "Epoch 807/1000\n",
      "6/6 - 0s - loss: 41.2634 - val_loss: 379.5172\n",
      "Epoch 808/1000\n",
      "6/6 - 0s - loss: 41.2042 - val_loss: 379.3164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 809/1000\n",
      "6/6 - 0s - loss: 41.1507 - val_loss: 379.0549\n",
      "Epoch 810/1000\n",
      "6/6 - 0s - loss: 41.1048 - val_loss: 378.9871\n",
      "Epoch 811/1000\n",
      "6/6 - 0s - loss: 41.0558 - val_loss: 378.6733\n",
      "Epoch 812/1000\n",
      "6/6 - 0s - loss: 40.9871 - val_loss: 378.6302\n",
      "Epoch 813/1000\n",
      "6/6 - 0s - loss: 40.9423 - val_loss: 378.2998\n",
      "Epoch 814/1000\n",
      "6/6 - 0s - loss: 40.8800 - val_loss: 378.1321\n",
      "Epoch 815/1000\n",
      "6/6 - 0s - loss: 40.8306 - val_loss: 377.8790\n",
      "Epoch 816/1000\n",
      "6/6 - 0s - loss: 40.7670 - val_loss: 377.7583\n",
      "Epoch 817/1000\n",
      "6/6 - 0s - loss: 40.7290 - val_loss: 377.3987\n",
      "Epoch 818/1000\n",
      "6/6 - 0s - loss: 40.6665 - val_loss: 377.3239\n",
      "Epoch 819/1000\n",
      "6/6 - 0s - loss: 40.6003 - val_loss: 377.0299\n",
      "Epoch 820/1000\n",
      "6/6 - 0s - loss: 40.5507 - val_loss: 376.6961\n",
      "Epoch 821/1000\n",
      "6/6 - 0s - loss: 40.4934 - val_loss: 376.7434\n",
      "Epoch 822/1000\n",
      "6/6 - 0s - loss: 40.4352 - val_loss: 376.1735\n",
      "Epoch 823/1000\n",
      "6/6 - 0s - loss: 40.3756 - val_loss: 376.3188\n",
      "Epoch 824/1000\n",
      "6/6 - 0s - loss: 40.3222 - val_loss: 375.6068\n",
      "Epoch 825/1000\n",
      "6/6 - 0s - loss: 40.2612 - val_loss: 375.7689\n",
      "Epoch 826/1000\n",
      "6/6 - 0s - loss: 40.2011 - val_loss: 375.3167\n",
      "Epoch 827/1000\n",
      "6/6 - 0s - loss: 40.1437 - val_loss: 375.3932\n",
      "Epoch 828/1000\n",
      "6/6 - 0s - loss: 40.0902 - val_loss: 374.8561\n",
      "Epoch 829/1000\n",
      "6/6 - 0s - loss: 40.0341 - val_loss: 374.9022\n",
      "Epoch 830/1000\n",
      "6/6 - 0s - loss: 39.9723 - val_loss: 374.4286\n",
      "Epoch 831/1000\n",
      "6/6 - 0s - loss: 39.9211 - val_loss: 374.5906\n",
      "Epoch 832/1000\n",
      "6/6 - 0s - loss: 39.8778 - val_loss: 374.1008\n",
      "Epoch 833/1000\n",
      "6/6 - 0s - loss: 39.8262 - val_loss: 374.0524\n",
      "Epoch 834/1000\n",
      "6/6 - 0s - loss: 39.7588 - val_loss: 373.9123\n",
      "Epoch 835/1000\n",
      "6/6 - 0s - loss: 39.7044 - val_loss: 373.6684\n",
      "Epoch 836/1000\n",
      "6/6 - 0s - loss: 39.6500 - val_loss: 373.6204\n",
      "Epoch 837/1000\n",
      "6/6 - 0s - loss: 39.5836 - val_loss: 373.3436\n",
      "Epoch 838/1000\n",
      "6/6 - 0s - loss: 39.5164 - val_loss: 373.0193\n",
      "Epoch 839/1000\n",
      "6/6 - 0s - loss: 39.4522 - val_loss: 372.9228\n",
      "Epoch 840/1000\n",
      "6/6 - 0s - loss: 39.3758 - val_loss: 372.5526\n",
      "Epoch 841/1000\n",
      "6/6 - 0s - loss: 39.3217 - val_loss: 372.6061\n",
      "Epoch 842/1000\n",
      "6/6 - 0s - loss: 39.2658 - val_loss: 372.0904\n",
      "Epoch 843/1000\n",
      "6/6 - 0s - loss: 39.2079 - val_loss: 372.3274\n",
      "Epoch 844/1000\n",
      "6/6 - 0s - loss: 39.1448 - val_loss: 371.8019\n",
      "Epoch 845/1000\n",
      "6/6 - 0s - loss: 39.0879 - val_loss: 371.8806\n",
      "Epoch 846/1000\n",
      "6/6 - 0s - loss: 39.0393 - val_loss: 371.5289\n",
      "Epoch 847/1000\n",
      "6/6 - 0s - loss: 38.9862 - val_loss: 371.4109\n",
      "Epoch 848/1000\n",
      "6/6 - 0s - loss: 38.9212 - val_loss: 371.4734\n",
      "Epoch 849/1000\n",
      "6/6 - 0s - loss: 38.8719 - val_loss: 371.0713\n",
      "Epoch 850/1000\n",
      "6/6 - 0s - loss: 38.8210 - val_loss: 371.0541\n",
      "Epoch 851/1000\n",
      "6/6 - 0s - loss: 38.7766 - val_loss: 370.9403\n",
      "Epoch 852/1000\n",
      "6/6 - 0s - loss: 38.7095 - val_loss: 370.6191\n",
      "Epoch 853/1000\n",
      "6/6 - 0s - loss: 38.6733 - val_loss: 370.8309\n",
      "Epoch 854/1000\n",
      "6/6 - 0s - loss: 38.6092 - val_loss: 370.2549\n",
      "Epoch 855/1000\n",
      "6/6 - 0s - loss: 38.5620 - val_loss: 370.4589\n",
      "Epoch 856/1000\n",
      "6/6 - 0s - loss: 38.5202 - val_loss: 370.2239\n",
      "Epoch 857/1000\n",
      "6/6 - 0s - loss: 38.4607 - val_loss: 369.7285\n",
      "Epoch 858/1000\n",
      "6/6 - 0s - loss: 38.4149 - val_loss: 370.2077\n",
      "Epoch 859/1000\n",
      "6/6 - 0s - loss: 38.3545 - val_loss: 369.2194\n",
      "Epoch 860/1000\n",
      "6/6 - 0s - loss: 38.2939 - val_loss: 369.8948\n",
      "Epoch 861/1000\n",
      "6/6 - 0s - loss: 38.2394 - val_loss: 369.3312\n",
      "Epoch 862/1000\n",
      "6/6 - 0s - loss: 38.1789 - val_loss: 368.5550\n",
      "Epoch 863/1000\n",
      "6/6 - 0s - loss: 38.1102 - val_loss: 369.1104\n",
      "Epoch 864/1000\n",
      "6/6 - 0s - loss: 38.0600 - val_loss: 368.5586\n",
      "Epoch 865/1000\n",
      "6/6 - 0s - loss: 38.0027 - val_loss: 368.3294\n",
      "Epoch 866/1000\n",
      "6/6 - 0s - loss: 37.9491 - val_loss: 368.7032\n",
      "Epoch 867/1000\n",
      "6/6 - 0s - loss: 37.9054 - val_loss: 367.5102\n",
      "Epoch 868/1000\n",
      "6/6 - 0s - loss: 37.8480 - val_loss: 368.5530\n",
      "Epoch 869/1000\n",
      "6/6 - 0s - loss: 37.8090 - val_loss: 367.0496\n",
      "Epoch 870/1000\n",
      "6/6 - 0s - loss: 37.7576 - val_loss: 367.8898\n",
      "Epoch 871/1000\n",
      "6/6 - 0s - loss: 37.6974 - val_loss: 367.3985\n",
      "Epoch 872/1000\n",
      "6/6 - 0s - loss: 37.6540 - val_loss: 367.1391\n",
      "Epoch 00872: early stopping\n",
      "Score (MSE): 367.1391105192714\n",
      "Score(RMSE): 19.1608744716746\n",
      "\n",
      "Run  2\n",
      "Activation: Sigmoid\n",
      "Optimizer: Adam\n",
      "\n",
      "Epoch 1/1000\n",
      "6/6 - 0s - loss: 188.8086 - val_loss: 739.7416\n",
      "Epoch 2/1000\n",
      "6/6 - 0s - loss: 186.2144 - val_loss: 734.9466\n",
      "Epoch 3/1000\n",
      "6/6 - 0s - loss: 183.4503 - val_loss: 730.2078\n",
      "Epoch 4/1000\n",
      "6/6 - 0s - loss: 180.9358 - val_loss: 725.6085\n",
      "Epoch 5/1000\n",
      "6/6 - 0s - loss: 178.2759 - val_loss: 720.8847\n",
      "Epoch 6/1000\n",
      "6/6 - 0s - loss: 176.0313 - val_loss: 715.9778\n",
      "Epoch 7/1000\n",
      "6/6 - 0s - loss: 173.9701 - val_loss: 711.9293\n",
      "Epoch 8/1000\n",
      "6/6 - 0s - loss: 171.9488 - val_loss: 708.9888\n",
      "Epoch 9/1000\n",
      "6/6 - 0s - loss: 170.2843 - val_loss: 706.4822\n",
      "Epoch 10/1000\n",
      "6/6 - 0s - loss: 168.7922 - val_loss: 704.2286\n",
      "Epoch 11/1000\n",
      "6/6 - 0s - loss: 167.4050 - val_loss: 702.2402\n",
      "Epoch 12/1000\n",
      "6/6 - 0s - loss: 166.1214 - val_loss: 700.4717\n",
      "Epoch 13/1000\n",
      "6/6 - 0s - loss: 164.9824 - val_loss: 698.8365\n",
      "Epoch 14/1000\n",
      "6/6 - 0s - loss: 164.0117 - val_loss: 697.2557\n",
      "Epoch 15/1000\n",
      "6/6 - 0s - loss: 163.0453 - val_loss: 695.7153\n",
      "Epoch 16/1000\n",
      "6/6 - 0s - loss: 162.1504 - val_loss: 694.3095\n",
      "Epoch 17/1000\n",
      "6/6 - 0s - loss: 161.2771 - val_loss: 693.0654\n",
      "Epoch 18/1000\n",
      "6/6 - 0s - loss: 160.5359 - val_loss: 691.8904\n",
      "Epoch 19/1000\n",
      "6/6 - 0s - loss: 159.7898 - val_loss: 690.8252\n",
      "Epoch 20/1000\n",
      "6/6 - 0s - loss: 159.1590 - val_loss: 689.7913\n",
      "Epoch 21/1000\n",
      "6/6 - 0s - loss: 158.5124 - val_loss: 688.8386\n",
      "Epoch 22/1000\n",
      "6/6 - 0s - loss: 157.9285 - val_loss: 687.9214\n",
      "Epoch 23/1000\n",
      "6/6 - 0s - loss: 157.4008 - val_loss: 687.0302\n",
      "Epoch 24/1000\n",
      "6/6 - 0s - loss: 156.8679 - val_loss: 686.1899\n",
      "Epoch 25/1000\n",
      "6/6 - 0s - loss: 156.3608 - val_loss: 685.4023\n",
      "Epoch 26/1000\n",
      "6/6 - 0s - loss: 155.9192 - val_loss: 684.6248\n",
      "Epoch 27/1000\n",
      "6/6 - 0s - loss: 155.4606 - val_loss: 683.8902\n",
      "Epoch 28/1000\n",
      "6/6 - 0s - loss: 155.0091 - val_loss: 683.1954\n",
      "Epoch 29/1000\n",
      "6/6 - 0s - loss: 154.6194 - val_loss: 682.4960\n",
      "Epoch 30/1000\n",
      "6/6 - 0s - loss: 154.1973 - val_loss: 681.8332\n",
      "Epoch 31/1000\n",
      "6/6 - 0s - loss: 153.8133 - val_loss: 681.1349\n",
      "Epoch 32/1000\n",
      "6/6 - 0s - loss: 153.4352 - val_loss: 680.4579\n",
      "Epoch 33/1000\n",
      "6/6 - 0s - loss: 153.0818 - val_loss: 679.8054\n",
      "Epoch 34/1000\n",
      "6/6 - 0s - loss: 152.7146 - val_loss: 679.1891\n",
      "Epoch 35/1000\n",
      "6/6 - 0s - loss: 152.3669 - val_loss: 678.5776\n",
      "Epoch 36/1000\n",
      "6/6 - 0s - loss: 152.0405 - val_loss: 677.9868\n",
      "Epoch 37/1000\n",
      "6/6 - 0s - loss: 151.7074 - val_loss: 677.4230\n",
      "Epoch 38/1000\n",
      "6/6 - 0s - loss: 151.4057 - val_loss: 676.8725\n",
      "Epoch 39/1000\n",
      "6/6 - 0s - loss: 151.0858 - val_loss: 676.3630\n",
      "Epoch 40/1000\n",
      "6/6 - 0s - loss: 150.8037 - val_loss: 675.8592\n",
      "Epoch 41/1000\n",
      "6/6 - 0s - loss: 150.5186 - val_loss: 675.3414\n",
      "Epoch 42/1000\n",
      "6/6 - 0s - loss: 150.2466 - val_loss: 674.8091\n",
      "Epoch 43/1000\n",
      "6/6 - 0s - loss: 149.9566 - val_loss: 674.3047\n",
      "Epoch 44/1000\n",
      "6/6 - 0s - loss: 149.6673 - val_loss: 673.8240\n",
      "Epoch 45/1000\n",
      "6/6 - 0s - loss: 149.4050 - val_loss: 673.3275\n",
      "Epoch 46/1000\n",
      "6/6 - 0s - loss: 149.1368 - val_loss: 672.8288\n",
      "Epoch 47/1000\n",
      "6/6 - 0s - loss: 148.8566 - val_loss: 672.3328\n",
      "Epoch 48/1000\n",
      "6/6 - 0s - loss: 148.5900 - val_loss: 671.8168\n",
      "Epoch 49/1000\n",
      "6/6 - 0s - loss: 148.3000 - val_loss: 671.3241\n",
      "Epoch 50/1000\n",
      "6/6 - 0s - loss: 148.0426 - val_loss: 670.8070\n",
      "Epoch 51/1000\n",
      "6/6 - 0s - loss: 147.7693 - val_loss: 670.2888\n",
      "Epoch 52/1000\n",
      "6/6 - 0s - loss: 147.4993 - val_loss: 669.7648\n",
      "Epoch 53/1000\n",
      "6/6 - 0s - loss: 147.1981 - val_loss: 669.2587\n",
      "Epoch 54/1000\n",
      "6/6 - 0s - loss: 146.9269 - val_loss: 668.7236\n",
      "Epoch 55/1000\n",
      "6/6 - 0s - loss: 146.6393 - val_loss: 668.1749\n",
      "Epoch 56/1000\n",
      "6/6 - 0s - loss: 146.3323 - val_loss: 667.6262\n",
      "Epoch 57/1000\n",
      "6/6 - 0s - loss: 146.0366 - val_loss: 667.0487\n",
      "Epoch 58/1000\n",
      "6/6 - 0s - loss: 145.7511 - val_loss: 666.4393\n",
      "Epoch 59/1000\n",
      "6/6 - 0s - loss: 145.4137 - val_loss: 665.8423\n",
      "Epoch 60/1000\n",
      "6/6 - 0s - loss: 145.1185 - val_loss: 665.2198\n",
      "Epoch 61/1000\n",
      "6/6 - 0s - loss: 144.7858 - val_loss: 664.6296\n",
      "Epoch 62/1000\n",
      "6/6 - 0s - loss: 144.5053 - val_loss: 664.0147\n",
      "Epoch 63/1000\n",
      "6/6 - 0s - loss: 144.2079 - val_loss: 663.4172\n",
      "Epoch 64/1000\n",
      "6/6 - 0s - loss: 143.8951 - val_loss: 662.8625\n",
      "Epoch 65/1000\n",
      "6/6 - 0s - loss: 143.6051 - val_loss: 662.3281\n",
      "Epoch 66/1000\n",
      "6/6 - 0s - loss: 143.3326 - val_loss: 661.7823\n",
      "Epoch 67/1000\n",
      "6/6 - 0s - loss: 143.0560 - val_loss: 661.2278\n",
      "Epoch 68/1000\n",
      "6/6 - 0s - loss: 142.7771 - val_loss: 660.6870\n",
      "Epoch 69/1000\n",
      "6/6 - 0s - loss: 142.4966 - val_loss: 660.1631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/1000\n",
      "6/6 - 0s - loss: 142.2464 - val_loss: 659.6414\n",
      "Epoch 71/1000\n",
      "6/6 - 0s - loss: 141.9628 - val_loss: 659.1541\n",
      "Epoch 72/1000\n",
      "6/6 - 0s - loss: 141.7057 - val_loss: 658.6652\n",
      "Epoch 73/1000\n",
      "6/6 - 0s - loss: 141.4845 - val_loss: 658.1407\n",
      "Epoch 74/1000\n",
      "6/6 - 0s - loss: 141.2166 - val_loss: 657.6354\n",
      "Epoch 75/1000\n",
      "6/6 - 0s - loss: 140.9561 - val_loss: 657.1387\n",
      "Epoch 76/1000\n",
      "6/6 - 0s - loss: 140.7062 - val_loss: 656.6605\n",
      "Epoch 77/1000\n",
      "6/6 - 0s - loss: 140.4673 - val_loss: 656.1827\n",
      "Epoch 78/1000\n",
      "6/6 - 0s - loss: 140.2268 - val_loss: 655.6904\n",
      "Epoch 79/1000\n",
      "6/6 - 0s - loss: 139.9886 - val_loss: 655.1946\n",
      "Epoch 80/1000\n",
      "6/6 - 0s - loss: 139.7375 - val_loss: 654.7092\n",
      "Epoch 81/1000\n",
      "6/6 - 0s - loss: 139.5087 - val_loss: 654.2259\n",
      "Epoch 82/1000\n",
      "6/6 - 0s - loss: 139.2706 - val_loss: 653.7635\n",
      "Epoch 83/1000\n",
      "6/6 - 0s - loss: 139.0278 - val_loss: 653.3258\n",
      "Epoch 84/1000\n",
      "6/6 - 0s - loss: 138.8316 - val_loss: 652.8401\n",
      "Epoch 85/1000\n",
      "6/6 - 0s - loss: 138.5888 - val_loss: 652.3792\n",
      "Epoch 86/1000\n",
      "6/6 - 0s - loss: 138.3548 - val_loss: 651.9167\n",
      "Epoch 87/1000\n",
      "6/6 - 0s - loss: 138.1488 - val_loss: 651.4337\n",
      "Epoch 88/1000\n",
      "6/6 - 0s - loss: 137.9078 - val_loss: 650.9859\n",
      "Epoch 89/1000\n",
      "6/6 - 0s - loss: 137.6940 - val_loss: 650.5371\n",
      "Epoch 90/1000\n",
      "6/6 - 0s - loss: 137.4845 - val_loss: 650.0891\n",
      "Epoch 91/1000\n",
      "6/6 - 0s - loss: 137.2676 - val_loss: 649.6679\n",
      "Epoch 92/1000\n",
      "6/6 - 0s - loss: 137.0669 - val_loss: 649.2433\n",
      "Epoch 93/1000\n",
      "6/6 - 0s - loss: 136.8515 - val_loss: 648.8268\n",
      "Epoch 94/1000\n",
      "6/6 - 0s - loss: 136.6544 - val_loss: 648.4023\n",
      "Epoch 95/1000\n",
      "6/6 - 0s - loss: 136.4551 - val_loss: 647.9741\n",
      "Epoch 96/1000\n",
      "6/6 - 0s - loss: 136.2568 - val_loss: 647.5411\n",
      "Epoch 97/1000\n",
      "6/6 - 0s - loss: 136.0565 - val_loss: 647.1201\n",
      "Epoch 98/1000\n",
      "6/6 - 0s - loss: 135.8571 - val_loss: 646.7189\n",
      "Epoch 99/1000\n",
      "6/6 - 0s - loss: 135.6651 - val_loss: 646.3165\n",
      "Epoch 100/1000\n",
      "6/6 - 0s - loss: 135.4659 - val_loss: 645.9289\n",
      "Epoch 101/1000\n",
      "6/6 - 0s - loss: 135.2827 - val_loss: 645.5273\n",
      "Epoch 102/1000\n",
      "6/6 - 0s - loss: 135.0987 - val_loss: 645.0981\n",
      "Epoch 103/1000\n",
      "6/6 - 0s - loss: 134.9119 - val_loss: 644.6885\n",
      "Epoch 104/1000\n",
      "6/6 - 0s - loss: 134.7072 - val_loss: 644.3058\n",
      "Epoch 105/1000\n",
      "6/6 - 0s - loss: 134.5352 - val_loss: 643.9148\n",
      "Epoch 106/1000\n",
      "6/6 - 0s - loss: 134.3577 - val_loss: 643.5198\n",
      "Epoch 107/1000\n",
      "6/6 - 0s - loss: 134.1707 - val_loss: 643.1309\n",
      "Epoch 108/1000\n",
      "6/6 - 0s - loss: 133.9984 - val_loss: 642.7408\n",
      "Epoch 109/1000\n",
      "6/6 - 0s - loss: 133.8183 - val_loss: 642.3597\n",
      "Epoch 110/1000\n",
      "6/6 - 0s - loss: 133.6474 - val_loss: 641.9828\n",
      "Epoch 111/1000\n",
      "6/6 - 0s - loss: 133.4680 - val_loss: 641.6266\n",
      "Epoch 112/1000\n",
      "6/6 - 0s - loss: 133.3148 - val_loss: 641.2422\n",
      "Epoch 113/1000\n",
      "6/6 - 0s - loss: 133.1334 - val_loss: 640.8771\n",
      "Epoch 114/1000\n",
      "6/6 - 0s - loss: 132.9634 - val_loss: 640.5243\n",
      "Epoch 115/1000\n",
      "6/6 - 0s - loss: 132.7959 - val_loss: 640.1798\n",
      "Epoch 116/1000\n",
      "6/6 - 0s - loss: 132.6459 - val_loss: 639.8101\n",
      "Epoch 117/1000\n",
      "6/6 - 0s - loss: 132.4807 - val_loss: 639.4465\n",
      "Epoch 118/1000\n",
      "6/6 - 0s - loss: 132.3204 - val_loss: 639.0798\n",
      "Epoch 119/1000\n",
      "6/6 - 0s - loss: 132.1604 - val_loss: 638.7190\n",
      "Epoch 120/1000\n",
      "6/6 - 0s - loss: 131.9951 - val_loss: 638.3667\n",
      "Epoch 121/1000\n",
      "6/6 - 0s - loss: 131.8455 - val_loss: 638.0116\n",
      "Epoch 122/1000\n",
      "6/6 - 0s - loss: 131.6862 - val_loss: 637.6708\n",
      "Epoch 123/1000\n",
      "6/6 - 0s - loss: 131.5277 - val_loss: 637.3391\n",
      "Epoch 124/1000\n",
      "6/6 - 0s - loss: 131.3714 - val_loss: 637.0054\n",
      "Epoch 125/1000\n",
      "6/6 - 0s - loss: 131.2291 - val_loss: 636.6430\n",
      "Epoch 126/1000\n",
      "6/6 - 0s - loss: 131.0663 - val_loss: 636.3032\n",
      "Epoch 127/1000\n",
      "6/6 - 0s - loss: 130.9213 - val_loss: 635.9540\n",
      "Epoch 128/1000\n",
      "6/6 - 0s - loss: 130.7621 - val_loss: 635.6277\n",
      "Epoch 129/1000\n",
      "6/6 - 0s - loss: 130.6285 - val_loss: 635.2905\n",
      "Epoch 130/1000\n",
      "6/6 - 0s - loss: 130.4804 - val_loss: 634.9568\n",
      "Epoch 131/1000\n",
      "6/6 - 0s - loss: 130.3254 - val_loss: 634.6436\n",
      "Epoch 132/1000\n",
      "6/6 - 0s - loss: 130.1940 - val_loss: 634.3171\n",
      "Epoch 133/1000\n",
      "6/6 - 0s - loss: 130.0482 - val_loss: 633.9942\n",
      "Epoch 134/1000\n",
      "6/6 - 0s - loss: 129.9145 - val_loss: 633.6702\n",
      "Epoch 135/1000\n",
      "6/6 - 0s - loss: 129.7715 - val_loss: 633.3647\n",
      "Epoch 136/1000\n",
      "6/6 - 0s - loss: 129.6341 - val_loss: 633.0626\n",
      "Epoch 137/1000\n",
      "6/6 - 0s - loss: 129.5143 - val_loss: 632.7352\n",
      "Epoch 138/1000\n",
      "6/6 - 0s - loss: 129.3658 - val_loss: 632.4192\n",
      "Epoch 139/1000\n",
      "6/6 - 0s - loss: 129.2197 - val_loss: 632.1053\n",
      "Epoch 140/1000\n",
      "6/6 - 0s - loss: 129.0904 - val_loss: 631.7809\n",
      "Epoch 141/1000\n",
      "6/6 - 0s - loss: 128.9600 - val_loss: 631.4609\n",
      "Epoch 142/1000\n",
      "6/6 - 0s - loss: 128.8244 - val_loss: 631.1487\n",
      "Epoch 143/1000\n",
      "6/6 - 0s - loss: 128.6767 - val_loss: 630.8596\n",
      "Epoch 144/1000\n",
      "6/6 - 0s - loss: 128.5633 - val_loss: 630.5333\n",
      "Epoch 145/1000\n",
      "6/6 - 0s - loss: 128.4164 - val_loss: 630.2216\n",
      "Epoch 146/1000\n",
      "6/6 - 0s - loss: 128.2831 - val_loss: 629.9122\n",
      "Epoch 147/1000\n",
      "6/6 - 0s - loss: 128.1492 - val_loss: 629.5989\n",
      "Epoch 148/1000\n",
      "6/6 - 0s - loss: 128.0168 - val_loss: 629.2831\n",
      "Epoch 149/1000\n",
      "6/6 - 0s - loss: 127.8816 - val_loss: 628.9626\n",
      "Epoch 150/1000\n",
      "6/6 - 0s - loss: 127.7546 - val_loss: 628.6457\n",
      "Epoch 151/1000\n",
      "6/6 - 0s - loss: 127.6235 - val_loss: 628.3414\n",
      "Epoch 152/1000\n",
      "6/6 - 0s - loss: 127.4819 - val_loss: 628.0640\n",
      "Epoch 153/1000\n",
      "6/6 - 0s - loss: 127.3658 - val_loss: 627.7686\n",
      "Epoch 154/1000\n",
      "6/6 - 0s - loss: 127.2419 - val_loss: 627.4716\n",
      "Epoch 155/1000\n",
      "6/6 - 0s - loss: 127.1146 - val_loss: 627.1732\n",
      "Epoch 156/1000\n",
      "6/6 - 0s - loss: 127.0012 - val_loss: 626.8704\n",
      "Epoch 157/1000\n",
      "6/6 - 0s - loss: 126.8730 - val_loss: 626.5898\n",
      "Epoch 158/1000\n",
      "6/6 - 0s - loss: 126.7446 - val_loss: 626.3298\n",
      "Epoch 159/1000\n",
      "6/6 - 0s - loss: 126.6373 - val_loss: 626.0546\n",
      "Epoch 160/1000\n",
      "6/6 - 0s - loss: 126.5180 - val_loss: 625.7776\n",
      "Epoch 161/1000\n",
      "6/6 - 0s - loss: 126.4111 - val_loss: 625.4791\n",
      "Epoch 162/1000\n",
      "6/6 - 0s - loss: 126.2715 - val_loss: 625.2130\n",
      "Epoch 163/1000\n",
      "6/6 - 0s - loss: 126.1566 - val_loss: 624.9437\n",
      "Epoch 164/1000\n",
      "6/6 - 0s - loss: 126.0416 - val_loss: 624.6556\n",
      "Epoch 165/1000\n",
      "6/6 - 0s - loss: 125.9106 - val_loss: 624.3782\n",
      "Epoch 166/1000\n",
      "6/6 - 0s - loss: 125.7935 - val_loss: 624.0936\n",
      "Epoch 167/1000\n",
      "6/6 - 0s - loss: 125.6705 - val_loss: 623.8151\n",
      "Epoch 168/1000\n",
      "6/6 - 0s - loss: 125.5498 - val_loss: 623.5283\n",
      "Epoch 169/1000\n",
      "6/6 - 0s - loss: 125.4185 - val_loss: 623.2433\n",
      "Epoch 170/1000\n",
      "6/6 - 0s - loss: 125.2978 - val_loss: 622.9410\n",
      "Epoch 171/1000\n",
      "6/6 - 0s - loss: 125.1633 - val_loss: 622.6567\n",
      "Epoch 172/1000\n",
      "6/6 - 0s - loss: 125.0419 - val_loss: 622.3774\n",
      "Epoch 173/1000\n",
      "6/6 - 0s - loss: 124.9217 - val_loss: 622.1026\n",
      "Epoch 174/1000\n",
      "6/6 - 0s - loss: 124.7980 - val_loss: 621.8298\n",
      "Epoch 175/1000\n",
      "6/6 - 0s - loss: 124.6796 - val_loss: 621.5488\n",
      "Epoch 176/1000\n",
      "6/6 - 0s - loss: 124.5490 - val_loss: 621.2656\n",
      "Epoch 177/1000\n",
      "6/6 - 0s - loss: 124.4311 - val_loss: 620.9730\n",
      "Epoch 178/1000\n",
      "6/6 - 0s - loss: 124.2859 - val_loss: 620.7165\n",
      "Epoch 179/1000\n",
      "6/6 - 0s - loss: 124.1650 - val_loss: 620.4424\n",
      "Epoch 180/1000\n",
      "6/6 - 0s - loss: 124.0460 - val_loss: 620.1612\n",
      "Epoch 181/1000\n",
      "6/6 - 0s - loss: 123.9060 - val_loss: 619.8944\n",
      "Epoch 182/1000\n",
      "6/6 - 0s - loss: 123.7719 - val_loss: 619.6177\n",
      "Epoch 183/1000\n",
      "6/6 - 0s - loss: 123.6411 - val_loss: 619.3165\n",
      "Epoch 184/1000\n",
      "6/6 - 0s - loss: 123.5002 - val_loss: 619.0140\n",
      "Epoch 185/1000\n",
      "6/6 - 0s - loss: 123.3577 - val_loss: 618.7195\n",
      "Epoch 186/1000\n",
      "6/6 - 0s - loss: 123.2134 - val_loss: 618.4393\n",
      "Epoch 187/1000\n",
      "6/6 - 0s - loss: 123.0634 - val_loss: 618.1773\n",
      "Epoch 188/1000\n",
      "6/6 - 0s - loss: 122.9362 - val_loss: 617.8915\n",
      "Epoch 189/1000\n",
      "6/6 - 0s - loss: 122.7884 - val_loss: 617.6212\n",
      "Epoch 190/1000\n",
      "6/6 - 0s - loss: 122.6357 - val_loss: 617.3698\n",
      "Epoch 191/1000\n",
      "6/6 - 0s - loss: 122.4956 - val_loss: 617.0821\n",
      "Epoch 192/1000\n",
      "6/6 - 0s - loss: 122.3366 - val_loss: 616.7922\n",
      "Epoch 193/1000\n",
      "6/6 - 0s - loss: 122.1886 - val_loss: 616.4785\n",
      "Epoch 194/1000\n",
      "6/6 - 0s - loss: 122.0095 - val_loss: 616.1995\n",
      "Epoch 195/1000\n",
      "6/6 - 0s - loss: 121.8586 - val_loss: 615.8965\n",
      "Epoch 196/1000\n",
      "6/6 - 0s - loss: 121.6850 - val_loss: 615.6174\n",
      "Epoch 197/1000\n",
      "6/6 - 0s - loss: 121.5254 - val_loss: 615.3206\n",
      "Epoch 198/1000\n",
      "6/6 - 0s - loss: 121.3572 - val_loss: 615.0073\n",
      "Epoch 199/1000\n",
      "6/6 - 0s - loss: 121.1766 - val_loss: 614.7255\n",
      "Epoch 200/1000\n",
      "6/6 - 0s - loss: 121.0063 - val_loss: 614.4395\n",
      "Epoch 201/1000\n",
      "6/6 - 0s - loss: 120.8443 - val_loss: 614.1422\n",
      "Epoch 202/1000\n",
      "6/6 - 0s - loss: 120.6616 - val_loss: 613.8616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203/1000\n",
      "6/6 - 0s - loss: 120.4939 - val_loss: 613.5535\n",
      "Epoch 204/1000\n",
      "6/6 - 0s - loss: 120.3114 - val_loss: 613.2486\n",
      "Epoch 205/1000\n",
      "6/6 - 0s - loss: 120.1285 - val_loss: 612.9462\n",
      "Epoch 206/1000\n",
      "6/6 - 0s - loss: 119.9557 - val_loss: 612.6348\n",
      "Epoch 207/1000\n",
      "6/6 - 0s - loss: 119.7669 - val_loss: 612.3381\n",
      "Epoch 208/1000\n",
      "6/6 - 0s - loss: 119.5908 - val_loss: 612.0185\n",
      "Epoch 209/1000\n",
      "6/6 - 0s - loss: 119.3926 - val_loss: 611.7065\n",
      "Epoch 210/1000\n",
      "6/6 - 0s - loss: 119.2034 - val_loss: 611.3876\n",
      "Epoch 211/1000\n",
      "6/6 - 0s - loss: 119.0104 - val_loss: 611.0515\n",
      "Epoch 212/1000\n",
      "6/6 - 0s - loss: 118.8306 - val_loss: 610.6843\n",
      "Epoch 213/1000\n",
      "6/6 - 0s - loss: 118.6205 - val_loss: 610.3423\n",
      "Epoch 214/1000\n",
      "6/6 - 0s - loss: 118.4240 - val_loss: 610.0084\n",
      "Epoch 215/1000\n",
      "6/6 - 0s - loss: 118.2418 - val_loss: 609.6630\n",
      "Epoch 216/1000\n",
      "6/6 - 0s - loss: 118.0397 - val_loss: 609.3370\n",
      "Epoch 217/1000\n",
      "6/6 - 0s - loss: 117.8497 - val_loss: 609.0121\n",
      "Epoch 218/1000\n",
      "6/6 - 0s - loss: 117.6631 - val_loss: 608.6906\n",
      "Epoch 219/1000\n",
      "6/6 - 0s - loss: 117.4869 - val_loss: 608.3525\n",
      "Epoch 220/1000\n",
      "6/6 - 0s - loss: 117.2938 - val_loss: 608.0213\n",
      "Epoch 221/1000\n",
      "6/6 - 0s - loss: 117.1010 - val_loss: 607.7039\n",
      "Epoch 222/1000\n",
      "6/6 - 0s - loss: 116.9161 - val_loss: 607.3828\n",
      "Epoch 223/1000\n",
      "6/6 - 0s - loss: 116.7349 - val_loss: 607.0356\n",
      "Epoch 224/1000\n",
      "6/6 - 0s - loss: 116.5480 - val_loss: 606.6653\n",
      "Epoch 225/1000\n",
      "6/6 - 0s - loss: 116.3429 - val_loss: 606.3106\n",
      "Epoch 226/1000\n",
      "6/6 - 0s - loss: 116.1517 - val_loss: 605.9620\n",
      "Epoch 227/1000\n",
      "6/6 - 0s - loss: 115.9600 - val_loss: 605.6093\n",
      "Epoch 228/1000\n",
      "6/6 - 0s - loss: 115.7726 - val_loss: 605.2484\n",
      "Epoch 229/1000\n",
      "6/6 - 0s - loss: 115.5894 - val_loss: 604.8925\n",
      "Epoch 230/1000\n",
      "6/6 - 0s - loss: 115.4033 - val_loss: 604.5472\n",
      "Epoch 231/1000\n",
      "6/6 - 0s - loss: 115.2229 - val_loss: 604.2037\n",
      "Epoch 232/1000\n",
      "6/6 - 0s - loss: 115.0509 - val_loss: 603.8472\n",
      "Epoch 233/1000\n",
      "6/6 - 0s - loss: 114.8588 - val_loss: 603.5075\n",
      "Epoch 234/1000\n",
      "6/6 - 0s - loss: 114.6833 - val_loss: 603.1636\n",
      "Epoch 235/1000\n",
      "6/6 - 0s - loss: 114.5168 - val_loss: 602.7902\n",
      "Epoch 236/1000\n",
      "6/6 - 0s - loss: 114.3165 - val_loss: 602.4476\n",
      "Epoch 237/1000\n",
      "6/6 - 0s - loss: 114.1440 - val_loss: 602.1003\n",
      "Epoch 238/1000\n",
      "6/6 - 0s - loss: 113.9616 - val_loss: 601.7262\n",
      "Epoch 239/1000\n",
      "6/6 - 0s - loss: 113.7756 - val_loss: 601.3401\n",
      "Epoch 240/1000\n",
      "6/6 - 0s - loss: 113.6088 - val_loss: 600.9500\n",
      "Epoch 241/1000\n",
      "6/6 - 0s - loss: 113.4086 - val_loss: 600.5945\n",
      "Epoch 242/1000\n",
      "6/6 - 0s - loss: 113.2367 - val_loss: 600.2305\n",
      "Epoch 243/1000\n",
      "6/6 - 0s - loss: 113.0593 - val_loss: 599.8663\n",
      "Epoch 244/1000\n",
      "6/6 - 0s - loss: 112.8928 - val_loss: 599.4973\n",
      "Epoch 245/1000\n",
      "6/6 - 0s - loss: 112.7251 - val_loss: 599.1212\n",
      "Epoch 246/1000\n",
      "6/6 - 0s - loss: 112.5364 - val_loss: 598.7726\n",
      "Epoch 247/1000\n",
      "6/6 - 0s - loss: 112.3665 - val_loss: 598.4166\n",
      "Epoch 248/1000\n",
      "6/6 - 0s - loss: 112.1991 - val_loss: 598.0667\n",
      "Epoch 249/1000\n",
      "6/6 - 0s - loss: 112.0382 - val_loss: 597.7084\n",
      "Epoch 250/1000\n",
      "6/6 - 0s - loss: 111.8731 - val_loss: 597.3510\n",
      "Epoch 251/1000\n",
      "6/6 - 0s - loss: 111.7100 - val_loss: 596.9990\n",
      "Epoch 252/1000\n",
      "6/6 - 0s - loss: 111.5396 - val_loss: 596.6575\n",
      "Epoch 253/1000\n",
      "6/6 - 0s - loss: 111.3840 - val_loss: 596.3055\n",
      "Epoch 254/1000\n",
      "6/6 - 0s - loss: 111.2200 - val_loss: 595.9623\n",
      "Epoch 255/1000\n",
      "6/6 - 0s - loss: 111.0711 - val_loss: 595.6125\n",
      "Epoch 256/1000\n",
      "6/6 - 0s - loss: 110.9113 - val_loss: 595.2584\n",
      "Epoch 257/1000\n",
      "6/6 - 0s - loss: 110.7353 - val_loss: 594.9296\n",
      "Epoch 258/1000\n",
      "6/6 - 0s - loss: 110.5962 - val_loss: 594.5760\n",
      "Epoch 259/1000\n",
      "6/6 - 0s - loss: 110.4241 - val_loss: 594.2417\n",
      "Epoch 260/1000\n",
      "6/6 - 0s - loss: 110.2848 - val_loss: 593.8882\n",
      "Epoch 261/1000\n",
      "6/6 - 0s - loss: 110.1165 - val_loss: 593.5642\n",
      "Epoch 262/1000\n",
      "6/6 - 0s - loss: 109.9794 - val_loss: 593.2302\n",
      "Epoch 263/1000\n",
      "6/6 - 0s - loss: 109.8224 - val_loss: 592.9048\n",
      "Epoch 264/1000\n",
      "6/6 - 0s - loss: 109.6780 - val_loss: 592.5659\n",
      "Epoch 265/1000\n",
      "6/6 - 0s - loss: 109.5301 - val_loss: 592.2214\n",
      "Epoch 266/1000\n",
      "6/6 - 0s - loss: 109.3711 - val_loss: 591.8922\n",
      "Epoch 267/1000\n",
      "6/6 - 0s - loss: 109.2257 - val_loss: 591.5640\n",
      "Epoch 268/1000\n",
      "6/6 - 0s - loss: 109.0829 - val_loss: 591.2109\n",
      "Epoch 269/1000\n",
      "6/6 - 0s - loss: 108.9230 - val_loss: 590.8698\n",
      "Epoch 270/1000\n",
      "6/6 - 0s - loss: 108.7646 - val_loss: 590.5318\n",
      "Epoch 271/1000\n",
      "6/6 - 0s - loss: 108.6214 - val_loss: 590.1761\n",
      "Epoch 272/1000\n",
      "6/6 - 0s - loss: 108.4717 - val_loss: 589.8348\n",
      "Epoch 273/1000\n",
      "6/6 - 0s - loss: 108.3157 - val_loss: 589.5118\n",
      "Epoch 274/1000\n",
      "6/6 - 0s - loss: 108.1729 - val_loss: 589.1878\n",
      "Epoch 275/1000\n",
      "6/6 - 0s - loss: 108.0389 - val_loss: 588.8433\n",
      "Epoch 276/1000\n",
      "6/6 - 0s - loss: 107.8823 - val_loss: 588.5196\n",
      "Epoch 277/1000\n",
      "6/6 - 0s - loss: 107.7445 - val_loss: 588.1857\n",
      "Epoch 278/1000\n",
      "6/6 - 0s - loss: 107.6049 - val_loss: 587.8602\n",
      "Epoch 279/1000\n",
      "6/6 - 0s - loss: 107.4589 - val_loss: 587.5437\n",
      "Epoch 280/1000\n",
      "6/6 - 0s - loss: 107.3145 - val_loss: 587.2104\n",
      "Epoch 281/1000\n",
      "6/6 - 0s - loss: 107.1763 - val_loss: 586.8658\n",
      "Epoch 282/1000\n",
      "6/6 - 0s - loss: 107.0276 - val_loss: 586.5259\n",
      "Epoch 283/1000\n",
      "6/6 - 0s - loss: 106.8854 - val_loss: 586.1898\n",
      "Epoch 284/1000\n",
      "6/6 - 0s - loss: 106.7438 - val_loss: 585.8566\n",
      "Epoch 285/1000\n",
      "6/6 - 0s - loss: 106.6115 - val_loss: 585.5222\n",
      "Epoch 286/1000\n",
      "6/6 - 0s - loss: 106.4544 - val_loss: 585.2192\n",
      "Epoch 287/1000\n",
      "6/6 - 0s - loss: 106.3346 - val_loss: 584.8926\n",
      "Epoch 288/1000\n",
      "6/6 - 0s - loss: 106.1974 - val_loss: 584.5645\n",
      "Epoch 289/1000\n",
      "6/6 - 0s - loss: 106.0588 - val_loss: 584.2373\n",
      "Epoch 290/1000\n",
      "6/6 - 0s - loss: 105.9138 - val_loss: 583.9201\n",
      "Epoch 291/1000\n",
      "6/6 - 0s - loss: 105.7889 - val_loss: 583.5896\n",
      "Epoch 292/1000\n",
      "6/6 - 0s - loss: 105.6452 - val_loss: 583.2709\n",
      "Epoch 293/1000\n",
      "6/6 - 0s - loss: 105.5161 - val_loss: 582.9536\n",
      "Epoch 294/1000\n",
      "6/6 - 0s - loss: 105.3819 - val_loss: 582.6281\n",
      "Epoch 295/1000\n",
      "6/6 - 0s - loss: 105.2397 - val_loss: 582.3160\n",
      "Epoch 296/1000\n",
      "6/6 - 0s - loss: 105.1225 - val_loss: 581.9751\n",
      "Epoch 297/1000\n",
      "6/6 - 0s - loss: 104.9749 - val_loss: 581.6581\n",
      "Epoch 298/1000\n",
      "6/6 - 0s - loss: 104.8454 - val_loss: 581.3456\n",
      "Epoch 299/1000\n",
      "6/6 - 0s - loss: 104.7144 - val_loss: 581.0198\n",
      "Epoch 300/1000\n",
      "6/6 - 0s - loss: 104.5713 - val_loss: 580.6980\n",
      "Epoch 301/1000\n",
      "6/6 - 0s - loss: 104.4348 - val_loss: 580.3601\n",
      "Epoch 302/1000\n",
      "6/6 - 0s - loss: 104.3196 - val_loss: 580.0148\n",
      "Epoch 303/1000\n",
      "6/6 - 0s - loss: 104.1736 - val_loss: 579.6791\n",
      "Epoch 304/1000\n",
      "6/6 - 0s - loss: 104.0393 - val_loss: 579.3511\n",
      "Epoch 305/1000\n",
      "6/6 - 0s - loss: 103.8909 - val_loss: 579.0380\n",
      "Epoch 306/1000\n",
      "6/6 - 0s - loss: 103.7611 - val_loss: 578.7135\n",
      "Epoch 307/1000\n",
      "6/6 - 0s - loss: 103.6346 - val_loss: 578.3824\n",
      "Epoch 308/1000\n",
      "6/6 - 0s - loss: 103.4950 - val_loss: 578.0599\n",
      "Epoch 309/1000\n",
      "6/6 - 0s - loss: 103.3606 - val_loss: 577.7441\n",
      "Epoch 310/1000\n",
      "6/6 - 0s - loss: 103.2425 - val_loss: 577.4180\n",
      "Epoch 311/1000\n",
      "6/6 - 0s - loss: 103.1022 - val_loss: 577.1031\n",
      "Epoch 312/1000\n",
      "6/6 - 0s - loss: 102.9838 - val_loss: 576.7618\n",
      "Epoch 313/1000\n",
      "6/6 - 0s - loss: 102.8436 - val_loss: 576.4342\n",
      "Epoch 314/1000\n",
      "6/6 - 0s - loss: 102.7067 - val_loss: 576.0983\n",
      "Epoch 315/1000\n",
      "6/6 - 0s - loss: 102.5684 - val_loss: 575.7699\n",
      "Epoch 316/1000\n",
      "6/6 - 0s - loss: 102.4365 - val_loss: 575.4345\n",
      "Epoch 317/1000\n",
      "6/6 - 0s - loss: 102.3000 - val_loss: 575.1184\n",
      "Epoch 318/1000\n",
      "6/6 - 0s - loss: 102.1676 - val_loss: 574.8062\n",
      "Epoch 319/1000\n",
      "6/6 - 0s - loss: 102.0397 - val_loss: 574.4748\n",
      "Epoch 320/1000\n",
      "6/6 - 0s - loss: 101.9143 - val_loss: 574.1558\n",
      "Epoch 321/1000\n",
      "6/6 - 0s - loss: 101.7902 - val_loss: 573.8448\n",
      "Epoch 322/1000\n",
      "6/6 - 0s - loss: 101.6498 - val_loss: 573.5475\n",
      "Epoch 323/1000\n",
      "6/6 - 0s - loss: 101.5404 - val_loss: 573.2137\n",
      "Epoch 324/1000\n",
      "6/6 - 0s - loss: 101.4110 - val_loss: 572.8864\n",
      "Epoch 325/1000\n",
      "6/6 - 0s - loss: 101.2796 - val_loss: 572.5781\n",
      "Epoch 326/1000\n",
      "6/6 - 0s - loss: 101.1568 - val_loss: 572.2815\n",
      "Epoch 327/1000\n",
      "6/6 - 0s - loss: 101.0428 - val_loss: 571.9718\n",
      "Epoch 328/1000\n",
      "6/6 - 0s - loss: 100.9246 - val_loss: 571.6707\n",
      "Epoch 329/1000\n",
      "6/6 - 0s - loss: 100.8003 - val_loss: 571.3887\n",
      "Epoch 330/1000\n",
      "6/6 - 0s - loss: 100.6903 - val_loss: 571.0978\n",
      "Epoch 331/1000\n",
      "6/6 - 0s - loss: 100.5649 - val_loss: 570.8164\n",
      "Epoch 332/1000\n",
      "6/6 - 0s - loss: 100.4496 - val_loss: 570.5277\n",
      "Epoch 333/1000\n",
      "6/6 - 0s - loss: 100.3400 - val_loss: 570.2139\n",
      "Epoch 334/1000\n",
      "6/6 - 0s - loss: 100.2036 - val_loss: 569.9173\n",
      "Epoch 335/1000\n",
      "6/6 - 0s - loss: 100.0926 - val_loss: 569.6010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/1000\n",
      "6/6 - 0s - loss: 99.9609 - val_loss: 569.3071\n",
      "Epoch 337/1000\n",
      "6/6 - 0s - loss: 99.8411 - val_loss: 569.0149\n",
      "Epoch 338/1000\n",
      "6/6 - 0s - loss: 99.7332 - val_loss: 568.7115\n",
      "Epoch 339/1000\n",
      "6/6 - 0s - loss: 99.6147 - val_loss: 568.4152\n",
      "Epoch 340/1000\n",
      "6/6 - 0s - loss: 99.4872 - val_loss: 568.1331\n",
      "Epoch 341/1000\n",
      "6/6 - 0s - loss: 99.3726 - val_loss: 567.8311\n",
      "Epoch 342/1000\n",
      "6/6 - 0s - loss: 99.2544 - val_loss: 567.5040\n",
      "Epoch 343/1000\n",
      "6/6 - 0s - loss: 99.1264 - val_loss: 567.1937\n",
      "Epoch 344/1000\n",
      "6/6 - 0s - loss: 99.0119 - val_loss: 566.8741\n",
      "Epoch 345/1000\n",
      "6/6 - 0s - loss: 98.8960 - val_loss: 566.5501\n",
      "Epoch 346/1000\n",
      "6/6 - 0s - loss: 98.7534 - val_loss: 566.2518\n",
      "Epoch 347/1000\n",
      "6/6 - 0s - loss: 98.6441 - val_loss: 565.9321\n",
      "Epoch 348/1000\n",
      "6/6 - 0s - loss: 98.5127 - val_loss: 565.6140\n",
      "Epoch 349/1000\n",
      "6/6 - 0s - loss: 98.3976 - val_loss: 565.2939\n",
      "Epoch 350/1000\n",
      "6/6 - 0s - loss: 98.2665 - val_loss: 564.9710\n",
      "Epoch 351/1000\n",
      "6/6 - 0s - loss: 98.1499 - val_loss: 564.6449\n",
      "Epoch 352/1000\n",
      "6/6 - 0s - loss: 98.0190 - val_loss: 564.3276\n",
      "Epoch 353/1000\n",
      "6/6 - 0s - loss: 97.9034 - val_loss: 564.0204\n",
      "Epoch 354/1000\n",
      "6/6 - 0s - loss: 97.7933 - val_loss: 563.7193\n",
      "Epoch 355/1000\n",
      "6/6 - 0s - loss: 97.6730 - val_loss: 563.4371\n",
      "Epoch 356/1000\n",
      "6/6 - 0s - loss: 97.5548 - val_loss: 563.1622\n",
      "Epoch 357/1000\n",
      "6/6 - 0s - loss: 97.4487 - val_loss: 562.8689\n",
      "Epoch 358/1000\n",
      "6/6 - 0s - loss: 97.3383 - val_loss: 562.5760\n",
      "Epoch 359/1000\n",
      "6/6 - 0s - loss: 97.2325 - val_loss: 562.2732\n",
      "Epoch 360/1000\n",
      "6/6 - 0s - loss: 97.1190 - val_loss: 561.9731\n",
      "Epoch 361/1000\n",
      "6/6 - 0s - loss: 97.0104 - val_loss: 561.6861\n",
      "Epoch 362/1000\n",
      "6/6 - 0s - loss: 96.8921 - val_loss: 561.4100\n",
      "Epoch 363/1000\n",
      "6/6 - 0s - loss: 96.7885 - val_loss: 561.1114\n",
      "Epoch 364/1000\n",
      "6/6 - 0s - loss: 96.6666 - val_loss: 560.8381\n",
      "Epoch 365/1000\n",
      "6/6 - 0s - loss: 96.5661 - val_loss: 560.5441\n",
      "Epoch 366/1000\n",
      "6/6 - 0s - loss: 96.4591 - val_loss: 560.2477\n",
      "Epoch 367/1000\n",
      "6/6 - 0s - loss: 96.3507 - val_loss: 559.9600\n",
      "Epoch 368/1000\n",
      "6/6 - 0s - loss: 96.2294 - val_loss: 559.6801\n",
      "Epoch 369/1000\n",
      "6/6 - 0s - loss: 96.1216 - val_loss: 559.4067\n",
      "Epoch 370/1000\n",
      "6/6 - 0s - loss: 96.0199 - val_loss: 559.1021\n",
      "Epoch 371/1000\n",
      "6/6 - 0s - loss: 95.8910 - val_loss: 558.8310\n",
      "Epoch 372/1000\n",
      "6/6 - 0s - loss: 95.7904 - val_loss: 558.5164\n",
      "Epoch 373/1000\n",
      "6/6 - 0s - loss: 95.6762 - val_loss: 558.2004\n",
      "Epoch 374/1000\n",
      "6/6 - 0s - loss: 95.5485 - val_loss: 557.9039\n",
      "Epoch 375/1000\n",
      "6/6 - 0s - loss: 95.4433 - val_loss: 557.6074\n",
      "Epoch 376/1000\n",
      "6/6 - 0s - loss: 95.3288 - val_loss: 557.3262\n",
      "Epoch 377/1000\n",
      "6/6 - 0s - loss: 95.2215 - val_loss: 557.0403\n",
      "Epoch 378/1000\n",
      "6/6 - 0s - loss: 95.1054 - val_loss: 556.7520\n",
      "Epoch 379/1000\n",
      "6/6 - 0s - loss: 95.0100 - val_loss: 556.4395\n",
      "Epoch 380/1000\n",
      "6/6 - 0s - loss: 94.8847 - val_loss: 556.1529\n",
      "Epoch 381/1000\n",
      "6/6 - 0s - loss: 94.7757 - val_loss: 555.8536\n",
      "Epoch 382/1000\n",
      "6/6 - 0s - loss: 94.6604 - val_loss: 555.5718\n",
      "Epoch 383/1000\n",
      "6/6 - 0s - loss: 94.5619 - val_loss: 555.2847\n",
      "Epoch 384/1000\n",
      "6/6 - 0s - loss: 94.4424 - val_loss: 555.0043\n",
      "Epoch 385/1000\n",
      "6/6 - 0s - loss: 94.3391 - val_loss: 554.7101\n",
      "Epoch 386/1000\n",
      "6/6 - 0s - loss: 94.2283 - val_loss: 554.4189\n",
      "Epoch 387/1000\n",
      "6/6 - 0s - loss: 94.1174 - val_loss: 554.1400\n",
      "Epoch 388/1000\n",
      "6/6 - 0s - loss: 94.0140 - val_loss: 553.8525\n",
      "Epoch 389/1000\n",
      "6/6 - 0s - loss: 93.9074 - val_loss: 553.5720\n",
      "Epoch 390/1000\n",
      "6/6 - 0s - loss: 93.8011 - val_loss: 553.2961\n",
      "Epoch 391/1000\n",
      "6/6 - 0s - loss: 93.6955 - val_loss: 553.0280\n",
      "Epoch 392/1000\n",
      "6/6 - 0s - loss: 93.6023 - val_loss: 552.7374\n",
      "Epoch 393/1000\n",
      "6/6 - 0s - loss: 93.4894 - val_loss: 552.4568\n",
      "Epoch 394/1000\n",
      "6/6 - 0s - loss: 93.3904 - val_loss: 552.1702\n",
      "Epoch 395/1000\n",
      "6/6 - 0s - loss: 93.2733 - val_loss: 551.9062\n",
      "Epoch 396/1000\n",
      "6/6 - 0s - loss: 93.1786 - val_loss: 551.6279\n",
      "Epoch 397/1000\n",
      "6/6 - 0s - loss: 93.0765 - val_loss: 551.3599\n",
      "Epoch 398/1000\n",
      "6/6 - 0s - loss: 92.9789 - val_loss: 551.0810\n",
      "Epoch 399/1000\n",
      "6/6 - 0s - loss: 92.8748 - val_loss: 550.8084\n",
      "Epoch 400/1000\n",
      "6/6 - 0s - loss: 92.7761 - val_loss: 550.5175\n",
      "Epoch 401/1000\n",
      "6/6 - 0s - loss: 92.6675 - val_loss: 550.2471\n",
      "Epoch 402/1000\n",
      "6/6 - 0s - loss: 92.5690 - val_loss: 549.9749\n",
      "Epoch 403/1000\n",
      "6/6 - 0s - loss: 92.4668 - val_loss: 549.6954\n",
      "Epoch 404/1000\n",
      "6/6 - 0s - loss: 92.3574 - val_loss: 549.4260\n",
      "Epoch 405/1000\n",
      "6/6 - 0s - loss: 92.2627 - val_loss: 549.1445\n",
      "Epoch 406/1000\n",
      "6/6 - 0s - loss: 92.1721 - val_loss: 548.8480\n",
      "Epoch 407/1000\n",
      "6/6 - 0s - loss: 92.0623 - val_loss: 548.5670\n",
      "Epoch 408/1000\n",
      "6/6 - 0s - loss: 91.9500 - val_loss: 548.3063\n",
      "Epoch 409/1000\n",
      "6/6 - 0s - loss: 91.8474 - val_loss: 548.0261\n",
      "Epoch 410/1000\n",
      "6/6 - 0s - loss: 91.7484 - val_loss: 547.7399\n",
      "Epoch 411/1000\n",
      "6/6 - 0s - loss: 91.6526 - val_loss: 547.4480\n",
      "Epoch 412/1000\n",
      "6/6 - 0s - loss: 91.5368 - val_loss: 547.1653\n",
      "Epoch 413/1000\n",
      "6/6 - 0s - loss: 91.4358 - val_loss: 546.8808\n",
      "Epoch 414/1000\n",
      "6/6 - 0s - loss: 91.3275 - val_loss: 546.6026\n",
      "Epoch 415/1000\n",
      "6/6 - 0s - loss: 91.2360 - val_loss: 546.3117\n",
      "Epoch 416/1000\n",
      "6/6 - 0s - loss: 91.1335 - val_loss: 546.0224\n",
      "Epoch 417/1000\n",
      "6/6 - 0s - loss: 91.0322 - val_loss: 545.7329\n",
      "Epoch 418/1000\n",
      "6/6 - 0s - loss: 90.9293 - val_loss: 545.4473\n",
      "Epoch 419/1000\n",
      "6/6 - 0s - loss: 90.8328 - val_loss: 545.1641\n",
      "Epoch 420/1000\n",
      "6/6 - 0s - loss: 90.7266 - val_loss: 544.8898\n",
      "Epoch 421/1000\n",
      "6/6 - 0s - loss: 90.6305 - val_loss: 544.6082\n",
      "Epoch 422/1000\n",
      "6/6 - 0s - loss: 90.5283 - val_loss: 544.3466\n",
      "Epoch 423/1000\n",
      "6/6 - 0s - loss: 90.4387 - val_loss: 544.0771\n",
      "Epoch 424/1000\n",
      "6/6 - 0s - loss: 90.3386 - val_loss: 543.8123\n",
      "Epoch 425/1000\n",
      "6/6 - 0s - loss: 90.2467 - val_loss: 543.5468\n",
      "Epoch 426/1000\n",
      "6/6 - 0s - loss: 90.1544 - val_loss: 543.2806\n",
      "Epoch 427/1000\n",
      "6/6 - 0s - loss: 90.0558 - val_loss: 543.0164\n",
      "Epoch 428/1000\n",
      "6/6 - 0s - loss: 89.9684 - val_loss: 542.7357\n",
      "Epoch 429/1000\n",
      "6/6 - 0s - loss: 89.8684 - val_loss: 542.4611\n",
      "Epoch 430/1000\n",
      "6/6 - 0s - loss: 89.7770 - val_loss: 542.1960\n",
      "Epoch 431/1000\n",
      "6/6 - 0s - loss: 89.6852 - val_loss: 541.9435\n",
      "Epoch 432/1000\n",
      "6/6 - 0s - loss: 89.5859 - val_loss: 541.6855\n",
      "Epoch 433/1000\n",
      "6/6 - 0s - loss: 89.4971 - val_loss: 541.4172\n",
      "Epoch 434/1000\n",
      "6/6 - 0s - loss: 89.4203 - val_loss: 541.1415\n",
      "Epoch 435/1000\n",
      "6/6 - 0s - loss: 89.3126 - val_loss: 540.8808\n",
      "Epoch 436/1000\n",
      "6/6 - 0s - loss: 89.2249 - val_loss: 540.6055\n",
      "Epoch 437/1000\n",
      "6/6 - 0s - loss: 89.1178 - val_loss: 540.3525\n",
      "Epoch 438/1000\n",
      "6/6 - 0s - loss: 89.0303 - val_loss: 540.0833\n",
      "Epoch 439/1000\n",
      "6/6 - 0s - loss: 88.9380 - val_loss: 539.8248\n",
      "Epoch 440/1000\n",
      "6/6 - 0s - loss: 88.8417 - val_loss: 539.5743\n",
      "Epoch 441/1000\n",
      "6/6 - 0s - loss: 88.7591 - val_loss: 539.3164\n",
      "Epoch 442/1000\n",
      "6/6 - 0s - loss: 88.6577 - val_loss: 539.0840\n",
      "Epoch 443/1000\n",
      "6/6 - 0s - loss: 88.5788 - val_loss: 538.8116\n",
      "Epoch 444/1000\n",
      "6/6 - 0s - loss: 88.4881 - val_loss: 538.5460\n",
      "Epoch 445/1000\n",
      "6/6 - 0s - loss: 88.3821 - val_loss: 538.2874\n",
      "Epoch 446/1000\n",
      "6/6 - 0s - loss: 88.2988 - val_loss: 538.0120\n",
      "Epoch 447/1000\n",
      "6/6 - 0s - loss: 88.2065 - val_loss: 537.7513\n",
      "Epoch 448/1000\n",
      "6/6 - 0s - loss: 88.1229 - val_loss: 537.4824\n",
      "Epoch 449/1000\n",
      "6/6 - 0s - loss: 88.0258 - val_loss: 537.2290\n",
      "Epoch 450/1000\n",
      "6/6 - 0s - loss: 87.9329 - val_loss: 536.9719\n",
      "Epoch 451/1000\n",
      "6/6 - 0s - loss: 87.8440 - val_loss: 536.7162\n",
      "Epoch 452/1000\n",
      "6/6 - 0s - loss: 87.7507 - val_loss: 536.4623\n",
      "Epoch 453/1000\n",
      "6/6 - 0s - loss: 87.6597 - val_loss: 536.2176\n",
      "Epoch 454/1000\n",
      "6/6 - 0s - loss: 87.5737 - val_loss: 535.9521\n",
      "Epoch 455/1000\n",
      "6/6 - 0s - loss: 87.4751 - val_loss: 535.6934\n",
      "Epoch 456/1000\n",
      "6/6 - 0s - loss: 87.3904 - val_loss: 535.4309\n",
      "Epoch 457/1000\n",
      "6/6 - 0s - loss: 87.3040 - val_loss: 535.1690\n",
      "Epoch 458/1000\n",
      "6/6 - 0s - loss: 87.2101 - val_loss: 534.9161\n",
      "Epoch 459/1000\n",
      "6/6 - 0s - loss: 87.1279 - val_loss: 534.6645\n",
      "Epoch 460/1000\n",
      "6/6 - 0s - loss: 87.0422 - val_loss: 534.4199\n",
      "Epoch 461/1000\n",
      "6/6 - 0s - loss: 86.9623 - val_loss: 534.1594\n",
      "Epoch 462/1000\n",
      "6/6 - 0s - loss: 86.8706 - val_loss: 533.9169\n",
      "Epoch 463/1000\n",
      "6/6 - 0s - loss: 86.7880 - val_loss: 533.6703\n",
      "Epoch 464/1000\n",
      "6/6 - 0s - loss: 86.7010 - val_loss: 533.4228\n",
      "Epoch 465/1000\n",
      "6/6 - 0s - loss: 86.6265 - val_loss: 533.1656\n",
      "Epoch 466/1000\n",
      "6/6 - 0s - loss: 86.5352 - val_loss: 532.9213\n",
      "Epoch 467/1000\n",
      "6/6 - 0s - loss: 86.4517 - val_loss: 532.6846\n",
      "Epoch 468/1000\n",
      "6/6 - 0s - loss: 86.3705 - val_loss: 532.4348\n",
      "Epoch 469/1000\n",
      "6/6 - 0s - loss: 86.2903 - val_loss: 532.1965\n",
      "Epoch 470/1000\n",
      "6/6 - 0s - loss: 86.2031 - val_loss: 531.9609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 471/1000\n",
      "6/6 - 0s - loss: 86.1246 - val_loss: 531.7088\n",
      "Epoch 472/1000\n",
      "6/6 - 0s - loss: 86.0373 - val_loss: 531.4604\n",
      "Epoch 473/1000\n",
      "6/6 - 0s - loss: 85.9493 - val_loss: 531.2205\n",
      "Epoch 474/1000\n",
      "6/6 - 0s - loss: 85.8748 - val_loss: 530.9553\n",
      "Epoch 475/1000\n",
      "6/6 - 0s - loss: 85.7740 - val_loss: 530.7048\n",
      "Epoch 476/1000\n",
      "6/6 - 0s - loss: 85.6924 - val_loss: 530.4247\n",
      "Epoch 477/1000\n",
      "6/6 - 0s - loss: 85.6039 - val_loss: 530.1529\n",
      "Epoch 478/1000\n",
      "6/6 - 0s - loss: 85.5072 - val_loss: 529.8934\n",
      "Epoch 479/1000\n",
      "6/6 - 0s - loss: 85.4255 - val_loss: 529.6110\n",
      "Epoch 480/1000\n",
      "6/6 - 0s - loss: 85.3235 - val_loss: 529.3483\n",
      "Epoch 481/1000\n",
      "6/6 - 0s - loss: 85.2441 - val_loss: 529.0696\n",
      "Epoch 482/1000\n",
      "6/6 - 0s - loss: 85.1558 - val_loss: 528.8123\n",
      "Epoch 483/1000\n",
      "6/6 - 0s - loss: 85.0694 - val_loss: 528.5371\n",
      "Epoch 484/1000\n",
      "6/6 - 0s - loss: 84.9769 - val_loss: 528.2839\n",
      "Epoch 485/1000\n",
      "6/6 - 0s - loss: 84.9093 - val_loss: 528.0280\n",
      "Epoch 486/1000\n",
      "6/6 - 0s - loss: 84.8130 - val_loss: 527.8064\n",
      "Epoch 487/1000\n",
      "6/6 - 0s - loss: 84.7306 - val_loss: 527.5635\n",
      "Epoch 488/1000\n",
      "6/6 - 0s - loss: 84.6456 - val_loss: 527.2948\n",
      "Epoch 489/1000\n",
      "6/6 - 0s - loss: 84.5569 - val_loss: 527.0299\n",
      "Epoch 490/1000\n",
      "6/6 - 0s - loss: 84.4852 - val_loss: 526.7579\n",
      "Epoch 491/1000\n",
      "6/6 - 0s - loss: 84.3896 - val_loss: 526.4854\n",
      "Epoch 492/1000\n",
      "6/6 - 0s - loss: 84.2955 - val_loss: 526.2391\n",
      "Epoch 493/1000\n",
      "6/6 - 0s - loss: 84.2078 - val_loss: 526.0002\n",
      "Epoch 494/1000\n",
      "6/6 - 0s - loss: 84.1310 - val_loss: 525.7614\n",
      "Epoch 495/1000\n",
      "6/6 - 0s - loss: 84.0407 - val_loss: 525.5005\n",
      "Epoch 496/1000\n",
      "6/6 - 0s - loss: 83.9597 - val_loss: 525.1997\n",
      "Epoch 497/1000\n",
      "6/6 - 0s - loss: 83.8674 - val_loss: 524.9500\n",
      "Epoch 498/1000\n",
      "6/6 - 0s - loss: 83.7769 - val_loss: 524.7122\n",
      "Epoch 499/1000\n",
      "6/6 - 0s - loss: 83.6902 - val_loss: 524.4680\n",
      "Epoch 500/1000\n",
      "6/6 - 0s - loss: 83.6005 - val_loss: 524.2130\n",
      "Epoch 501/1000\n",
      "6/6 - 0s - loss: 83.5174 - val_loss: 523.9438\n",
      "Epoch 502/1000\n",
      "6/6 - 0s - loss: 83.4354 - val_loss: 523.7092\n",
      "Epoch 503/1000\n",
      "6/6 - 0s - loss: 83.3477 - val_loss: 523.4853\n",
      "Epoch 504/1000\n",
      "6/6 - 0s - loss: 83.2655 - val_loss: 523.2682\n",
      "Epoch 505/1000\n",
      "6/6 - 0s - loss: 83.1806 - val_loss: 523.0369\n",
      "Epoch 506/1000\n",
      "6/6 - 0s - loss: 83.1121 - val_loss: 522.7608\n",
      "Epoch 507/1000\n",
      "6/6 - 0s - loss: 83.0190 - val_loss: 522.5145\n",
      "Epoch 508/1000\n",
      "6/6 - 0s - loss: 82.9350 - val_loss: 522.2767\n",
      "Epoch 509/1000\n",
      "6/6 - 0s - loss: 82.8540 - val_loss: 522.0308\n",
      "Epoch 510/1000\n",
      "6/6 - 0s - loss: 82.7590 - val_loss: 521.7894\n",
      "Epoch 511/1000\n",
      "6/6 - 0s - loss: 82.6844 - val_loss: 521.5354\n",
      "Epoch 512/1000\n",
      "6/6 - 0s - loss: 82.5995 - val_loss: 521.2828\n",
      "Epoch 513/1000\n",
      "6/6 - 0s - loss: 82.5161 - val_loss: 521.0413\n",
      "Epoch 514/1000\n",
      "6/6 - 0s - loss: 82.4379 - val_loss: 520.7988\n",
      "Epoch 515/1000\n",
      "6/6 - 0s - loss: 82.3470 - val_loss: 520.5661\n",
      "Epoch 516/1000\n",
      "6/6 - 0s - loss: 82.2650 - val_loss: 520.3031\n",
      "Epoch 517/1000\n",
      "6/6 - 0s - loss: 82.1853 - val_loss: 520.0278\n",
      "Epoch 518/1000\n",
      "6/6 - 0s - loss: 82.0951 - val_loss: 519.7712\n",
      "Epoch 519/1000\n",
      "6/6 - 0s - loss: 82.0050 - val_loss: 519.5414\n",
      "Epoch 520/1000\n",
      "6/6 - 0s - loss: 81.9260 - val_loss: 519.3036\n",
      "Epoch 521/1000\n",
      "6/6 - 0s - loss: 81.8489 - val_loss: 519.0486\n",
      "Epoch 522/1000\n",
      "6/6 - 0s - loss: 81.7665 - val_loss: 518.8079\n",
      "Epoch 523/1000\n",
      "6/6 - 0s - loss: 81.6755 - val_loss: 518.5771\n",
      "Epoch 524/1000\n",
      "6/6 - 0s - loss: 81.5987 - val_loss: 518.3267\n",
      "Epoch 525/1000\n",
      "6/6 - 0s - loss: 81.5232 - val_loss: 518.0742\n",
      "Epoch 526/1000\n",
      "6/6 - 0s - loss: 81.4439 - val_loss: 517.8087\n",
      "Epoch 527/1000\n",
      "6/6 - 0s - loss: 81.3619 - val_loss: 517.5481\n",
      "Epoch 528/1000\n",
      "6/6 - 0s - loss: 81.2652 - val_loss: 517.3139\n",
      "Epoch 529/1000\n",
      "6/6 - 0s - loss: 81.1951 - val_loss: 517.0806\n",
      "Epoch 530/1000\n",
      "6/6 - 0s - loss: 81.1066 - val_loss: 516.8349\n",
      "Epoch 531/1000\n",
      "6/6 - 0s - loss: 81.0298 - val_loss: 516.5580\n",
      "Epoch 532/1000\n",
      "6/6 - 0s - loss: 80.9423 - val_loss: 516.2911\n",
      "Epoch 533/1000\n",
      "6/6 - 0s - loss: 80.8608 - val_loss: 516.0228\n",
      "Epoch 534/1000\n",
      "6/6 - 0s - loss: 80.7656 - val_loss: 515.7584\n",
      "Epoch 535/1000\n",
      "6/6 - 0s - loss: 80.6850 - val_loss: 515.5021\n",
      "Epoch 536/1000\n",
      "6/6 - 0s - loss: 80.6010 - val_loss: 515.2662\n",
      "Epoch 537/1000\n",
      "6/6 - 0s - loss: 80.5355 - val_loss: 514.9960\n",
      "Epoch 538/1000\n",
      "6/6 - 0s - loss: 80.4429 - val_loss: 514.7416\n",
      "Epoch 539/1000\n",
      "6/6 - 0s - loss: 80.3614 - val_loss: 514.4930\n",
      "Epoch 540/1000\n",
      "6/6 - 0s - loss: 80.2766 - val_loss: 514.2392\n",
      "Epoch 541/1000\n",
      "6/6 - 0s - loss: 80.1935 - val_loss: 513.9964\n",
      "Epoch 542/1000\n",
      "6/6 - 0s - loss: 80.1143 - val_loss: 513.7372\n",
      "Epoch 543/1000\n",
      "6/6 - 0s - loss: 80.0311 - val_loss: 513.4915\n",
      "Epoch 544/1000\n",
      "6/6 - 0s - loss: 79.9486 - val_loss: 513.2256\n",
      "Epoch 545/1000\n",
      "6/6 - 0s - loss: 79.8632 - val_loss: 512.9584\n",
      "Epoch 546/1000\n",
      "6/6 - 0s - loss: 79.7792 - val_loss: 512.6910\n",
      "Epoch 547/1000\n",
      "6/6 - 0s - loss: 79.6968 - val_loss: 512.4164\n",
      "Epoch 548/1000\n",
      "6/6 - 0s - loss: 79.6070 - val_loss: 512.1609\n",
      "Epoch 549/1000\n",
      "6/6 - 0s - loss: 79.5198 - val_loss: 511.9030\n",
      "Epoch 550/1000\n",
      "6/6 - 0s - loss: 79.4384 - val_loss: 511.6378\n",
      "Epoch 551/1000\n",
      "6/6 - 0s - loss: 79.3624 - val_loss: 511.3502\n",
      "Epoch 552/1000\n",
      "6/6 - 0s - loss: 79.2663 - val_loss: 511.0822\n",
      "Epoch 553/1000\n",
      "6/6 - 0s - loss: 79.1799 - val_loss: 510.8117\n",
      "Epoch 554/1000\n",
      "6/6 - 0s - loss: 79.0890 - val_loss: 510.5639\n",
      "Epoch 555/1000\n",
      "6/6 - 0s - loss: 79.0009 - val_loss: 510.2909\n",
      "Epoch 556/1000\n",
      "6/6 - 0s - loss: 78.9226 - val_loss: 510.0199\n",
      "Epoch 557/1000\n",
      "6/6 - 0s - loss: 78.8387 - val_loss: 509.7834\n",
      "Epoch 558/1000\n",
      "6/6 - 0s - loss: 78.7593 - val_loss: 509.5459\n",
      "Epoch 559/1000\n",
      "6/6 - 0s - loss: 78.6805 - val_loss: 509.3025\n",
      "Epoch 560/1000\n",
      "6/6 - 0s - loss: 78.6022 - val_loss: 509.0701\n",
      "Epoch 561/1000\n",
      "6/6 - 0s - loss: 78.5189 - val_loss: 508.8281\n",
      "Epoch 562/1000\n",
      "6/6 - 0s - loss: 78.4449 - val_loss: 508.5868\n",
      "Epoch 563/1000\n",
      "6/6 - 0s - loss: 78.3623 - val_loss: 508.3519\n",
      "Epoch 564/1000\n",
      "6/6 - 0s - loss: 78.2817 - val_loss: 508.1133\n",
      "Epoch 565/1000\n",
      "6/6 - 0s - loss: 78.2120 - val_loss: 507.8737\n",
      "Epoch 566/1000\n",
      "6/6 - 0s - loss: 78.1234 - val_loss: 507.6301\n",
      "Epoch 567/1000\n",
      "6/6 - 0s - loss: 78.0513 - val_loss: 507.3703\n",
      "Epoch 568/1000\n",
      "6/6 - 0s - loss: 77.9586 - val_loss: 507.1299\n",
      "Epoch 569/1000\n",
      "6/6 - 0s - loss: 77.8896 - val_loss: 506.8700\n",
      "Epoch 570/1000\n",
      "6/6 - 0s - loss: 77.8037 - val_loss: 506.6141\n",
      "Epoch 571/1000\n",
      "6/6 - 0s - loss: 77.7247 - val_loss: 506.4074\n",
      "Epoch 572/1000\n",
      "6/6 - 0s - loss: 77.6522 - val_loss: 506.1630\n",
      "Epoch 573/1000\n",
      "6/6 - 0s - loss: 77.5751 - val_loss: 505.9073\n",
      "Epoch 574/1000\n",
      "6/6 - 0s - loss: 77.4992 - val_loss: 505.6738\n",
      "Epoch 575/1000\n",
      "6/6 - 0s - loss: 77.4116 - val_loss: 505.4571\n",
      "Epoch 576/1000\n",
      "6/6 - 0s - loss: 77.3391 - val_loss: 505.2216\n",
      "Epoch 577/1000\n",
      "6/6 - 0s - loss: 77.2680 - val_loss: 504.9592\n",
      "Epoch 578/1000\n",
      "6/6 - 0s - loss: 77.1884 - val_loss: 504.7064\n",
      "Epoch 579/1000\n",
      "6/6 - 0s - loss: 77.1068 - val_loss: 504.4555\n",
      "Epoch 580/1000\n",
      "6/6 - 0s - loss: 77.0171 - val_loss: 504.2220\n",
      "Epoch 581/1000\n",
      "6/6 - 0s - loss: 76.9422 - val_loss: 504.0009\n",
      "Epoch 582/1000\n",
      "6/6 - 0s - loss: 76.8799 - val_loss: 503.7528\n",
      "Epoch 583/1000\n",
      "6/6 - 0s - loss: 76.7913 - val_loss: 503.5111\n",
      "Epoch 584/1000\n",
      "6/6 - 0s - loss: 76.7112 - val_loss: 503.2527\n",
      "Epoch 585/1000\n",
      "6/6 - 0s - loss: 76.6345 - val_loss: 503.0224\n",
      "Epoch 586/1000\n",
      "6/6 - 0s - loss: 76.5580 - val_loss: 502.7725\n",
      "Epoch 587/1000\n",
      "6/6 - 0s - loss: 76.4734 - val_loss: 502.5379\n",
      "Epoch 588/1000\n",
      "6/6 - 0s - loss: 76.3983 - val_loss: 502.2965\n",
      "Epoch 589/1000\n",
      "6/6 - 0s - loss: 76.3276 - val_loss: 502.0216\n",
      "Epoch 590/1000\n",
      "6/6 - 0s - loss: 76.2506 - val_loss: 501.7892\n",
      "Epoch 591/1000\n",
      "6/6 - 0s - loss: 76.1645 - val_loss: 501.5651\n",
      "Epoch 592/1000\n",
      "6/6 - 0s - loss: 76.0900 - val_loss: 501.3331\n",
      "Epoch 593/1000\n",
      "6/6 - 0s - loss: 76.0120 - val_loss: 501.0768\n",
      "Epoch 594/1000\n",
      "6/6 - 0s - loss: 75.9374 - val_loss: 500.8361\n",
      "Epoch 595/1000\n",
      "6/6 - 0s - loss: 75.8506 - val_loss: 500.5992\n",
      "Epoch 596/1000\n",
      "6/6 - 0s - loss: 75.7812 - val_loss: 500.3535\n",
      "Epoch 597/1000\n",
      "6/6 - 0s - loss: 75.7056 - val_loss: 500.1038\n",
      "Epoch 598/1000\n",
      "6/6 - 0s - loss: 75.6249 - val_loss: 499.8687\n",
      "Epoch 599/1000\n",
      "6/6 - 0s - loss: 75.5505 - val_loss: 499.6327\n",
      "Epoch 600/1000\n",
      "6/6 - 0s - loss: 75.4798 - val_loss: 499.3944\n",
      "Epoch 601/1000\n",
      "6/6 - 0s - loss: 75.3993 - val_loss: 499.1667\n",
      "Epoch 602/1000\n",
      "6/6 - 0s - loss: 75.3319 - val_loss: 498.9269\n",
      "Epoch 603/1000\n",
      "6/6 - 0s - loss: 75.2450 - val_loss: 498.7062\n",
      "Epoch 604/1000\n",
      "6/6 - 0s - loss: 75.1678 - val_loss: 498.4554\n",
      "Epoch 605/1000\n",
      "6/6 - 0s - loss: 75.0970 - val_loss: 498.1899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 606/1000\n",
      "6/6 - 0s - loss: 75.0176 - val_loss: 497.9123\n",
      "Epoch 607/1000\n",
      "6/6 - 0s - loss: 74.9309 - val_loss: 497.6562\n",
      "Epoch 608/1000\n",
      "6/6 - 0s - loss: 74.8467 - val_loss: 497.4263\n",
      "Epoch 609/1000\n",
      "6/6 - 0s - loss: 74.7754 - val_loss: 497.1927\n",
      "Epoch 610/1000\n",
      "6/6 - 0s - loss: 74.7046 - val_loss: 496.9590\n",
      "Epoch 611/1000\n",
      "6/6 - 0s - loss: 74.6347 - val_loss: 496.7383\n",
      "Epoch 612/1000\n",
      "6/6 - 0s - loss: 74.5635 - val_loss: 496.4993\n",
      "Epoch 613/1000\n",
      "6/6 - 0s - loss: 74.4839 - val_loss: 496.2829\n",
      "Epoch 614/1000\n",
      "6/6 - 0s - loss: 74.4171 - val_loss: 496.0779\n",
      "Epoch 615/1000\n",
      "6/6 - 0s - loss: 74.3582 - val_loss: 495.8206\n",
      "Epoch 616/1000\n",
      "6/6 - 0s - loss: 74.2769 - val_loss: 495.5764\n",
      "Epoch 617/1000\n",
      "6/6 - 0s - loss: 74.1974 - val_loss: 495.3817\n",
      "Epoch 618/1000\n",
      "6/6 - 0s - loss: 74.1241 - val_loss: 495.1363\n",
      "Epoch 619/1000\n",
      "6/6 - 0s - loss: 74.0586 - val_loss: 494.8622\n",
      "Epoch 620/1000\n",
      "6/6 - 0s - loss: 73.9674 - val_loss: 494.6184\n",
      "Epoch 621/1000\n",
      "6/6 - 0s - loss: 73.8920 - val_loss: 494.3732\n",
      "Epoch 622/1000\n",
      "6/6 - 0s - loss: 73.8127 - val_loss: 494.1329\n",
      "Epoch 623/1000\n",
      "6/6 - 0s - loss: 73.7339 - val_loss: 493.8985\n",
      "Epoch 624/1000\n",
      "6/6 - 0s - loss: 73.6594 - val_loss: 493.6366\n",
      "Epoch 625/1000\n",
      "6/6 - 0s - loss: 73.5898 - val_loss: 493.3631\n",
      "Epoch 626/1000\n",
      "6/6 - 0s - loss: 73.5011 - val_loss: 493.1335\n",
      "Epoch 627/1000\n",
      "6/6 - 0s - loss: 73.4268 - val_loss: 492.8805\n",
      "Epoch 628/1000\n",
      "6/6 - 0s - loss: 73.3530 - val_loss: 492.6302\n",
      "Epoch 629/1000\n",
      "6/6 - 0s - loss: 73.2740 - val_loss: 492.3854\n",
      "Epoch 630/1000\n",
      "6/6 - 0s - loss: 73.2056 - val_loss: 492.1236\n",
      "Epoch 631/1000\n",
      "6/6 - 0s - loss: 73.1184 - val_loss: 491.8988\n",
      "Epoch 632/1000\n",
      "6/6 - 0s - loss: 73.0447 - val_loss: 491.6664\n",
      "Epoch 633/1000\n",
      "6/6 - 0s - loss: 72.9683 - val_loss: 491.3983\n",
      "Epoch 634/1000\n",
      "6/6 - 0s - loss: 72.8840 - val_loss: 491.1625\n",
      "Epoch 635/1000\n",
      "6/6 - 0s - loss: 72.8077 - val_loss: 490.9369\n",
      "Epoch 636/1000\n",
      "6/6 - 0s - loss: 72.7386 - val_loss: 490.6796\n",
      "Epoch 637/1000\n",
      "6/6 - 0s - loss: 72.6616 - val_loss: 490.4348\n",
      "Epoch 638/1000\n",
      "6/6 - 0s - loss: 72.5771 - val_loss: 490.2186\n",
      "Epoch 639/1000\n",
      "6/6 - 0s - loss: 72.5174 - val_loss: 489.9622\n",
      "Epoch 640/1000\n",
      "6/6 - 0s - loss: 72.4433 - val_loss: 489.7061\n",
      "Epoch 641/1000\n",
      "6/6 - 0s - loss: 72.3678 - val_loss: 489.4562\n",
      "Epoch 642/1000\n",
      "6/6 - 0s - loss: 72.2909 - val_loss: 489.2563\n",
      "Epoch 643/1000\n",
      "6/6 - 0s - loss: 72.2271 - val_loss: 489.0112\n",
      "Epoch 644/1000\n",
      "6/6 - 0s - loss: 72.1446 - val_loss: 488.8163\n",
      "Epoch 645/1000\n",
      "6/6 - 0s - loss: 72.0792 - val_loss: 488.6040\n",
      "Epoch 646/1000\n",
      "6/6 - 0s - loss: 72.0148 - val_loss: 488.3653\n",
      "Epoch 647/1000\n",
      "6/6 - 0s - loss: 71.9427 - val_loss: 488.1450\n",
      "Epoch 648/1000\n",
      "6/6 - 0s - loss: 71.8753 - val_loss: 487.9105\n",
      "Epoch 649/1000\n",
      "6/6 - 0s - loss: 71.8046 - val_loss: 487.6995\n",
      "Epoch 650/1000\n",
      "6/6 - 0s - loss: 71.7307 - val_loss: 487.4700\n",
      "Epoch 651/1000\n",
      "6/6 - 0s - loss: 71.6604 - val_loss: 487.2777\n",
      "Epoch 652/1000\n",
      "6/6 - 0s - loss: 71.5946 - val_loss: 487.0567\n",
      "Epoch 653/1000\n",
      "6/6 - 0s - loss: 71.5206 - val_loss: 486.8398\n",
      "Epoch 654/1000\n",
      "6/6 - 0s - loss: 71.4588 - val_loss: 486.5979\n",
      "Epoch 655/1000\n",
      "6/6 - 0s - loss: 71.3778 - val_loss: 486.3618\n",
      "Epoch 656/1000\n",
      "6/6 - 0s - loss: 71.3043 - val_loss: 486.1512\n",
      "Epoch 657/1000\n",
      "6/6 - 0s - loss: 71.2310 - val_loss: 485.9193\n",
      "Epoch 658/1000\n",
      "6/6 - 0s - loss: 71.1653 - val_loss: 485.7125\n",
      "Epoch 659/1000\n",
      "6/6 - 0s - loss: 71.0921 - val_loss: 485.4736\n",
      "Epoch 660/1000\n",
      "6/6 - 0s - loss: 71.0204 - val_loss: 485.2306\n",
      "Epoch 661/1000\n",
      "6/6 - 0s - loss: 70.9498 - val_loss: 484.9916\n",
      "Epoch 662/1000\n",
      "6/6 - 0s - loss: 70.8724 - val_loss: 484.7675\n",
      "Epoch 663/1000\n",
      "6/6 - 0s - loss: 70.8048 - val_loss: 484.5350\n",
      "Epoch 664/1000\n",
      "6/6 - 0s - loss: 70.7368 - val_loss: 484.2946\n",
      "Epoch 665/1000\n",
      "6/6 - 0s - loss: 70.6686 - val_loss: 484.0796\n",
      "Epoch 666/1000\n",
      "6/6 - 0s - loss: 70.5984 - val_loss: 483.8562\n",
      "Epoch 667/1000\n",
      "6/6 - 0s - loss: 70.5307 - val_loss: 483.6207\n",
      "Epoch 668/1000\n",
      "6/6 - 0s - loss: 70.4620 - val_loss: 483.3801\n",
      "Epoch 669/1000\n",
      "6/6 - 0s - loss: 70.3879 - val_loss: 483.1615\n",
      "Epoch 670/1000\n",
      "6/6 - 0s - loss: 70.3202 - val_loss: 482.9368\n",
      "Epoch 671/1000\n",
      "6/6 - 0s - loss: 70.2623 - val_loss: 482.7295\n",
      "Epoch 672/1000\n",
      "6/6 - 0s - loss: 70.1914 - val_loss: 482.4995\n",
      "Epoch 673/1000\n",
      "6/6 - 0s - loss: 70.1268 - val_loss: 482.2875\n",
      "Epoch 674/1000\n",
      "6/6 - 0s - loss: 70.0609 - val_loss: 482.0760\n",
      "Epoch 675/1000\n",
      "6/6 - 0s - loss: 69.9930 - val_loss: 481.8500\n",
      "Epoch 676/1000\n",
      "6/6 - 0s - loss: 69.9324 - val_loss: 481.6288\n",
      "Epoch 677/1000\n",
      "6/6 - 0s - loss: 69.8565 - val_loss: 481.4086\n",
      "Epoch 678/1000\n",
      "6/6 - 0s - loss: 69.7900 - val_loss: 481.1777\n",
      "Epoch 679/1000\n",
      "6/6 - 0s - loss: 69.7236 - val_loss: 480.9503\n",
      "Epoch 680/1000\n",
      "6/6 - 0s - loss: 69.6607 - val_loss: 480.7068\n",
      "Epoch 681/1000\n",
      "6/6 - 0s - loss: 69.5805 - val_loss: 480.4791\n",
      "Epoch 682/1000\n",
      "6/6 - 0s - loss: 69.5199 - val_loss: 480.2155\n",
      "Epoch 683/1000\n",
      "6/6 - 0s - loss: 69.4439 - val_loss: 479.9477\n",
      "Epoch 684/1000\n",
      "6/6 - 0s - loss: 69.3666 - val_loss: 479.7320\n",
      "Epoch 685/1000\n",
      "6/6 - 0s - loss: 69.3022 - val_loss: 479.4777\n",
      "Epoch 686/1000\n",
      "6/6 - 0s - loss: 69.2227 - val_loss: 479.2470\n",
      "Epoch 687/1000\n",
      "6/6 - 0s - loss: 69.1623 - val_loss: 479.0422\n",
      "Epoch 688/1000\n",
      "6/6 - 0s - loss: 69.0955 - val_loss: 478.8118\n",
      "Epoch 689/1000\n",
      "6/6 - 0s - loss: 69.0243 - val_loss: 478.5798\n",
      "Epoch 690/1000\n",
      "6/6 - 0s - loss: 68.9657 - val_loss: 478.3577\n",
      "Epoch 691/1000\n",
      "6/6 - 0s - loss: 68.8936 - val_loss: 478.1399\n",
      "Epoch 692/1000\n",
      "6/6 - 0s - loss: 68.8283 - val_loss: 477.9375\n",
      "Epoch 693/1000\n",
      "6/6 - 0s - loss: 68.7641 - val_loss: 477.7102\n",
      "Epoch 694/1000\n",
      "6/6 - 0s - loss: 68.6964 - val_loss: 477.4979\n",
      "Epoch 695/1000\n",
      "6/6 - 0s - loss: 68.6364 - val_loss: 477.2668\n",
      "Epoch 696/1000\n",
      "6/6 - 0s - loss: 68.5662 - val_loss: 477.0564\n",
      "Epoch 697/1000\n",
      "6/6 - 0s - loss: 68.5065 - val_loss: 476.8373\n",
      "Epoch 698/1000\n",
      "6/6 - 0s - loss: 68.4270 - val_loss: 476.6378\n",
      "Epoch 699/1000\n",
      "6/6 - 0s - loss: 68.3741 - val_loss: 476.4166\n",
      "Epoch 700/1000\n",
      "6/6 - 0s - loss: 68.3051 - val_loss: 476.2016\n",
      "Epoch 701/1000\n",
      "6/6 - 0s - loss: 68.2384 - val_loss: 475.9956\n",
      "Epoch 702/1000\n",
      "6/6 - 0s - loss: 68.1771 - val_loss: 475.7725\n",
      "Epoch 703/1000\n",
      "6/6 - 0s - loss: 68.0995 - val_loss: 475.5812\n",
      "Epoch 704/1000\n",
      "6/6 - 0s - loss: 68.0441 - val_loss: 475.3372\n",
      "Epoch 705/1000\n",
      "6/6 - 0s - loss: 67.9685 - val_loss: 475.1075\n",
      "Epoch 706/1000\n",
      "6/6 - 0s - loss: 67.9070 - val_loss: 474.8565\n",
      "Epoch 707/1000\n",
      "6/6 - 0s - loss: 67.8229 - val_loss: 474.6346\n",
      "Epoch 708/1000\n",
      "6/6 - 0s - loss: 67.7628 - val_loss: 474.4208\n",
      "Epoch 709/1000\n",
      "6/6 - 0s - loss: 67.6906 - val_loss: 474.1941\n",
      "Epoch 710/1000\n",
      "6/6 - 0s - loss: 67.6293 - val_loss: 473.9940\n",
      "Epoch 711/1000\n",
      "6/6 - 0s - loss: 67.5629 - val_loss: 473.7508\n",
      "Epoch 712/1000\n",
      "6/6 - 0s - loss: 67.5013 - val_loss: 473.5309\n",
      "Epoch 713/1000\n",
      "6/6 - 0s - loss: 67.4194 - val_loss: 473.3146\n",
      "Epoch 714/1000\n",
      "6/6 - 0s - loss: 67.3586 - val_loss: 473.0924\n",
      "Epoch 715/1000\n",
      "6/6 - 0s - loss: 67.2862 - val_loss: 472.8680\n",
      "Epoch 716/1000\n",
      "6/6 - 0s - loss: 67.2294 - val_loss: 472.6581\n",
      "Epoch 717/1000\n",
      "6/6 - 0s - loss: 67.1593 - val_loss: 472.4345\n",
      "Epoch 718/1000\n",
      "6/6 - 0s - loss: 67.0939 - val_loss: 472.2103\n",
      "Epoch 719/1000\n",
      "6/6 - 0s - loss: 67.0324 - val_loss: 471.9673\n",
      "Epoch 720/1000\n",
      "6/6 - 0s - loss: 66.9602 - val_loss: 471.7511\n",
      "Epoch 721/1000\n",
      "6/6 - 0s - loss: 66.8914 - val_loss: 471.5422\n",
      "Epoch 722/1000\n",
      "6/6 - 0s - loss: 66.8340 - val_loss: 471.3313\n",
      "Epoch 723/1000\n",
      "6/6 - 0s - loss: 66.7705 - val_loss: 471.1284\n",
      "Epoch 724/1000\n",
      "6/6 - 0s - loss: 66.7112 - val_loss: 470.9185\n",
      "Epoch 725/1000\n",
      "6/6 - 0s - loss: 66.6488 - val_loss: 470.7186\n",
      "Epoch 726/1000\n",
      "6/6 - 0s - loss: 66.5867 - val_loss: 470.5110\n",
      "Epoch 727/1000\n",
      "6/6 - 0s - loss: 66.5295 - val_loss: 470.3007\n",
      "Epoch 728/1000\n",
      "6/6 - 0s - loss: 66.4636 - val_loss: 470.0957\n",
      "Epoch 729/1000\n",
      "6/6 - 0s - loss: 66.4016 - val_loss: 469.8876\n",
      "Epoch 730/1000\n",
      "6/6 - 0s - loss: 66.3471 - val_loss: 469.6739\n",
      "Epoch 731/1000\n",
      "6/6 - 0s - loss: 66.2747 - val_loss: 469.4762\n",
      "Epoch 732/1000\n",
      "6/6 - 0s - loss: 66.2174 - val_loss: 469.2644\n",
      "Epoch 733/1000\n",
      "6/6 - 0s - loss: 66.1545 - val_loss: 469.0516\n",
      "Epoch 734/1000\n",
      "6/6 - 0s - loss: 66.0996 - val_loss: 468.8430\n",
      "Epoch 735/1000\n",
      "6/6 - 0s - loss: 66.0276 - val_loss: 468.6581\n",
      "Epoch 736/1000\n",
      "6/6 - 0s - loss: 65.9741 - val_loss: 468.4287\n",
      "Epoch 737/1000\n",
      "6/6 - 0s - loss: 65.9013 - val_loss: 468.2366\n",
      "Epoch 738/1000\n",
      "6/6 - 0s - loss: 65.8401 - val_loss: 467.9930\n",
      "Epoch 739/1000\n",
      "6/6 - 0s - loss: 65.7708 - val_loss: 467.7535\n",
      "Epoch 740/1000\n",
      "6/6 - 0s - loss: 65.7081 - val_loss: 467.4951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 741/1000\n",
      "6/6 - 0s - loss: 65.6353 - val_loss: 467.2682\n",
      "Epoch 742/1000\n",
      "6/6 - 0s - loss: 65.5648 - val_loss: 467.0540\n",
      "Epoch 743/1000\n",
      "6/6 - 0s - loss: 65.5079 - val_loss: 466.8394\n",
      "Epoch 744/1000\n",
      "6/6 - 0s - loss: 65.4399 - val_loss: 466.6341\n",
      "Epoch 745/1000\n",
      "6/6 - 0s - loss: 65.3903 - val_loss: 466.4138\n",
      "Epoch 746/1000\n",
      "6/6 - 0s - loss: 65.3244 - val_loss: 466.1858\n",
      "Epoch 747/1000\n",
      "6/6 - 0s - loss: 65.2626 - val_loss: 465.9944\n",
      "Epoch 748/1000\n",
      "6/6 - 0s - loss: 65.2048 - val_loss: 465.7633\n",
      "Epoch 749/1000\n",
      "6/6 - 0s - loss: 65.1374 - val_loss: 465.5719\n",
      "Epoch 750/1000\n",
      "6/6 - 0s - loss: 65.0759 - val_loss: 465.3685\n",
      "Epoch 751/1000\n",
      "6/6 - 0s - loss: 65.0152 - val_loss: 465.1563\n",
      "Epoch 752/1000\n",
      "6/6 - 0s - loss: 64.9651 - val_loss: 464.9285\n",
      "Epoch 753/1000\n",
      "6/6 - 0s - loss: 64.8914 - val_loss: 464.7076\n",
      "Epoch 754/1000\n",
      "6/6 - 0s - loss: 64.8293 - val_loss: 464.4966\n",
      "Epoch 755/1000\n",
      "6/6 - 0s - loss: 64.7659 - val_loss: 464.2943\n",
      "Epoch 756/1000\n",
      "6/6 - 0s - loss: 64.7059 - val_loss: 464.0492\n",
      "Epoch 757/1000\n",
      "6/6 - 0s - loss: 64.6454 - val_loss: 463.8701\n",
      "Epoch 758/1000\n",
      "6/6 - 0s - loss: 64.5766 - val_loss: 463.6196\n",
      "Epoch 759/1000\n",
      "6/6 - 0s - loss: 64.5109 - val_loss: 463.4305\n",
      "Epoch 760/1000\n",
      "6/6 - 0s - loss: 64.4484 - val_loss: 463.2227\n",
      "Epoch 761/1000\n",
      "6/6 - 0s - loss: 64.3859 - val_loss: 462.9902\n",
      "Epoch 762/1000\n",
      "6/6 - 0s - loss: 64.3222 - val_loss: 462.7575\n",
      "Epoch 763/1000\n",
      "6/6 - 0s - loss: 64.2397 - val_loss: 462.5252\n",
      "Epoch 764/1000\n",
      "6/6 - 0s - loss: 64.1860 - val_loss: 462.3365\n",
      "Epoch 765/1000\n",
      "6/6 - 0s - loss: 64.1272 - val_loss: 462.1201\n",
      "Epoch 766/1000\n",
      "6/6 - 0s - loss: 64.0605 - val_loss: 461.9352\n",
      "Epoch 767/1000\n",
      "6/6 - 0s - loss: 63.9980 - val_loss: 461.7147\n",
      "Epoch 768/1000\n",
      "6/6 - 0s - loss: 63.9406 - val_loss: 461.5206\n",
      "Epoch 769/1000\n",
      "6/6 - 0s - loss: 63.8773 - val_loss: 461.2851\n",
      "Epoch 770/1000\n",
      "6/6 - 0s - loss: 63.8225 - val_loss: 461.1142\n",
      "Epoch 771/1000\n",
      "6/6 - 0s - loss: 63.7544 - val_loss: 460.8808\n",
      "Epoch 772/1000\n",
      "6/6 - 0s - loss: 63.6894 - val_loss: 460.7295\n",
      "Epoch 773/1000\n",
      "6/6 - 0s - loss: 63.6368 - val_loss: 460.5108\n",
      "Epoch 774/1000\n",
      "6/6 - 0s - loss: 63.5788 - val_loss: 460.3296\n",
      "Epoch 775/1000\n",
      "6/6 - 0s - loss: 63.5184 - val_loss: 460.0974\n",
      "Epoch 776/1000\n",
      "6/6 - 0s - loss: 63.4564 - val_loss: 459.9230\n",
      "Epoch 777/1000\n",
      "6/6 - 0s - loss: 63.4003 - val_loss: 459.6638\n",
      "Epoch 778/1000\n",
      "6/6 - 0s - loss: 63.3329 - val_loss: 459.4880\n",
      "Epoch 779/1000\n",
      "6/6 - 0s - loss: 63.2699 - val_loss: 459.2386\n",
      "Epoch 780/1000\n",
      "6/6 - 0s - loss: 63.2063 - val_loss: 459.0497\n",
      "Epoch 781/1000\n",
      "6/6 - 0s - loss: 63.1402 - val_loss: 458.8253\n",
      "Epoch 782/1000\n",
      "6/6 - 0s - loss: 63.0889 - val_loss: 458.6431\n",
      "Epoch 783/1000\n",
      "6/6 - 0s - loss: 63.0217 - val_loss: 458.4244\n",
      "Epoch 784/1000\n",
      "6/6 - 0s - loss: 62.9619 - val_loss: 458.2451\n",
      "Epoch 785/1000\n",
      "6/6 - 0s - loss: 62.8985 - val_loss: 458.0350\n",
      "Epoch 786/1000\n",
      "6/6 - 0s - loss: 62.8413 - val_loss: 457.8237\n",
      "Epoch 787/1000\n",
      "6/6 - 0s - loss: 62.7778 - val_loss: 457.6115\n",
      "Epoch 788/1000\n",
      "6/6 - 0s - loss: 62.7200 - val_loss: 457.4108\n",
      "Epoch 789/1000\n",
      "6/6 - 0s - loss: 62.6600 - val_loss: 457.1821\n",
      "Epoch 790/1000\n",
      "6/6 - 0s - loss: 62.6067 - val_loss: 456.9828\n",
      "Epoch 791/1000\n",
      "6/6 - 0s - loss: 62.5456 - val_loss: 456.7544\n",
      "Epoch 792/1000\n",
      "6/6 - 0s - loss: 62.4777 - val_loss: 456.6000\n",
      "Epoch 793/1000\n",
      "6/6 - 0s - loss: 62.4290 - val_loss: 456.3676\n",
      "Epoch 794/1000\n",
      "6/6 - 0s - loss: 62.3713 - val_loss: 456.2192\n",
      "Epoch 795/1000\n",
      "6/6 - 0s - loss: 62.3110 - val_loss: 455.9868\n",
      "Epoch 796/1000\n",
      "6/6 - 0s - loss: 62.2599 - val_loss: 455.8331\n",
      "Epoch 797/1000\n",
      "6/6 - 0s - loss: 62.1977 - val_loss: 455.6182\n",
      "Epoch 798/1000\n",
      "6/6 - 0s - loss: 62.1442 - val_loss: 455.4677\n",
      "Epoch 799/1000\n",
      "6/6 - 0s - loss: 62.0964 - val_loss: 455.2307\n",
      "Epoch 800/1000\n",
      "6/6 - 0s - loss: 62.0316 - val_loss: 455.0614\n",
      "Epoch 801/1000\n",
      "6/6 - 0s - loss: 61.9745 - val_loss: 454.8786\n",
      "Epoch 802/1000\n",
      "6/6 - 0s - loss: 61.9220 - val_loss: 454.6547\n",
      "Epoch 803/1000\n",
      "6/6 - 0s - loss: 61.8669 - val_loss: 454.5070\n",
      "Epoch 804/1000\n",
      "6/6 - 0s - loss: 61.8093 - val_loss: 454.2423\n",
      "Epoch 805/1000\n",
      "6/6 - 0s - loss: 61.7457 - val_loss: 454.1494\n",
      "Epoch 806/1000\n",
      "6/6 - 0s - loss: 61.6917 - val_loss: 453.8181\n",
      "Epoch 807/1000\n",
      "6/6 - 0s - loss: 61.6283 - val_loss: 453.7498\n",
      "Epoch 808/1000\n",
      "6/6 - 0s - loss: 61.5725 - val_loss: 453.3666\n",
      "Epoch 809/1000\n",
      "6/6 - 0s - loss: 61.5159 - val_loss: 453.4004\n",
      "Epoch 810/1000\n",
      "6/6 - 0s - loss: 61.4564 - val_loss: 452.9132\n",
      "Epoch 811/1000\n",
      "6/6 - 0s - loss: 61.4039 - val_loss: 453.0197\n",
      "Epoch 812/1000\n",
      "6/6 - 0s - loss: 61.3403 - val_loss: 452.4102\n",
      "Epoch 813/1000\n",
      "6/6 - 0s - loss: 61.2829 - val_loss: 452.6556\n",
      "Epoch 814/1000\n",
      "6/6 - 0s - loss: 61.2241 - val_loss: 452.1031\n",
      "Epoch 815/1000\n",
      "6/6 - 0s - loss: 61.1702 - val_loss: 452.1545\n",
      "Epoch 816/1000\n",
      "6/6 - 0s - loss: 61.1035 - val_loss: 451.7137\n",
      "Epoch 817/1000\n",
      "6/6 - 0s - loss: 61.0395 - val_loss: 451.7499\n",
      "Epoch 818/1000\n",
      "6/6 - 0s - loss: 60.9741 - val_loss: 451.3729\n",
      "Epoch 819/1000\n",
      "6/6 - 0s - loss: 60.9141 - val_loss: 451.2021\n",
      "Epoch 820/1000\n",
      "6/6 - 0s - loss: 60.8439 - val_loss: 451.0201\n",
      "Epoch 821/1000\n",
      "6/6 - 0s - loss: 60.7792 - val_loss: 450.8900\n",
      "Epoch 822/1000\n",
      "6/6 - 0s - loss: 60.7292 - val_loss: 450.6685\n",
      "Epoch 823/1000\n",
      "6/6 - 0s - loss: 60.6571 - val_loss: 450.4600\n",
      "Epoch 824/1000\n",
      "6/6 - 0s - loss: 60.6059 - val_loss: 450.2643\n",
      "Epoch 825/1000\n",
      "6/6 - 0s - loss: 60.5382 - val_loss: 450.0945\n",
      "Epoch 826/1000\n",
      "6/6 - 0s - loss: 60.4952 - val_loss: 449.8423\n",
      "Epoch 827/1000\n",
      "6/6 - 0s - loss: 60.4246 - val_loss: 449.6891\n",
      "Epoch 828/1000\n",
      "6/6 - 0s - loss: 60.3719 - val_loss: 449.4555\n",
      "Epoch 829/1000\n",
      "6/6 - 0s - loss: 60.3151 - val_loss: 449.3197\n",
      "Epoch 830/1000\n",
      "6/6 - 0s - loss: 60.2579 - val_loss: 449.0628\n",
      "Epoch 831/1000\n",
      "6/6 - 0s - loss: 60.2058 - val_loss: 448.8873\n",
      "Epoch 832/1000\n",
      "6/6 - 0s - loss: 60.1412 - val_loss: 448.6266\n",
      "Epoch 833/1000\n",
      "6/6 - 0s - loss: 60.0740 - val_loss: 448.5103\n",
      "Epoch 834/1000\n",
      "6/6 - 0s - loss: 60.0354 - val_loss: 448.2395\n",
      "Epoch 835/1000\n",
      "6/6 - 0s - loss: 59.9646 - val_loss: 448.1280\n",
      "Epoch 836/1000\n",
      "6/6 - 0s - loss: 59.9174 - val_loss: 447.8622\n",
      "Epoch 837/1000\n",
      "6/6 - 0s - loss: 59.8632 - val_loss: 447.7517\n",
      "Epoch 838/1000\n",
      "6/6 - 0s - loss: 59.8063 - val_loss: 447.4798\n",
      "Epoch 839/1000\n",
      "6/6 - 0s - loss: 59.7483 - val_loss: 447.3633\n",
      "Epoch 840/1000\n",
      "6/6 - 0s - loss: 59.6931 - val_loss: 447.0775\n",
      "Epoch 841/1000\n",
      "6/6 - 0s - loss: 59.6354 - val_loss: 446.9766\n",
      "Epoch 842/1000\n",
      "6/6 - 0s - loss: 59.5839 - val_loss: 446.6909\n",
      "Epoch 843/1000\n",
      "6/6 - 0s - loss: 59.5230 - val_loss: 446.6182\n",
      "Epoch 844/1000\n",
      "6/6 - 0s - loss: 59.4697 - val_loss: 446.3228\n",
      "Epoch 845/1000\n",
      "6/6 - 0s - loss: 59.4226 - val_loss: 446.1991\n",
      "Epoch 846/1000\n",
      "6/6 - 0s - loss: 59.3582 - val_loss: 445.9149\n",
      "Epoch 847/1000\n",
      "6/6 - 0s - loss: 59.3062 - val_loss: 445.7913\n",
      "Epoch 848/1000\n",
      "6/6 - 0s - loss: 59.2471 - val_loss: 445.5110\n",
      "Epoch 849/1000\n",
      "6/6 - 0s - loss: 59.1888 - val_loss: 445.4247\n",
      "Epoch 850/1000\n",
      "6/6 - 0s - loss: 59.1302 - val_loss: 445.1023\n",
      "Epoch 851/1000\n",
      "6/6 - 0s - loss: 59.0745 - val_loss: 445.0100\n",
      "Epoch 852/1000\n",
      "6/6 - 0s - loss: 59.0243 - val_loss: 444.7129\n",
      "Epoch 853/1000\n",
      "6/6 - 0s - loss: 58.9569 - val_loss: 444.5482\n",
      "Epoch 854/1000\n",
      "6/6 - 0s - loss: 58.9029 - val_loss: 444.3860\n",
      "Epoch 855/1000\n",
      "6/6 - 0s - loss: 58.8493 - val_loss: 444.0474\n",
      "Epoch 856/1000\n",
      "6/6 - 0s - loss: 58.7828 - val_loss: 443.9445\n",
      "Epoch 857/1000\n",
      "6/6 - 0s - loss: 58.7157 - val_loss: 443.6521\n",
      "Epoch 858/1000\n",
      "6/6 - 0s - loss: 58.6597 - val_loss: 443.5586\n",
      "Epoch 859/1000\n",
      "6/6 - 0s - loss: 58.5983 - val_loss: 443.2300\n",
      "Epoch 860/1000\n",
      "6/6 - 0s - loss: 58.5272 - val_loss: 443.1235\n",
      "Epoch 861/1000\n",
      "6/6 - 0s - loss: 58.4755 - val_loss: 442.7593\n",
      "Epoch 862/1000\n",
      "6/6 - 0s - loss: 58.4069 - val_loss: 442.7596\n",
      "Epoch 863/1000\n",
      "6/6 - 0s - loss: 58.3614 - val_loss: 442.2961\n",
      "Epoch 864/1000\n",
      "6/6 - 0s - loss: 58.3021 - val_loss: 442.3768\n",
      "Epoch 865/1000\n",
      "6/6 - 0s - loss: 58.2415 - val_loss: 441.9417\n",
      "Epoch 866/1000\n",
      "6/6 - 0s - loss: 58.1876 - val_loss: 441.9785\n",
      "Epoch 867/1000\n",
      "6/6 - 0s - loss: 58.1366 - val_loss: 441.5765\n",
      "Epoch 868/1000\n",
      "6/6 - 0s - loss: 58.0784 - val_loss: 441.6008\n",
      "Epoch 869/1000\n",
      "6/6 - 0s - loss: 58.0202 - val_loss: 441.2009\n",
      "Epoch 870/1000\n",
      "6/6 - 0s - loss: 57.9620 - val_loss: 441.1815\n",
      "Epoch 871/1000\n",
      "6/6 - 0s - loss: 57.8962 - val_loss: 440.8132\n",
      "Epoch 872/1000\n",
      "6/6 - 0s - loss: 57.8342 - val_loss: 440.7427\n",
      "Epoch 873/1000\n",
      "6/6 - 0s - loss: 57.7808 - val_loss: 440.3911\n",
      "Epoch 874/1000\n",
      "6/6 - 0s - loss: 57.7191 - val_loss: 440.2888\n",
      "Epoch 875/1000\n",
      "6/6 - 0s - loss: 57.6541 - val_loss: 440.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 876/1000\n",
      "6/6 - 0s - loss: 57.6059 - val_loss: 439.9075\n",
      "Epoch 877/1000\n",
      "6/6 - 0s - loss: 57.5421 - val_loss: 439.6127\n",
      "Epoch 878/1000\n",
      "6/6 - 0s - loss: 57.4946 - val_loss: 439.4931\n",
      "Epoch 879/1000\n",
      "6/6 - 0s - loss: 57.4403 - val_loss: 439.2547\n",
      "Epoch 880/1000\n",
      "6/6 - 0s - loss: 57.3826 - val_loss: 439.1143\n",
      "Epoch 881/1000\n",
      "6/6 - 0s - loss: 57.3317 - val_loss: 438.8841\n",
      "Epoch 882/1000\n",
      "6/6 - 0s - loss: 57.2751 - val_loss: 438.7776\n",
      "Epoch 883/1000\n",
      "6/6 - 0s - loss: 57.2265 - val_loss: 438.4975\n",
      "Epoch 884/1000\n",
      "6/6 - 0s - loss: 57.1752 - val_loss: 438.3933\n",
      "Epoch 885/1000\n",
      "6/6 - 0s - loss: 57.1212 - val_loss: 438.1386\n",
      "Epoch 886/1000\n",
      "6/6 - 0s - loss: 57.0737 - val_loss: 438.0232\n",
      "Epoch 887/1000\n",
      "6/6 - 0s - loss: 57.0156 - val_loss: 437.7659\n",
      "Epoch 888/1000\n",
      "6/6 - 0s - loss: 56.9703 - val_loss: 437.6870\n",
      "Epoch 889/1000\n",
      "6/6 - 0s - loss: 56.9170 - val_loss: 437.3875\n",
      "Epoch 890/1000\n",
      "6/6 - 0s - loss: 56.8683 - val_loss: 437.4079\n",
      "Epoch 891/1000\n",
      "6/6 - 0s - loss: 56.8214 - val_loss: 437.0364\n",
      "Epoch 892/1000\n",
      "6/6 - 0s - loss: 56.7682 - val_loss: 437.0315\n",
      "Epoch 893/1000\n",
      "6/6 - 0s - loss: 56.7143 - val_loss: 436.6819\n",
      "Epoch 894/1000\n",
      "6/6 - 0s - loss: 56.6619 - val_loss: 436.6531\n",
      "Epoch 895/1000\n",
      "6/6 - 0s - loss: 56.6159 - val_loss: 436.3003\n",
      "Epoch 896/1000\n",
      "6/6 - 0s - loss: 56.5640 - val_loss: 436.2949\n",
      "Epoch 897/1000\n",
      "6/6 - 0s - loss: 56.5097 - val_loss: 435.9004\n",
      "Epoch 898/1000\n",
      "6/6 - 0s - loss: 56.4571 - val_loss: 435.9402\n",
      "Epoch 899/1000\n",
      "6/6 - 0s - loss: 56.4016 - val_loss: 435.5516\n",
      "Epoch 900/1000\n",
      "6/6 - 0s - loss: 56.3585 - val_loss: 435.5981\n",
      "Epoch 901/1000\n",
      "6/6 - 0s - loss: 56.2985 - val_loss: 435.1664\n",
      "Epoch 902/1000\n",
      "6/6 - 0s - loss: 56.2533 - val_loss: 435.2014\n",
      "Epoch 903/1000\n",
      "6/6 - 0s - loss: 56.1985 - val_loss: 434.7891\n",
      "Epoch 904/1000\n",
      "6/6 - 0s - loss: 56.1427 - val_loss: 434.8369\n",
      "Epoch 905/1000\n",
      "6/6 - 0s - loss: 56.0946 - val_loss: 434.4157\n",
      "Epoch 906/1000\n",
      "6/6 - 0s - loss: 56.0410 - val_loss: 434.4684\n",
      "Epoch 907/1000\n",
      "6/6 - 0s - loss: 55.9877 - val_loss: 434.0695\n",
      "Epoch 908/1000\n",
      "6/6 - 0s - loss: 55.9340 - val_loss: 434.0533\n",
      "Epoch 909/1000\n",
      "6/6 - 0s - loss: 55.8832 - val_loss: 433.6768\n",
      "Epoch 910/1000\n",
      "6/6 - 0s - loss: 55.8261 - val_loss: 433.6479\n",
      "Epoch 911/1000\n",
      "6/6 - 0s - loss: 55.7701 - val_loss: 433.3284\n",
      "Epoch 912/1000\n",
      "6/6 - 0s - loss: 55.7232 - val_loss: 433.2811\n",
      "Epoch 913/1000\n",
      "6/6 - 0s - loss: 55.6705 - val_loss: 432.9098\n",
      "Epoch 914/1000\n",
      "6/6 - 0s - loss: 55.6142 - val_loss: 432.8671\n",
      "Epoch 915/1000\n",
      "6/6 - 0s - loss: 55.5633 - val_loss: 432.5189\n",
      "Epoch 916/1000\n",
      "6/6 - 0s - loss: 55.5170 - val_loss: 432.5266\n",
      "Epoch 917/1000\n",
      "6/6 - 0s - loss: 55.4646 - val_loss: 432.1748\n",
      "Epoch 918/1000\n",
      "6/6 - 0s - loss: 55.4119 - val_loss: 432.1259\n",
      "Epoch 919/1000\n",
      "6/6 - 0s - loss: 55.3631 - val_loss: 431.8640\n",
      "Epoch 920/1000\n",
      "6/6 - 0s - loss: 55.3147 - val_loss: 431.7522\n",
      "Epoch 921/1000\n",
      "6/6 - 0s - loss: 55.2602 - val_loss: 431.5099\n",
      "Epoch 922/1000\n",
      "6/6 - 0s - loss: 55.2104 - val_loss: 431.3705\n",
      "Epoch 923/1000\n",
      "6/6 - 0s - loss: 55.1687 - val_loss: 431.1098\n",
      "Epoch 924/1000\n",
      "6/6 - 0s - loss: 55.1042 - val_loss: 430.9585\n",
      "Epoch 925/1000\n",
      "6/6 - 0s - loss: 55.0422 - val_loss: 430.7617\n",
      "Epoch 926/1000\n",
      "6/6 - 0s - loss: 55.0039 - val_loss: 430.4693\n",
      "Epoch 927/1000\n",
      "6/6 - 0s - loss: 54.9366 - val_loss: 430.3937\n",
      "Epoch 928/1000\n",
      "6/6 - 0s - loss: 54.8891 - val_loss: 430.0619\n",
      "Epoch 929/1000\n",
      "6/6 - 0s - loss: 54.8353 - val_loss: 429.9976\n",
      "Epoch 930/1000\n",
      "6/6 - 0s - loss: 54.7844 - val_loss: 429.6819\n",
      "Epoch 931/1000\n",
      "6/6 - 0s - loss: 54.7349 - val_loss: 429.5761\n",
      "Epoch 932/1000\n",
      "6/6 - 0s - loss: 54.6756 - val_loss: 429.2846\n",
      "Epoch 933/1000\n",
      "6/6 - 0s - loss: 54.6215 - val_loss: 429.1347\n",
      "Epoch 934/1000\n",
      "6/6 - 0s - loss: 54.5623 - val_loss: 428.9009\n",
      "Epoch 935/1000\n",
      "6/6 - 0s - loss: 54.5005 - val_loss: 428.7402\n",
      "Epoch 936/1000\n",
      "6/6 - 0s - loss: 54.4432 - val_loss: 428.4722\n",
      "Epoch 937/1000\n",
      "6/6 - 0s - loss: 54.3834 - val_loss: 428.3362\n",
      "Epoch 938/1000\n",
      "6/6 - 0s - loss: 54.3285 - val_loss: 428.0539\n",
      "Epoch 939/1000\n",
      "6/6 - 0s - loss: 54.2725 - val_loss: 427.9017\n",
      "Epoch 940/1000\n",
      "6/6 - 0s - loss: 54.2194 - val_loss: 427.6325\n",
      "Epoch 941/1000\n",
      "6/6 - 0s - loss: 54.1681 - val_loss: 427.4709\n",
      "Epoch 942/1000\n",
      "6/6 - 0s - loss: 54.1210 - val_loss: 427.2731\n",
      "Epoch 943/1000\n",
      "6/6 - 0s - loss: 54.0714 - val_loss: 427.0955\n",
      "Epoch 944/1000\n",
      "6/6 - 0s - loss: 54.0170 - val_loss: 426.9169\n",
      "Epoch 945/1000\n",
      "6/6 - 0s - loss: 53.9623 - val_loss: 426.7066\n",
      "Epoch 946/1000\n",
      "6/6 - 0s - loss: 53.9177 - val_loss: 426.5303\n",
      "Epoch 947/1000\n",
      "6/6 - 0s - loss: 53.8650 - val_loss: 426.2823\n",
      "Epoch 948/1000\n",
      "6/6 - 0s - loss: 53.8083 - val_loss: 426.1513\n",
      "Epoch 949/1000\n",
      "6/6 - 0s - loss: 53.7547 - val_loss: 425.8921\n",
      "Epoch 950/1000\n",
      "6/6 - 0s - loss: 53.7032 - val_loss: 425.7856\n",
      "Epoch 951/1000\n",
      "6/6 - 0s - loss: 53.6596 - val_loss: 425.5257\n",
      "Epoch 952/1000\n",
      "6/6 - 0s - loss: 53.6084 - val_loss: 425.4192\n",
      "Epoch 953/1000\n",
      "6/6 - 0s - loss: 53.5605 - val_loss: 425.1566\n",
      "Epoch 954/1000\n",
      "6/6 - 0s - loss: 53.5140 - val_loss: 425.0347\n",
      "Epoch 955/1000\n",
      "6/6 - 0s - loss: 53.4606 - val_loss: 424.7500\n",
      "Epoch 956/1000\n",
      "6/6 - 0s - loss: 53.4128 - val_loss: 424.6062\n",
      "Epoch 957/1000\n",
      "6/6 - 0s - loss: 53.3591 - val_loss: 424.2992\n",
      "Epoch 958/1000\n",
      "6/6 - 0s - loss: 53.3095 - val_loss: 424.1772\n",
      "Epoch 959/1000\n",
      "6/6 - 0s - loss: 53.2559 - val_loss: 423.8659\n",
      "Epoch 960/1000\n",
      "6/6 - 0s - loss: 53.2069 - val_loss: 423.7858\n",
      "Epoch 961/1000\n",
      "6/6 - 0s - loss: 53.1549 - val_loss: 423.4435\n",
      "Epoch 962/1000\n",
      "6/6 - 0s - loss: 53.1133 - val_loss: 423.3062\n",
      "Epoch 963/1000\n",
      "6/6 - 0s - loss: 53.0600 - val_loss: 423.0397\n",
      "Epoch 964/1000\n",
      "6/6 - 0s - loss: 53.0037 - val_loss: 422.8161\n",
      "Epoch 965/1000\n",
      "6/6 - 0s - loss: 52.9439 - val_loss: 422.5060\n",
      "Epoch 966/1000\n",
      "6/6 - 0s - loss: 52.8884 - val_loss: 422.4957\n",
      "Epoch 967/1000\n",
      "6/6 - 0s - loss: 52.8202 - val_loss: 421.9878\n",
      "Epoch 968/1000\n",
      "6/6 - 0s - loss: 52.7742 - val_loss: 422.1874\n",
      "Epoch 969/1000\n",
      "6/6 - 0s - loss: 52.7204 - val_loss: 421.7871\n",
      "Epoch 970/1000\n",
      "6/6 - 0s - loss: 52.6744 - val_loss: 421.8650\n",
      "Epoch 971/1000\n",
      "6/6 - 0s - loss: 52.6276 - val_loss: 421.5062\n",
      "Epoch 972/1000\n",
      "6/6 - 0s - loss: 52.5755 - val_loss: 421.4579\n",
      "Epoch 973/1000\n",
      "6/6 - 0s - loss: 52.5156 - val_loss: 421.2495\n",
      "Epoch 974/1000\n",
      "6/6 - 0s - loss: 52.4532 - val_loss: 421.1035\n",
      "Epoch 975/1000\n",
      "6/6 - 0s - loss: 52.4095 - val_loss: 420.9421\n",
      "Epoch 976/1000\n",
      "6/6 - 0s - loss: 52.3483 - val_loss: 420.6944\n",
      "Epoch 977/1000\n",
      "6/6 - 0s - loss: 52.2878 - val_loss: 420.6476\n",
      "Epoch 978/1000\n",
      "6/6 - 0s - loss: 52.2455 - val_loss: 420.3158\n",
      "Epoch 979/1000\n",
      "6/6 - 0s - loss: 52.1858 - val_loss: 420.3101\n",
      "Epoch 980/1000\n",
      "6/6 - 0s - loss: 52.1460 - val_loss: 420.0358\n",
      "Epoch 981/1000\n",
      "6/6 - 0s - loss: 52.0929 - val_loss: 419.9747\n",
      "Epoch 982/1000\n",
      "6/6 - 0s - loss: 52.0423 - val_loss: 419.7629\n",
      "Epoch 983/1000\n",
      "6/6 - 0s - loss: 52.0062 - val_loss: 419.6408\n",
      "Epoch 984/1000\n",
      "6/6 - 0s - loss: 51.9502 - val_loss: 419.4726\n",
      "Epoch 985/1000\n",
      "6/6 - 0s - loss: 51.8999 - val_loss: 419.3704\n",
      "Epoch 986/1000\n",
      "6/6 - 0s - loss: 51.8587 - val_loss: 419.1578\n",
      "Epoch 987/1000\n",
      "6/6 - 0s - loss: 51.8038 - val_loss: 419.0241\n",
      "Epoch 988/1000\n",
      "6/6 - 0s - loss: 51.7549 - val_loss: 418.8301\n",
      "Epoch 989/1000\n",
      "6/6 - 0s - loss: 51.7093 - val_loss: 418.6758\n",
      "Epoch 990/1000\n",
      "6/6 - 0s - loss: 51.6611 - val_loss: 418.4994\n",
      "Epoch 991/1000\n",
      "6/6 - 0s - loss: 51.6079 - val_loss: 418.3618\n",
      "Epoch 992/1000\n",
      "6/6 - 0s - loss: 51.5576 - val_loss: 418.1836\n",
      "Epoch 993/1000\n",
      "6/6 - 0s - loss: 51.5104 - val_loss: 418.0254\n",
      "Epoch 994/1000\n",
      "6/6 - 0s - loss: 51.4660 - val_loss: 417.8235\n",
      "Epoch 995/1000\n",
      "6/6 - 0s - loss: 51.4104 - val_loss: 417.6545\n",
      "Epoch 996/1000\n",
      "6/6 - 0s - loss: 51.3471 - val_loss: 417.4942\n",
      "Epoch 997/1000\n",
      "6/6 - 0s - loss: 51.3000 - val_loss: 417.3102\n",
      "Epoch 998/1000\n",
      "6/6 - 0s - loss: 51.2530 - val_loss: 417.1186\n",
      "Epoch 999/1000\n",
      "6/6 - 0s - loss: 51.1943 - val_loss: 416.9572\n",
      "Epoch 1000/1000\n",
      "6/6 - 0s - loss: 51.1499 - val_loss: 416.7771\n",
      "Score (MSE): 416.77712418015886\n",
      "Score(RMSE): 20.41511998936472\n",
      "\n",
      "Run  3\n",
      "Activation: Sigmoid\n",
      "Optimizer: Adam\n",
      "\n",
      "Epoch 1/1000\n",
      "6/6 - 0s - loss: 167.5501 - val_loss: 703.2033\n",
      "Epoch 2/1000\n",
      "6/6 - 0s - loss: 165.4277 - val_loss: 699.3632\n",
      "Epoch 3/1000\n",
      "6/6 - 0s - loss: 163.3766 - val_loss: 695.6999\n",
      "Epoch 4/1000\n",
      "6/6 - 0s - loss: 161.3512 - val_loss: 692.0137\n",
      "Epoch 5/1000\n",
      "6/6 - 0s - loss: 159.4853 - val_loss: 688.3112\n",
      "Epoch 6/1000\n",
      "6/6 - 0s - loss: 157.8145 - val_loss: 684.8344\n",
      "Epoch 7/1000\n",
      "6/6 - 0s - loss: 156.0258 - val_loss: 681.7826\n",
      "Epoch 8/1000\n",
      "6/6 - 0s - loss: 154.3926 - val_loss: 679.0893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000\n",
      "6/6 - 0s - loss: 152.9648 - val_loss: 676.5545\n",
      "Epoch 10/1000\n",
      "6/6 - 0s - loss: 151.5856 - val_loss: 674.2820\n",
      "Epoch 11/1000\n",
      "6/6 - 0s - loss: 150.3609 - val_loss: 672.1415\n",
      "Epoch 12/1000\n",
      "6/6 - 0s - loss: 149.1135 - val_loss: 670.1357\n",
      "Epoch 13/1000\n",
      "6/6 - 0s - loss: 148.0385 - val_loss: 668.1344\n",
      "Epoch 14/1000\n",
      "6/6 - 0s - loss: 146.9374 - val_loss: 666.3346\n",
      "Epoch 15/1000\n",
      "6/6 - 0s - loss: 145.9761 - val_loss: 664.6255\n",
      "Epoch 16/1000\n",
      "6/6 - 0s - loss: 145.0519 - val_loss: 663.0286\n",
      "Epoch 17/1000\n",
      "6/6 - 0s - loss: 144.1328 - val_loss: 661.6091\n",
      "Epoch 18/1000\n",
      "6/6 - 0s - loss: 143.4152 - val_loss: 660.1619\n",
      "Epoch 19/1000\n",
      "6/6 - 0s - loss: 142.6230 - val_loss: 658.8331\n",
      "Epoch 20/1000\n",
      "6/6 - 0s - loss: 141.9124 - val_loss: 657.5877\n",
      "Epoch 21/1000\n",
      "6/6 - 0s - loss: 141.2300 - val_loss: 656.3982\n",
      "Epoch 22/1000\n",
      "6/6 - 0s - loss: 140.6225 - val_loss: 655.2262\n",
      "Epoch 23/1000\n",
      "6/6 - 0s - loss: 140.0123 - val_loss: 654.0942\n",
      "Epoch 24/1000\n",
      "6/6 - 0s - loss: 139.4315 - val_loss: 653.0695\n",
      "Epoch 25/1000\n",
      "6/6 - 0s - loss: 138.9017 - val_loss: 652.0898\n",
      "Epoch 26/1000\n",
      "6/6 - 0s - loss: 138.4277 - val_loss: 651.0953\n",
      "Epoch 27/1000\n",
      "6/6 - 0s - loss: 137.8949 - val_loss: 650.1805\n",
      "Epoch 28/1000\n",
      "6/6 - 0s - loss: 137.4368 - val_loss: 649.2804\n",
      "Epoch 29/1000\n",
      "6/6 - 0s - loss: 137.0136 - val_loss: 648.3730\n",
      "Epoch 30/1000\n",
      "6/6 - 0s - loss: 136.5611 - val_loss: 647.5190\n",
      "Epoch 31/1000\n",
      "6/6 - 0s - loss: 136.1232 - val_loss: 646.7151\n",
      "Epoch 32/1000\n",
      "6/6 - 0s - loss: 135.7159 - val_loss: 645.9368\n",
      "Epoch 33/1000\n",
      "6/6 - 0s - loss: 135.3531 - val_loss: 645.1201\n",
      "Epoch 34/1000\n",
      "6/6 - 0s - loss: 134.9416 - val_loss: 644.3273\n",
      "Epoch 35/1000\n",
      "6/6 - 0s - loss: 134.5639 - val_loss: 643.5309\n",
      "Epoch 36/1000\n",
      "6/6 - 0s - loss: 134.1910 - val_loss: 642.7351\n",
      "Epoch 37/1000\n",
      "6/6 - 0s - loss: 133.8208 - val_loss: 641.9896\n",
      "Epoch 38/1000\n",
      "6/6 - 0s - loss: 133.4743 - val_loss: 641.2772\n",
      "Epoch 39/1000\n",
      "6/6 - 0s - loss: 133.1404 - val_loss: 640.6173\n",
      "Epoch 40/1000\n",
      "6/6 - 0s - loss: 132.8198 - val_loss: 639.9736\n",
      "Epoch 41/1000\n",
      "6/6 - 0s - loss: 132.5453 - val_loss: 639.2880\n",
      "Epoch 42/1000\n",
      "6/6 - 0s - loss: 132.2351 - val_loss: 638.6386\n",
      "Epoch 43/1000\n",
      "6/6 - 0s - loss: 131.9284 - val_loss: 638.0225\n",
      "Epoch 44/1000\n",
      "6/6 - 0s - loss: 131.6370 - val_loss: 637.4263\n",
      "Epoch 45/1000\n",
      "6/6 - 0s - loss: 131.3679 - val_loss: 636.8345\n",
      "Epoch 46/1000\n",
      "6/6 - 0s - loss: 131.0745 - val_loss: 636.2609\n",
      "Epoch 47/1000\n",
      "6/6 - 0s - loss: 130.8270 - val_loss: 635.6043\n",
      "Epoch 48/1000\n",
      "6/6 - 0s - loss: 130.5627 - val_loss: 634.9620\n",
      "Epoch 49/1000\n",
      "6/6 - 0s - loss: 130.2519 - val_loss: 634.3995\n",
      "Epoch 50/1000\n",
      "6/6 - 0s - loss: 130.0134 - val_loss: 633.7875\n",
      "Epoch 51/1000\n",
      "6/6 - 0s - loss: 129.7299 - val_loss: 633.2111\n",
      "Epoch 52/1000\n",
      "6/6 - 0s - loss: 129.4694 - val_loss: 632.6233\n",
      "Epoch 53/1000\n",
      "6/6 - 0s - loss: 129.2177 - val_loss: 632.0308\n",
      "Epoch 54/1000\n",
      "6/6 - 0s - loss: 128.9566 - val_loss: 631.4581\n",
      "Epoch 55/1000\n",
      "6/6 - 0s - loss: 128.7295 - val_loss: 630.8653\n",
      "Epoch 56/1000\n",
      "6/6 - 0s - loss: 128.4680 - val_loss: 630.3329\n",
      "Epoch 57/1000\n",
      "6/6 - 0s - loss: 128.2375 - val_loss: 629.8136\n",
      "Epoch 58/1000\n",
      "6/6 - 0s - loss: 128.0321 - val_loss: 629.2653\n",
      "Epoch 59/1000\n",
      "6/6 - 0s - loss: 127.7804 - val_loss: 628.7691\n",
      "Epoch 60/1000\n",
      "6/6 - 0s - loss: 127.5784 - val_loss: 628.2447\n",
      "Epoch 61/1000\n",
      "6/6 - 0s - loss: 127.3345 - val_loss: 627.7576\n",
      "Epoch 62/1000\n",
      "6/6 - 0s - loss: 127.1471 - val_loss: 627.2440\n",
      "Epoch 63/1000\n",
      "6/6 - 0s - loss: 126.9223 - val_loss: 626.7590\n",
      "Epoch 64/1000\n",
      "6/6 - 0s - loss: 126.7219 - val_loss: 626.2697\n",
      "Epoch 65/1000\n",
      "6/6 - 0s - loss: 126.5175 - val_loss: 625.7896\n",
      "Epoch 66/1000\n",
      "6/6 - 0s - loss: 126.2951 - val_loss: 625.3434\n",
      "Epoch 67/1000\n",
      "6/6 - 0s - loss: 126.1181 - val_loss: 624.8596\n",
      "Epoch 68/1000\n",
      "6/6 - 0s - loss: 125.9038 - val_loss: 624.4024\n",
      "Epoch 69/1000\n",
      "6/6 - 0s - loss: 125.7178 - val_loss: 623.9271\n",
      "Epoch 70/1000\n",
      "6/6 - 0s - loss: 125.5066 - val_loss: 623.4335\n",
      "Epoch 71/1000\n",
      "6/6 - 0s - loss: 125.3166 - val_loss: 622.9214\n",
      "Epoch 72/1000\n",
      "6/6 - 0s - loss: 125.0954 - val_loss: 622.4526\n",
      "Epoch 73/1000\n",
      "6/6 - 0s - loss: 124.9114 - val_loss: 621.9679\n",
      "Epoch 74/1000\n",
      "6/6 - 0s - loss: 124.7127 - val_loss: 621.4874\n",
      "Epoch 75/1000\n",
      "6/6 - 0s - loss: 124.5044 - val_loss: 621.0450\n",
      "Epoch 76/1000\n",
      "6/6 - 0s - loss: 124.3200 - val_loss: 620.5829\n",
      "Epoch 77/1000\n",
      "6/6 - 0s - loss: 124.1213 - val_loss: 620.1385\n",
      "Epoch 78/1000\n",
      "6/6 - 0s - loss: 123.9341 - val_loss: 619.6987\n",
      "Epoch 79/1000\n",
      "6/6 - 0s - loss: 123.7360 - val_loss: 619.2709\n",
      "Epoch 80/1000\n",
      "6/6 - 0s - loss: 123.5521 - val_loss: 618.8444\n",
      "Epoch 81/1000\n",
      "6/6 - 0s - loss: 123.3867 - val_loss: 618.3672\n",
      "Epoch 82/1000\n",
      "6/6 - 0s - loss: 123.1795 - val_loss: 617.9333\n",
      "Epoch 83/1000\n",
      "6/6 - 0s - loss: 122.9967 - val_loss: 617.4926\n",
      "Epoch 84/1000\n",
      "6/6 - 0s - loss: 122.8058 - val_loss: 617.0539\n",
      "Epoch 85/1000\n",
      "6/6 - 0s - loss: 122.6016 - val_loss: 616.6299\n",
      "Epoch 86/1000\n",
      "6/6 - 0s - loss: 122.4269 - val_loss: 616.1779\n",
      "Epoch 87/1000\n",
      "6/6 - 0s - loss: 122.2325 - val_loss: 615.7415\n",
      "Epoch 88/1000\n",
      "6/6 - 0s - loss: 122.0518 - val_loss: 615.3107\n",
      "Epoch 89/1000\n",
      "6/6 - 0s - loss: 121.8431 - val_loss: 614.9307\n",
      "Epoch 90/1000\n",
      "6/6 - 0s - loss: 121.6769 - val_loss: 614.4885\n",
      "Epoch 91/1000\n",
      "6/6 - 0s - loss: 121.4768 - val_loss: 614.0676\n",
      "Epoch 92/1000\n",
      "6/6 - 0s - loss: 121.2836 - val_loss: 613.6454\n",
      "Epoch 93/1000\n",
      "6/6 - 0s - loss: 121.0999 - val_loss: 613.2172\n",
      "Epoch 94/1000\n",
      "6/6 - 0s - loss: 120.8975 - val_loss: 612.8094\n",
      "Epoch 95/1000\n",
      "6/6 - 0s - loss: 120.6960 - val_loss: 612.3998\n",
      "Epoch 96/1000\n",
      "6/6 - 0s - loss: 120.5091 - val_loss: 611.9612\n",
      "Epoch 97/1000\n",
      "6/6 - 0s - loss: 120.3014 - val_loss: 611.5400\n",
      "Epoch 98/1000\n",
      "6/6 - 0s - loss: 120.0798 - val_loss: 611.1466\n",
      "Epoch 99/1000\n",
      "6/6 - 0s - loss: 119.8764 - val_loss: 610.7289\n",
      "Epoch 100/1000\n",
      "6/6 - 0s - loss: 119.6618 - val_loss: 610.3073\n",
      "Epoch 101/1000\n",
      "6/6 - 0s - loss: 119.4372 - val_loss: 609.9000\n",
      "Epoch 102/1000\n",
      "6/6 - 0s - loss: 119.2179 - val_loss: 609.4578\n",
      "Epoch 103/1000\n",
      "6/6 - 0s - loss: 118.9812 - val_loss: 609.0157\n",
      "Epoch 104/1000\n",
      "6/6 - 0s - loss: 118.7550 - val_loss: 608.5505\n",
      "Epoch 105/1000\n",
      "6/6 - 0s - loss: 118.5077 - val_loss: 608.1019\n",
      "Epoch 106/1000\n",
      "6/6 - 0s - loss: 118.2636 - val_loss: 607.6565\n",
      "Epoch 107/1000\n",
      "6/6 - 0s - loss: 118.0150 - val_loss: 607.2149\n",
      "Epoch 108/1000\n",
      "6/6 - 0s - loss: 117.7665 - val_loss: 606.7737\n",
      "Epoch 109/1000\n",
      "6/6 - 0s - loss: 117.5222 - val_loss: 606.2822\n",
      "Epoch 110/1000\n",
      "6/6 - 0s - loss: 117.2505 - val_loss: 605.8221\n",
      "Epoch 111/1000\n",
      "6/6 - 0s - loss: 116.9962 - val_loss: 605.3742\n",
      "Epoch 112/1000\n",
      "6/6 - 0s - loss: 116.7386 - val_loss: 604.9318\n",
      "Epoch 113/1000\n",
      "6/6 - 0s - loss: 116.4973 - val_loss: 604.4564\n",
      "Epoch 114/1000\n",
      "6/6 - 0s - loss: 116.2143 - val_loss: 603.9999\n",
      "Epoch 115/1000\n",
      "6/6 - 0s - loss: 115.9548 - val_loss: 603.5219\n",
      "Epoch 116/1000\n",
      "6/6 - 0s - loss: 115.6852 - val_loss: 603.0141\n",
      "Epoch 117/1000\n",
      "6/6 - 0s - loss: 115.4072 - val_loss: 602.5110\n",
      "Epoch 118/1000\n",
      "6/6 - 0s - loss: 115.1367 - val_loss: 602.0087\n",
      "Epoch 119/1000\n",
      "6/6 - 0s - loss: 114.8546 - val_loss: 601.5173\n",
      "Epoch 120/1000\n",
      "6/6 - 0s - loss: 114.5694 - val_loss: 601.0190\n",
      "Epoch 121/1000\n",
      "6/6 - 0s - loss: 114.2983 - val_loss: 600.4995\n",
      "Epoch 122/1000\n",
      "6/6 - 0s - loss: 114.0156 - val_loss: 599.9700\n",
      "Epoch 123/1000\n",
      "6/6 - 0s - loss: 113.7352 - val_loss: 599.4333\n",
      "Epoch 124/1000\n",
      "6/6 - 0s - loss: 113.4449 - val_loss: 598.9102\n",
      "Epoch 125/1000\n",
      "6/6 - 0s - loss: 113.1524 - val_loss: 598.3691\n",
      "Epoch 126/1000\n",
      "6/6 - 0s - loss: 112.8865 - val_loss: 597.7675\n",
      "Epoch 127/1000\n",
      "6/6 - 0s - loss: 112.5926 - val_loss: 597.2050\n",
      "Epoch 128/1000\n",
      "6/6 - 0s - loss: 112.2990 - val_loss: 596.6830\n",
      "Epoch 129/1000\n",
      "6/6 - 0s - loss: 112.0522 - val_loss: 596.1335\n",
      "Epoch 130/1000\n",
      "6/6 - 0s - loss: 111.7593 - val_loss: 595.6161\n",
      "Epoch 131/1000\n",
      "6/6 - 0s - loss: 111.4835 - val_loss: 595.1181\n",
      "Epoch 132/1000\n",
      "6/6 - 0s - loss: 111.2323 - val_loss: 594.5771\n",
      "Epoch 133/1000\n",
      "6/6 - 0s - loss: 110.9570 - val_loss: 594.0223\n",
      "Epoch 134/1000\n",
      "6/6 - 0s - loss: 110.6947 - val_loss: 593.4708\n",
      "Epoch 135/1000\n",
      "6/6 - 0s - loss: 110.4137 - val_loss: 592.9146\n",
      "Epoch 136/1000\n",
      "6/6 - 0s - loss: 110.1516 - val_loss: 592.3203\n",
      "Epoch 137/1000\n",
      "6/6 - 0s - loss: 109.8828 - val_loss: 591.7256\n",
      "Epoch 138/1000\n",
      "6/6 - 0s - loss: 109.5937 - val_loss: 591.1794\n",
      "Epoch 139/1000\n",
      "6/6 - 0s - loss: 109.3273 - val_loss: 590.6517\n",
      "Epoch 140/1000\n",
      "6/6 - 0s - loss: 109.0739 - val_loss: 590.1031\n",
      "Epoch 141/1000\n",
      "6/6 - 0s - loss: 108.8192 - val_loss: 589.5479\n",
      "Epoch 142/1000\n",
      "6/6 - 0s - loss: 108.5573 - val_loss: 588.9920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/1000\n",
      "6/6 - 0s - loss: 108.2923 - val_loss: 588.4385\n",
      "Epoch 144/1000\n",
      "6/6 - 0s - loss: 108.0656 - val_loss: 587.8605\n",
      "Epoch 145/1000\n",
      "6/6 - 0s - loss: 107.8019 - val_loss: 587.3073\n",
      "Epoch 146/1000\n",
      "6/6 - 0s - loss: 107.5520 - val_loss: 586.7770\n",
      "Epoch 147/1000\n",
      "6/6 - 0s - loss: 107.3332 - val_loss: 586.2272\n",
      "Epoch 148/1000\n",
      "6/6 - 0s - loss: 107.0659 - val_loss: 585.7142\n",
      "Epoch 149/1000\n",
      "6/6 - 0s - loss: 106.8548 - val_loss: 585.1766\n",
      "Epoch 150/1000\n",
      "6/6 - 0s - loss: 106.6155 - val_loss: 584.6597\n",
      "Epoch 151/1000\n",
      "6/6 - 0s - loss: 106.3642 - val_loss: 584.1656\n",
      "Epoch 152/1000\n",
      "6/6 - 0s - loss: 106.1529 - val_loss: 583.6445\n",
      "Epoch 153/1000\n",
      "6/6 - 0s - loss: 105.9159 - val_loss: 583.1414\n",
      "Epoch 154/1000\n",
      "6/6 - 0s - loss: 105.6979 - val_loss: 582.6143\n",
      "Epoch 155/1000\n",
      "6/6 - 0s - loss: 105.4543 - val_loss: 582.1071\n",
      "Epoch 156/1000\n",
      "6/6 - 0s - loss: 105.2527 - val_loss: 581.5590\n",
      "Epoch 157/1000\n",
      "6/6 - 0s - loss: 105.0235 - val_loss: 581.0303\n",
      "Epoch 158/1000\n",
      "6/6 - 0s - loss: 104.8030 - val_loss: 580.5062\n",
      "Epoch 159/1000\n",
      "6/6 - 0s - loss: 104.5800 - val_loss: 580.0037\n",
      "Epoch 160/1000\n",
      "6/6 - 0s - loss: 104.3706 - val_loss: 579.5060\n",
      "Epoch 161/1000\n",
      "6/6 - 0s - loss: 104.1487 - val_loss: 579.0237\n",
      "Epoch 162/1000\n",
      "6/6 - 0s - loss: 103.9238 - val_loss: 578.5505\n",
      "Epoch 163/1000\n",
      "6/6 - 0s - loss: 103.7291 - val_loss: 578.0209\n",
      "Epoch 164/1000\n",
      "6/6 - 0s - loss: 103.5073 - val_loss: 577.4799\n",
      "Epoch 165/1000\n",
      "6/6 - 0s - loss: 103.2727 - val_loss: 576.9515\n",
      "Epoch 166/1000\n",
      "6/6 - 0s - loss: 103.0571 - val_loss: 576.4207\n",
      "Epoch 167/1000\n",
      "6/6 - 0s - loss: 102.8496 - val_loss: 575.8936\n",
      "Epoch 168/1000\n",
      "6/6 - 0s - loss: 102.6403 - val_loss: 575.3816\n",
      "Epoch 169/1000\n",
      "6/6 - 0s - loss: 102.4045 - val_loss: 574.8915\n",
      "Epoch 170/1000\n",
      "6/6 - 0s - loss: 102.2053 - val_loss: 574.3661\n",
      "Epoch 171/1000\n",
      "6/6 - 0s - loss: 102.0207 - val_loss: 573.8129\n",
      "Epoch 172/1000\n",
      "6/6 - 0s - loss: 101.7792 - val_loss: 573.3214\n",
      "Epoch 173/1000\n",
      "6/6 - 0s - loss: 101.5917 - val_loss: 572.8210\n",
      "Epoch 174/1000\n",
      "6/6 - 0s - loss: 101.4094 - val_loss: 572.3099\n",
      "Epoch 175/1000\n",
      "6/6 - 0s - loss: 101.1796 - val_loss: 571.8464\n",
      "Epoch 176/1000\n",
      "6/6 - 0s - loss: 100.9891 - val_loss: 571.3455\n",
      "Epoch 177/1000\n",
      "6/6 - 0s - loss: 100.7807 - val_loss: 570.8674\n",
      "Epoch 178/1000\n",
      "6/6 - 0s - loss: 100.6134 - val_loss: 570.3625\n",
      "Epoch 179/1000\n",
      "6/6 - 0s - loss: 100.4085 - val_loss: 569.8839\n",
      "Epoch 180/1000\n",
      "6/6 - 0s - loss: 100.2233 - val_loss: 569.4080\n",
      "Epoch 181/1000\n",
      "6/6 - 0s - loss: 100.0293 - val_loss: 568.9481\n",
      "Epoch 182/1000\n",
      "6/6 - 0s - loss: 99.8363 - val_loss: 568.4830\n",
      "Epoch 183/1000\n",
      "6/6 - 0s - loss: 99.6799 - val_loss: 567.9839\n",
      "Epoch 184/1000\n",
      "6/6 - 0s - loss: 99.4516 - val_loss: 567.5447\n",
      "Epoch 185/1000\n",
      "6/6 - 0s - loss: 99.2828 - val_loss: 567.0845\n",
      "Epoch 186/1000\n",
      "6/6 - 0s - loss: 99.0814 - val_loss: 566.6203\n",
      "Epoch 187/1000\n",
      "6/6 - 0s - loss: 98.9247 - val_loss: 566.1046\n",
      "Epoch 188/1000\n",
      "6/6 - 0s - loss: 98.7046 - val_loss: 565.6403\n",
      "Epoch 189/1000\n",
      "6/6 - 0s - loss: 98.5293 - val_loss: 565.1609\n",
      "Epoch 190/1000\n",
      "6/6 - 0s - loss: 98.3280 - val_loss: 564.6941\n",
      "Epoch 191/1000\n",
      "6/6 - 0s - loss: 98.1642 - val_loss: 564.1907\n",
      "Epoch 192/1000\n",
      "6/6 - 0s - loss: 97.9655 - val_loss: 563.7119\n",
      "Epoch 193/1000\n",
      "6/6 - 0s - loss: 97.7762 - val_loss: 563.2370\n",
      "Epoch 194/1000\n",
      "6/6 - 0s - loss: 97.5866 - val_loss: 562.7755\n",
      "Epoch 195/1000\n",
      "6/6 - 0s - loss: 97.4177 - val_loss: 562.3165\n",
      "Epoch 196/1000\n",
      "6/6 - 0s - loss: 97.2513 - val_loss: 561.8639\n",
      "Epoch 197/1000\n",
      "6/6 - 0s - loss: 97.0688 - val_loss: 561.4355\n",
      "Epoch 198/1000\n",
      "6/6 - 0s - loss: 96.9037 - val_loss: 561.0000\n",
      "Epoch 199/1000\n",
      "6/6 - 0s - loss: 96.7278 - val_loss: 560.5429\n",
      "Epoch 200/1000\n",
      "6/6 - 0s - loss: 96.5461 - val_loss: 560.1099\n",
      "Epoch 201/1000\n",
      "6/6 - 0s - loss: 96.3832 - val_loss: 559.6656\n",
      "Epoch 202/1000\n",
      "6/6 - 0s - loss: 96.2046 - val_loss: 559.1945\n",
      "Epoch 203/1000\n",
      "6/6 - 0s - loss: 96.0488 - val_loss: 558.7120\n",
      "Epoch 204/1000\n",
      "6/6 - 0s - loss: 95.8430 - val_loss: 558.2736\n",
      "Epoch 205/1000\n",
      "6/6 - 0s - loss: 95.6823 - val_loss: 557.7943\n",
      "Epoch 206/1000\n",
      "6/6 - 0s - loss: 95.5051 - val_loss: 557.3370\n",
      "Epoch 207/1000\n",
      "6/6 - 0s - loss: 95.3227 - val_loss: 556.8977\n",
      "Epoch 208/1000\n",
      "6/6 - 0s - loss: 95.1654 - val_loss: 556.4576\n",
      "Epoch 209/1000\n",
      "6/6 - 0s - loss: 94.9973 - val_loss: 556.0217\n",
      "Epoch 210/1000\n",
      "6/6 - 0s - loss: 94.8285 - val_loss: 555.5704\n",
      "Epoch 211/1000\n",
      "6/6 - 0s - loss: 94.6790 - val_loss: 555.0992\n",
      "Epoch 212/1000\n",
      "6/6 - 0s - loss: 94.4902 - val_loss: 554.6589\n",
      "Epoch 213/1000\n",
      "6/6 - 0s - loss: 94.3206 - val_loss: 554.2350\n",
      "Epoch 214/1000\n",
      "6/6 - 0s - loss: 94.1652 - val_loss: 553.7908\n",
      "Epoch 215/1000\n",
      "6/6 - 0s - loss: 93.9913 - val_loss: 553.3680\n",
      "Epoch 216/1000\n",
      "6/6 - 0s - loss: 93.8261 - val_loss: 552.9249\n",
      "Epoch 217/1000\n",
      "6/6 - 0s - loss: 93.6575 - val_loss: 552.4919\n",
      "Epoch 218/1000\n",
      "6/6 - 0s - loss: 93.5043 - val_loss: 552.0501\n",
      "Epoch 219/1000\n",
      "6/6 - 0s - loss: 93.3342 - val_loss: 551.6353\n",
      "Epoch 220/1000\n",
      "6/6 - 0s - loss: 93.1866 - val_loss: 551.1921\n",
      "Epoch 221/1000\n",
      "6/6 - 0s - loss: 93.0033 - val_loss: 550.7818\n",
      "Epoch 222/1000\n",
      "6/6 - 0s - loss: 92.8554 - val_loss: 550.3135\n",
      "Epoch 223/1000\n",
      "6/6 - 0s - loss: 92.6826 - val_loss: 549.8671\n",
      "Epoch 224/1000\n",
      "6/6 - 0s - loss: 92.5315 - val_loss: 549.4343\n",
      "Epoch 225/1000\n",
      "6/6 - 0s - loss: 92.3530 - val_loss: 549.0255\n",
      "Epoch 226/1000\n",
      "6/6 - 0s - loss: 92.2075 - val_loss: 548.6022\n",
      "Epoch 227/1000\n",
      "6/6 - 0s - loss: 92.0612 - val_loss: 548.1667\n",
      "Epoch 228/1000\n",
      "6/6 - 0s - loss: 91.8908 - val_loss: 547.7601\n",
      "Epoch 229/1000\n",
      "6/6 - 0s - loss: 91.7437 - val_loss: 547.3203\n",
      "Epoch 230/1000\n",
      "6/6 - 0s - loss: 91.5770 - val_loss: 546.8779\n",
      "Epoch 231/1000\n",
      "6/6 - 0s - loss: 91.4252 - val_loss: 546.4295\n",
      "Epoch 232/1000\n",
      "6/6 - 0s - loss: 91.2488 - val_loss: 546.0128\n",
      "Epoch 233/1000\n",
      "6/6 - 0s - loss: 91.1075 - val_loss: 545.5572\n",
      "Epoch 234/1000\n",
      "6/6 - 0s - loss: 90.9373 - val_loss: 545.1104\n",
      "Epoch 235/1000\n",
      "6/6 - 0s - loss: 90.7832 - val_loss: 544.6887\n",
      "Epoch 236/1000\n",
      "6/6 - 0s - loss: 90.6442 - val_loss: 544.2543\n",
      "Epoch 237/1000\n",
      "6/6 - 0s - loss: 90.4653 - val_loss: 543.8719\n",
      "Epoch 238/1000\n",
      "6/6 - 0s - loss: 90.3278 - val_loss: 543.4411\n",
      "Epoch 239/1000\n",
      "6/6 - 0s - loss: 90.1852 - val_loss: 543.0269\n",
      "Epoch 240/1000\n",
      "6/6 - 0s - loss: 90.0236 - val_loss: 542.6323\n",
      "Epoch 241/1000\n",
      "6/6 - 0s - loss: 89.8886 - val_loss: 542.2216\n",
      "Epoch 242/1000\n",
      "6/6 - 0s - loss: 89.7474 - val_loss: 541.8045\n",
      "Epoch 243/1000\n",
      "6/6 - 0s - loss: 89.6025 - val_loss: 541.4022\n",
      "Epoch 244/1000\n",
      "6/6 - 0s - loss: 89.4551 - val_loss: 541.0107\n",
      "Epoch 245/1000\n",
      "6/6 - 0s - loss: 89.3147 - val_loss: 540.6168\n",
      "Epoch 246/1000\n",
      "6/6 - 0s - loss: 89.1864 - val_loss: 540.1998\n",
      "Epoch 247/1000\n",
      "6/6 - 0s - loss: 89.0312 - val_loss: 539.8071\n",
      "Epoch 248/1000\n",
      "6/6 - 0s - loss: 88.8866 - val_loss: 539.4062\n",
      "Epoch 249/1000\n",
      "6/6 - 0s - loss: 88.7390 - val_loss: 539.0192\n",
      "Epoch 250/1000\n",
      "6/6 - 0s - loss: 88.6079 - val_loss: 538.6241\n",
      "Epoch 251/1000\n",
      "6/6 - 0s - loss: 88.4833 - val_loss: 538.2225\n",
      "Epoch 252/1000\n",
      "6/6 - 0s - loss: 88.3380 - val_loss: 537.8362\n",
      "Epoch 253/1000\n",
      "6/6 - 0s - loss: 88.2022 - val_loss: 537.4481\n",
      "Epoch 254/1000\n",
      "6/6 - 0s - loss: 88.0601 - val_loss: 537.0712\n",
      "Epoch 255/1000\n",
      "6/6 - 0s - loss: 87.9247 - val_loss: 536.6910\n",
      "Epoch 256/1000\n",
      "6/6 - 0s - loss: 87.7974 - val_loss: 536.3114\n",
      "Epoch 257/1000\n",
      "6/6 - 0s - loss: 87.6490 - val_loss: 535.9499\n",
      "Epoch 258/1000\n",
      "6/6 - 0s - loss: 87.5184 - val_loss: 535.5193\n",
      "Epoch 259/1000\n",
      "6/6 - 0s - loss: 87.3822 - val_loss: 535.0704\n",
      "Epoch 260/1000\n",
      "6/6 - 0s - loss: 87.2288 - val_loss: 534.6435\n",
      "Epoch 261/1000\n",
      "6/6 - 0s - loss: 87.0846 - val_loss: 534.2139\n",
      "Epoch 262/1000\n",
      "6/6 - 0s - loss: 86.9378 - val_loss: 533.8151\n",
      "Epoch 263/1000\n",
      "6/6 - 0s - loss: 86.8168 - val_loss: 533.4124\n",
      "Epoch 264/1000\n",
      "6/6 - 0s - loss: 86.6543 - val_loss: 533.0264\n",
      "Epoch 265/1000\n",
      "6/6 - 0s - loss: 86.5340 - val_loss: 532.6166\n",
      "Epoch 266/1000\n",
      "6/6 - 0s - loss: 86.3928 - val_loss: 532.2095\n",
      "Epoch 267/1000\n",
      "6/6 - 0s - loss: 86.2575 - val_loss: 531.8298\n",
      "Epoch 268/1000\n",
      "6/6 - 0s - loss: 86.1240 - val_loss: 531.4750\n",
      "Epoch 269/1000\n",
      "6/6 - 0s - loss: 85.9980 - val_loss: 531.1163\n",
      "Epoch 270/1000\n",
      "6/6 - 0s - loss: 85.8686 - val_loss: 530.7382\n",
      "Epoch 271/1000\n",
      "6/6 - 0s - loss: 85.7593 - val_loss: 530.3192\n",
      "Epoch 272/1000\n",
      "6/6 - 0s - loss: 85.6148 - val_loss: 529.9349\n",
      "Epoch 273/1000\n",
      "6/6 - 0s - loss: 85.4717 - val_loss: 529.5552\n",
      "Epoch 274/1000\n",
      "6/6 - 0s - loss: 85.3462 - val_loss: 529.1612\n",
      "Epoch 275/1000\n",
      "6/6 - 0s - loss: 85.2168 - val_loss: 528.7871\n",
      "Epoch 276/1000\n",
      "6/6 - 0s - loss: 85.0959 - val_loss: 528.4122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/1000\n",
      "6/6 - 0s - loss: 84.9553 - val_loss: 528.0530\n",
      "Epoch 278/1000\n",
      "6/6 - 0s - loss: 84.8417 - val_loss: 527.6434\n",
      "Epoch 279/1000\n",
      "6/6 - 0s - loss: 84.6923 - val_loss: 527.2556\n",
      "Epoch 280/1000\n",
      "6/6 - 0s - loss: 84.5645 - val_loss: 526.8411\n",
      "Epoch 281/1000\n",
      "6/6 - 0s - loss: 84.4446 - val_loss: 526.4282\n",
      "Epoch 282/1000\n",
      "6/6 - 0s - loss: 84.2852 - val_loss: 526.0269\n",
      "Epoch 283/1000\n",
      "6/6 - 0s - loss: 84.1564 - val_loss: 525.6028\n",
      "Epoch 284/1000\n",
      "6/6 - 0s - loss: 84.0275 - val_loss: 525.1967\n",
      "Epoch 285/1000\n",
      "6/6 - 0s - loss: 83.8941 - val_loss: 524.8110\n",
      "Epoch 286/1000\n",
      "6/6 - 0s - loss: 83.7692 - val_loss: 524.4604\n",
      "Epoch 287/1000\n",
      "6/6 - 0s - loss: 83.6528 - val_loss: 524.0787\n",
      "Epoch 288/1000\n",
      "6/6 - 0s - loss: 83.5227 - val_loss: 523.7161\n",
      "Epoch 289/1000\n",
      "6/6 - 0s - loss: 83.4044 - val_loss: 523.3586\n",
      "Epoch 290/1000\n",
      "6/6 - 0s - loss: 83.2934 - val_loss: 522.9819\n",
      "Epoch 291/1000\n",
      "6/6 - 0s - loss: 83.1575 - val_loss: 522.6285\n",
      "Epoch 292/1000\n",
      "6/6 - 0s - loss: 83.0479 - val_loss: 522.2241\n",
      "Epoch 293/1000\n",
      "6/6 - 0s - loss: 82.9135 - val_loss: 521.8466\n",
      "Epoch 294/1000\n",
      "6/6 - 0s - loss: 82.7793 - val_loss: 521.4659\n",
      "Epoch 295/1000\n",
      "6/6 - 0s - loss: 82.6627 - val_loss: 521.0591\n",
      "Epoch 296/1000\n",
      "6/6 - 0s - loss: 82.5231 - val_loss: 520.7050\n",
      "Epoch 297/1000\n",
      "6/6 - 0s - loss: 82.4007 - val_loss: 520.3401\n",
      "Epoch 298/1000\n",
      "6/6 - 0s - loss: 82.2874 - val_loss: 519.9467\n",
      "Epoch 299/1000\n",
      "6/6 - 0s - loss: 82.1567 - val_loss: 519.5682\n",
      "Epoch 300/1000\n",
      "6/6 - 0s - loss: 82.0268 - val_loss: 519.1922\n",
      "Epoch 301/1000\n",
      "6/6 - 0s - loss: 81.9013 - val_loss: 518.8067\n",
      "Epoch 302/1000\n",
      "6/6 - 0s - loss: 81.7811 - val_loss: 518.4542\n",
      "Epoch 303/1000\n",
      "6/6 - 0s - loss: 81.6689 - val_loss: 518.0632\n",
      "Epoch 304/1000\n",
      "6/6 - 0s - loss: 81.5411 - val_loss: 517.7034\n",
      "Epoch 305/1000\n",
      "6/6 - 0s - loss: 81.4139 - val_loss: 517.3632\n",
      "Epoch 306/1000\n",
      "6/6 - 0s - loss: 81.2917 - val_loss: 517.0164\n",
      "Epoch 307/1000\n",
      "6/6 - 0s - loss: 81.1629 - val_loss: 516.6310\n",
      "Epoch 308/1000\n",
      "6/6 - 0s - loss: 81.0550 - val_loss: 516.2365\n",
      "Epoch 309/1000\n",
      "6/6 - 0s - loss: 80.9111 - val_loss: 515.8738\n",
      "Epoch 310/1000\n",
      "6/6 - 0s - loss: 80.7849 - val_loss: 515.4806\n",
      "Epoch 311/1000\n",
      "6/6 - 0s - loss: 80.6539 - val_loss: 515.0894\n",
      "Epoch 312/1000\n",
      "6/6 - 0s - loss: 80.5373 - val_loss: 514.7060\n",
      "Epoch 313/1000\n",
      "6/6 - 0s - loss: 80.4075 - val_loss: 514.3550\n",
      "Epoch 314/1000\n",
      "6/6 - 0s - loss: 80.2978 - val_loss: 513.9732\n",
      "Epoch 315/1000\n",
      "6/6 - 0s - loss: 80.1798 - val_loss: 513.6331\n",
      "Epoch 316/1000\n",
      "6/6 - 0s - loss: 80.0612 - val_loss: 513.2961\n",
      "Epoch 317/1000\n",
      "6/6 - 0s - loss: 79.9502 - val_loss: 512.9631\n",
      "Epoch 318/1000\n",
      "6/6 - 0s - loss: 79.8382 - val_loss: 512.6339\n",
      "Epoch 319/1000\n",
      "6/6 - 0s - loss: 79.7265 - val_loss: 512.2667\n",
      "Epoch 320/1000\n",
      "6/6 - 0s - loss: 79.6111 - val_loss: 511.8943\n",
      "Epoch 321/1000\n",
      "6/6 - 0s - loss: 79.4870 - val_loss: 511.5410\n",
      "Epoch 322/1000\n",
      "6/6 - 0s - loss: 79.3839 - val_loss: 511.1776\n",
      "Epoch 323/1000\n",
      "6/6 - 0s - loss: 79.2455 - val_loss: 510.8478\n",
      "Epoch 324/1000\n",
      "6/6 - 0s - loss: 79.1554 - val_loss: 510.4801\n",
      "Epoch 325/1000\n",
      "6/6 - 0s - loss: 79.0172 - val_loss: 510.1040\n",
      "Epoch 326/1000\n",
      "6/6 - 0s - loss: 78.9190 - val_loss: 509.7025\n",
      "Epoch 327/1000\n",
      "6/6 - 0s - loss: 78.7783 - val_loss: 509.3372\n",
      "Epoch 328/1000\n",
      "6/6 - 0s - loss: 78.6535 - val_loss: 508.9870\n",
      "Epoch 329/1000\n",
      "6/6 - 0s - loss: 78.5448 - val_loss: 508.6004\n",
      "Epoch 330/1000\n",
      "6/6 - 0s - loss: 78.4295 - val_loss: 508.2298\n",
      "Epoch 331/1000\n",
      "6/6 - 0s - loss: 78.3091 - val_loss: 507.8894\n",
      "Epoch 332/1000\n",
      "6/6 - 0s - loss: 78.2019 - val_loss: 507.5356\n",
      "Epoch 333/1000\n",
      "6/6 - 0s - loss: 78.0955 - val_loss: 507.1696\n",
      "Epoch 334/1000\n",
      "6/6 - 0s - loss: 77.9767 - val_loss: 506.8051\n",
      "Epoch 335/1000\n",
      "6/6 - 0s - loss: 77.8680 - val_loss: 506.4546\n",
      "Epoch 336/1000\n",
      "6/6 - 0s - loss: 77.7521 - val_loss: 506.1158\n",
      "Epoch 337/1000\n",
      "6/6 - 0s - loss: 77.6237 - val_loss: 505.7440\n",
      "Epoch 338/1000\n",
      "6/6 - 0s - loss: 77.5168 - val_loss: 505.3252\n",
      "Epoch 339/1000\n",
      "6/6 - 0s - loss: 77.3828 - val_loss: 504.9426\n",
      "Epoch 340/1000\n",
      "6/6 - 0s - loss: 77.2717 - val_loss: 504.5131\n",
      "Epoch 341/1000\n",
      "6/6 - 0s - loss: 77.1352 - val_loss: 504.1519\n",
      "Epoch 342/1000\n",
      "6/6 - 0s - loss: 77.0168 - val_loss: 503.7950\n",
      "Epoch 343/1000\n",
      "6/6 - 0s - loss: 76.9196 - val_loss: 503.4195\n",
      "Epoch 344/1000\n",
      "6/6 - 0s - loss: 76.7850 - val_loss: 503.0846\n",
      "Epoch 345/1000\n",
      "6/6 - 0s - loss: 76.6847 - val_loss: 502.7202\n",
      "Epoch 346/1000\n",
      "6/6 - 0s - loss: 76.5693 - val_loss: 502.3706\n",
      "Epoch 347/1000\n",
      "6/6 - 0s - loss: 76.4683 - val_loss: 502.0189\n",
      "Epoch 348/1000\n",
      "6/6 - 0s - loss: 76.3521 - val_loss: 501.7009\n",
      "Epoch 349/1000\n",
      "6/6 - 0s - loss: 76.2513 - val_loss: 501.3932\n",
      "Epoch 350/1000\n",
      "6/6 - 0s - loss: 76.1461 - val_loss: 501.0375\n",
      "Epoch 351/1000\n",
      "6/6 - 0s - loss: 76.0288 - val_loss: 500.6981\n",
      "Epoch 352/1000\n",
      "6/6 - 0s - loss: 75.9276 - val_loss: 500.3519\n",
      "Epoch 353/1000\n",
      "6/6 - 0s - loss: 75.8203 - val_loss: 500.0207\n",
      "Epoch 354/1000\n",
      "6/6 - 0s - loss: 75.7075 - val_loss: 499.6788\n",
      "Epoch 355/1000\n",
      "6/6 - 0s - loss: 75.6039 - val_loss: 499.3340\n",
      "Epoch 356/1000\n",
      "6/6 - 0s - loss: 75.4848 - val_loss: 499.0019\n",
      "Epoch 357/1000\n",
      "6/6 - 0s - loss: 75.3824 - val_loss: 498.6503\n",
      "Epoch 358/1000\n",
      "6/6 - 0s - loss: 75.2703 - val_loss: 498.3074\n",
      "Epoch 359/1000\n",
      "6/6 - 0s - loss: 75.1658 - val_loss: 497.9674\n",
      "Epoch 360/1000\n",
      "6/6 - 0s - loss: 75.0545 - val_loss: 497.6478\n",
      "Epoch 361/1000\n",
      "6/6 - 0s - loss: 74.9624 - val_loss: 497.2846\n",
      "Epoch 362/1000\n",
      "6/6 - 0s - loss: 74.8384 - val_loss: 496.9351\n",
      "Epoch 363/1000\n",
      "6/6 - 0s - loss: 74.7316 - val_loss: 496.5859\n",
      "Epoch 364/1000\n",
      "6/6 - 0s - loss: 74.6304 - val_loss: 496.2208\n",
      "Epoch 365/1000\n",
      "6/6 - 0s - loss: 74.4974 - val_loss: 495.9006\n",
      "Epoch 366/1000\n",
      "6/6 - 0s - loss: 74.4035 - val_loss: 495.5236\n",
      "Epoch 367/1000\n",
      "6/6 - 0s - loss: 74.2889 - val_loss: 495.1637\n",
      "Epoch 368/1000\n",
      "6/6 - 0s - loss: 74.1840 - val_loss: 494.7892\n",
      "Epoch 369/1000\n",
      "6/6 - 0s - loss: 74.0704 - val_loss: 494.4294\n",
      "Epoch 370/1000\n",
      "6/6 - 0s - loss: 73.9561 - val_loss: 494.1188\n",
      "Epoch 371/1000\n",
      "6/6 - 0s - loss: 73.8586 - val_loss: 493.7766\n",
      "Epoch 372/1000\n",
      "6/6 - 0s - loss: 73.7514 - val_loss: 493.4042\n",
      "Epoch 373/1000\n",
      "6/6 - 0s - loss: 73.6327 - val_loss: 493.0689\n",
      "Epoch 374/1000\n",
      "6/6 - 0s - loss: 73.5362 - val_loss: 492.7527\n",
      "Epoch 375/1000\n",
      "6/6 - 0s - loss: 73.4464 - val_loss: 492.4011\n",
      "Epoch 376/1000\n",
      "6/6 - 0s - loss: 73.3196 - val_loss: 492.0772\n",
      "Epoch 377/1000\n",
      "6/6 - 0s - loss: 73.2140 - val_loss: 491.7461\n",
      "Epoch 378/1000\n",
      "6/6 - 0s - loss: 73.1133 - val_loss: 491.3599\n",
      "Epoch 379/1000\n",
      "6/6 - 0s - loss: 72.9966 - val_loss: 491.0201\n",
      "Epoch 380/1000\n",
      "6/6 - 0s - loss: 72.8872 - val_loss: 490.6867\n",
      "Epoch 381/1000\n",
      "6/6 - 0s - loss: 72.8082 - val_loss: 490.3167\n",
      "Epoch 382/1000\n",
      "6/6 - 0s - loss: 72.6809 - val_loss: 489.9528\n",
      "Epoch 383/1000\n",
      "6/6 - 0s - loss: 72.5705 - val_loss: 489.6369\n",
      "Epoch 384/1000\n",
      "6/6 - 0s - loss: 72.4704 - val_loss: 489.3184\n",
      "Epoch 385/1000\n",
      "6/6 - 0s - loss: 72.3567 - val_loss: 488.9621\n",
      "Epoch 386/1000\n",
      "6/6 - 0s - loss: 72.2514 - val_loss: 488.5784\n",
      "Epoch 387/1000\n",
      "6/6 - 0s - loss: 72.1475 - val_loss: 488.2313\n",
      "Epoch 388/1000\n",
      "6/6 - 0s - loss: 72.0413 - val_loss: 487.8980\n",
      "Epoch 389/1000\n",
      "6/6 - 0s - loss: 71.9363 - val_loss: 487.5540\n",
      "Epoch 390/1000\n",
      "6/6 - 0s - loss: 71.8262 - val_loss: 487.2021\n",
      "Epoch 391/1000\n",
      "6/6 - 0s - loss: 71.7327 - val_loss: 486.8704\n",
      "Epoch 392/1000\n",
      "6/6 - 0s - loss: 71.6131 - val_loss: 486.5374\n",
      "Epoch 393/1000\n",
      "6/6 - 0s - loss: 71.5122 - val_loss: 486.2151\n",
      "Epoch 394/1000\n",
      "6/6 - 0s - loss: 71.4031 - val_loss: 485.8902\n",
      "Epoch 395/1000\n",
      "6/6 - 0s - loss: 71.3120 - val_loss: 485.5012\n",
      "Epoch 396/1000\n",
      "6/6 - 0s - loss: 71.1981 - val_loss: 485.1506\n",
      "Epoch 397/1000\n",
      "6/6 - 0s - loss: 71.0816 - val_loss: 484.8875\n",
      "Epoch 398/1000\n",
      "6/6 - 0s - loss: 71.0000 - val_loss: 484.5101\n",
      "Epoch 399/1000\n",
      "6/6 - 0s - loss: 70.8740 - val_loss: 484.1560\n",
      "Epoch 400/1000\n",
      "6/6 - 0s - loss: 70.7841 - val_loss: 483.8240\n",
      "Epoch 401/1000\n",
      "6/6 - 0s - loss: 70.6829 - val_loss: 483.4858\n",
      "Epoch 402/1000\n",
      "6/6 - 0s - loss: 70.5651 - val_loss: 483.1649\n",
      "Epoch 403/1000\n",
      "6/6 - 0s - loss: 70.4624 - val_loss: 482.8179\n",
      "Epoch 404/1000\n",
      "6/6 - 0s - loss: 70.3539 - val_loss: 482.4331\n",
      "Epoch 405/1000\n",
      "6/6 - 0s - loss: 70.2432 - val_loss: 482.0909\n",
      "Epoch 406/1000\n",
      "6/6 - 0s - loss: 70.1384 - val_loss: 481.7487\n",
      "Epoch 407/1000\n",
      "6/6 - 0s - loss: 70.0236 - val_loss: 481.3770\n",
      "Epoch 408/1000\n",
      "6/6 - 0s - loss: 69.9187 - val_loss: 481.0349\n",
      "Epoch 409/1000\n",
      "6/6 - 0s - loss: 69.8108 - val_loss: 480.7308\n",
      "Epoch 410/1000\n",
      "6/6 - 0s - loss: 69.7021 - val_loss: 480.3880\n",
      "Epoch 411/1000\n",
      "6/6 - 0s - loss: 69.6136 - val_loss: 480.0267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412/1000\n",
      "6/6 - 0s - loss: 69.5125 - val_loss: 479.7032\n",
      "Epoch 413/1000\n",
      "6/6 - 0s - loss: 69.4106 - val_loss: 479.3900\n",
      "Epoch 414/1000\n",
      "6/6 - 0s - loss: 69.3061 - val_loss: 479.0605\n",
      "Epoch 415/1000\n",
      "6/6 - 0s - loss: 69.2167 - val_loss: 478.7296\n",
      "Epoch 416/1000\n",
      "6/6 - 0s - loss: 69.1079 - val_loss: 478.4429\n",
      "Epoch 417/1000\n",
      "6/6 - 0s - loss: 69.0157 - val_loss: 478.1475\n",
      "Epoch 418/1000\n",
      "6/6 - 0s - loss: 68.9280 - val_loss: 477.8237\n",
      "Epoch 419/1000\n",
      "6/6 - 0s - loss: 68.8347 - val_loss: 477.4788\n",
      "Epoch 420/1000\n",
      "6/6 - 0s - loss: 68.7358 - val_loss: 477.1499\n",
      "Epoch 421/1000\n",
      "6/6 - 0s - loss: 68.6347 - val_loss: 476.8213\n",
      "Epoch 422/1000\n",
      "6/6 - 0s - loss: 68.5358 - val_loss: 476.4723\n",
      "Epoch 423/1000\n",
      "6/6 - 0s - loss: 68.4353 - val_loss: 476.1259\n",
      "Epoch 424/1000\n",
      "6/6 - 0s - loss: 68.3254 - val_loss: 475.8010\n",
      "Epoch 425/1000\n",
      "6/6 - 0s - loss: 68.2371 - val_loss: 475.4359\n",
      "Epoch 426/1000\n",
      "6/6 - 0s - loss: 68.1355 - val_loss: 475.0704\n",
      "Epoch 427/1000\n",
      "6/6 - 0s - loss: 68.0261 - val_loss: 474.7180\n",
      "Epoch 428/1000\n",
      "6/6 - 0s - loss: 67.9276 - val_loss: 474.3959\n",
      "Epoch 429/1000\n",
      "6/6 - 0s - loss: 67.8325 - val_loss: 474.0686\n",
      "Epoch 430/1000\n",
      "6/6 - 0s - loss: 67.7267 - val_loss: 473.7487\n",
      "Epoch 431/1000\n",
      "6/6 - 0s - loss: 67.6340 - val_loss: 473.4181\n",
      "Epoch 432/1000\n",
      "6/6 - 0s - loss: 67.5356 - val_loss: 473.0482\n",
      "Epoch 433/1000\n",
      "6/6 - 0s - loss: 67.4421 - val_loss: 472.7568\n",
      "Epoch 434/1000\n",
      "6/6 - 0s - loss: 67.3455 - val_loss: 472.4312\n",
      "Epoch 435/1000\n",
      "6/6 - 0s - loss: 67.2415 - val_loss: 472.1018\n",
      "Epoch 436/1000\n",
      "6/6 - 0s - loss: 67.1583 - val_loss: 471.8117\n",
      "Epoch 437/1000\n",
      "6/6 - 0s - loss: 67.0650 - val_loss: 471.4849\n",
      "Epoch 438/1000\n",
      "6/6 - 0s - loss: 66.9806 - val_loss: 471.1560\n",
      "Epoch 439/1000\n",
      "6/6 - 0s - loss: 66.8774 - val_loss: 470.8916\n",
      "Epoch 440/1000\n",
      "6/6 - 0s - loss: 66.7904 - val_loss: 470.6028\n",
      "Epoch 441/1000\n",
      "6/6 - 0s - loss: 66.7056 - val_loss: 470.2788\n",
      "Epoch 442/1000\n",
      "6/6 - 0s - loss: 66.6290 - val_loss: 469.9413\n",
      "Epoch 443/1000\n",
      "6/6 - 0s - loss: 66.5179 - val_loss: 469.6176\n",
      "Epoch 444/1000\n",
      "6/6 - 0s - loss: 66.4150 - val_loss: 469.3203\n",
      "Epoch 445/1000\n",
      "6/6 - 0s - loss: 66.3278 - val_loss: 469.0138\n",
      "Epoch 446/1000\n",
      "6/6 - 0s - loss: 66.2340 - val_loss: 468.6835\n",
      "Epoch 447/1000\n",
      "6/6 - 0s - loss: 66.1461 - val_loss: 468.3727\n",
      "Epoch 448/1000\n",
      "6/6 - 0s - loss: 66.0409 - val_loss: 468.1031\n",
      "Epoch 449/1000\n",
      "6/6 - 0s - loss: 65.9570 - val_loss: 467.7706\n",
      "Epoch 450/1000\n",
      "6/6 - 0s - loss: 65.8640 - val_loss: 467.4432\n",
      "Epoch 451/1000\n",
      "6/6 - 0s - loss: 65.7846 - val_loss: 467.1293\n",
      "Epoch 452/1000\n",
      "6/6 - 0s - loss: 65.6801 - val_loss: 466.8231\n",
      "Epoch 453/1000\n",
      "6/6 - 0s - loss: 65.5879 - val_loss: 466.5230\n",
      "Epoch 454/1000\n",
      "6/6 - 0s - loss: 65.5011 - val_loss: 466.1936\n",
      "Epoch 455/1000\n",
      "6/6 - 0s - loss: 65.4191 - val_loss: 465.8441\n",
      "Epoch 456/1000\n",
      "6/6 - 0s - loss: 65.3124 - val_loss: 465.5353\n",
      "Epoch 457/1000\n",
      "6/6 - 0s - loss: 65.2235 - val_loss: 465.2468\n",
      "Epoch 458/1000\n",
      "6/6 - 0s - loss: 65.1427 - val_loss: 464.9372\n",
      "Epoch 459/1000\n",
      "6/6 - 0s - loss: 65.0511 - val_loss: 464.6656\n",
      "Epoch 460/1000\n",
      "6/6 - 0s - loss: 64.9596 - val_loss: 464.3592\n",
      "Epoch 461/1000\n",
      "6/6 - 0s - loss: 64.8922 - val_loss: 464.0486\n",
      "Epoch 462/1000\n",
      "6/6 - 0s - loss: 64.7903 - val_loss: 463.7440\n",
      "Epoch 463/1000\n",
      "6/6 - 0s - loss: 64.7048 - val_loss: 463.4608\n",
      "Epoch 464/1000\n",
      "6/6 - 0s - loss: 64.6134 - val_loss: 463.1397\n",
      "Epoch 465/1000\n",
      "6/6 - 0s - loss: 64.5305 - val_loss: 462.8340\n",
      "Epoch 466/1000\n",
      "6/6 - 0s - loss: 64.4334 - val_loss: 462.5451\n",
      "Epoch 467/1000\n",
      "6/6 - 0s - loss: 64.3476 - val_loss: 462.2065\n",
      "Epoch 468/1000\n",
      "6/6 - 0s - loss: 64.2607 - val_loss: 461.9002\n",
      "Epoch 469/1000\n",
      "6/6 - 0s - loss: 64.1573 - val_loss: 461.5944\n",
      "Epoch 470/1000\n",
      "6/6 - 0s - loss: 64.0865 - val_loss: 461.2697\n",
      "Epoch 471/1000\n",
      "6/6 - 0s - loss: 63.9982 - val_loss: 460.9250\n",
      "Epoch 472/1000\n",
      "6/6 - 0s - loss: 63.8869 - val_loss: 460.6590\n",
      "Epoch 473/1000\n",
      "6/6 - 0s - loss: 63.8216 - val_loss: 460.3359\n",
      "Epoch 474/1000\n",
      "6/6 - 0s - loss: 63.7060 - val_loss: 460.0172\n",
      "Epoch 475/1000\n",
      "6/6 - 0s - loss: 63.6279 - val_loss: 459.6935\n",
      "Epoch 476/1000\n",
      "6/6 - 0s - loss: 63.5386 - val_loss: 459.3285\n",
      "Epoch 477/1000\n",
      "6/6 - 0s - loss: 63.4316 - val_loss: 459.0168\n",
      "Epoch 478/1000\n",
      "6/6 - 0s - loss: 63.3413 - val_loss: 458.7264\n",
      "Epoch 479/1000\n",
      "6/6 - 0s - loss: 63.2473 - val_loss: 458.3903\n",
      "Epoch 480/1000\n",
      "6/6 - 0s - loss: 63.1644 - val_loss: 458.1376\n",
      "Epoch 481/1000\n",
      "6/6 - 0s - loss: 63.0647 - val_loss: 457.7826\n",
      "Epoch 482/1000\n",
      "6/6 - 0s - loss: 62.9843 - val_loss: 457.4763\n",
      "Epoch 483/1000\n",
      "6/6 - 0s - loss: 62.8958 - val_loss: 457.1880\n",
      "Epoch 484/1000\n",
      "6/6 - 0s - loss: 62.8089 - val_loss: 456.8289\n",
      "Epoch 485/1000\n",
      "6/6 - 0s - loss: 62.7085 - val_loss: 456.5979\n",
      "Epoch 486/1000\n",
      "6/6 - 0s - loss: 62.6340 - val_loss: 456.3033\n",
      "Epoch 487/1000\n",
      "6/6 - 0s - loss: 62.5518 - val_loss: 455.9818\n",
      "Epoch 488/1000\n",
      "6/6 - 0s - loss: 62.4713 - val_loss: 455.7476\n",
      "Epoch 489/1000\n",
      "6/6 - 0s - loss: 62.3797 - val_loss: 455.4484\n",
      "Epoch 490/1000\n",
      "6/6 - 0s - loss: 62.2970 - val_loss: 455.1923\n",
      "Epoch 491/1000\n",
      "6/6 - 0s - loss: 62.2196 - val_loss: 454.8951\n",
      "Epoch 492/1000\n",
      "6/6 - 0s - loss: 62.1355 - val_loss: 454.5652\n",
      "Epoch 493/1000\n",
      "6/6 - 0s - loss: 62.0473 - val_loss: 454.2830\n",
      "Epoch 494/1000\n",
      "6/6 - 0s - loss: 61.9610 - val_loss: 453.9640\n",
      "Epoch 495/1000\n",
      "6/6 - 0s - loss: 61.8720 - val_loss: 453.6616\n",
      "Epoch 496/1000\n",
      "6/6 - 0s - loss: 61.7860 - val_loss: 453.3489\n",
      "Epoch 497/1000\n",
      "6/6 - 0s - loss: 61.6831 - val_loss: 453.0587\n",
      "Epoch 498/1000\n",
      "6/6 - 0s - loss: 61.6103 - val_loss: 452.7896\n",
      "Epoch 499/1000\n",
      "6/6 - 0s - loss: 61.5293 - val_loss: 452.4825\n",
      "Epoch 500/1000\n",
      "6/6 - 0s - loss: 61.4512 - val_loss: 452.1758\n",
      "Epoch 501/1000\n",
      "6/6 - 0s - loss: 61.3617 - val_loss: 451.8709\n",
      "Epoch 502/1000\n",
      "6/6 - 0s - loss: 61.2738 - val_loss: 451.5535\n",
      "Epoch 503/1000\n",
      "6/6 - 0s - loss: 61.1734 - val_loss: 451.2788\n",
      "Epoch 504/1000\n",
      "6/6 - 0s - loss: 61.0969 - val_loss: 451.0016\n",
      "Epoch 505/1000\n",
      "6/6 - 0s - loss: 61.0242 - val_loss: 450.6816\n",
      "Epoch 506/1000\n",
      "6/6 - 0s - loss: 60.9413 - val_loss: 450.4095\n",
      "Epoch 507/1000\n",
      "6/6 - 0s - loss: 60.8570 - val_loss: 450.1069\n",
      "Epoch 508/1000\n",
      "6/6 - 0s - loss: 60.7692 - val_loss: 449.8372\n",
      "Epoch 509/1000\n",
      "6/6 - 0s - loss: 60.6886 - val_loss: 449.5441\n",
      "Epoch 510/1000\n",
      "6/6 - 0s - loss: 60.6062 - val_loss: 449.2325\n",
      "Epoch 511/1000\n",
      "6/6 - 0s - loss: 60.5180 - val_loss: 448.9359\n",
      "Epoch 512/1000\n",
      "6/6 - 0s - loss: 60.4309 - val_loss: 448.6432\n",
      "Epoch 513/1000\n",
      "6/6 - 0s - loss: 60.3553 - val_loss: 448.2951\n",
      "Epoch 514/1000\n",
      "6/6 - 0s - loss: 60.2563 - val_loss: 448.0052\n",
      "Epoch 515/1000\n",
      "6/6 - 0s - loss: 60.1661 - val_loss: 447.7104\n",
      "Epoch 516/1000\n",
      "6/6 - 0s - loss: 60.0797 - val_loss: 447.4232\n",
      "Epoch 517/1000\n",
      "6/6 - 0s - loss: 60.0019 - val_loss: 447.0898\n",
      "Epoch 518/1000\n",
      "6/6 - 0s - loss: 59.9048 - val_loss: 446.8024\n",
      "Epoch 519/1000\n",
      "6/6 - 0s - loss: 59.8285 - val_loss: 446.5293\n",
      "Epoch 520/1000\n",
      "6/6 - 0s - loss: 59.7339 - val_loss: 446.1787\n",
      "Epoch 521/1000\n",
      "6/6 - 0s - loss: 59.6552 - val_loss: 445.9082\n",
      "Epoch 522/1000\n",
      "6/6 - 0s - loss: 59.5604 - val_loss: 445.5920\n",
      "Epoch 523/1000\n",
      "6/6 - 0s - loss: 59.4736 - val_loss: 445.3296\n",
      "Epoch 524/1000\n",
      "6/6 - 0s - loss: 59.3825 - val_loss: 445.0110\n",
      "Epoch 525/1000\n",
      "6/6 - 0s - loss: 59.2960 - val_loss: 444.7010\n",
      "Epoch 526/1000\n",
      "6/6 - 0s - loss: 59.2073 - val_loss: 444.5035\n",
      "Epoch 527/1000\n",
      "6/6 - 0s - loss: 59.1246 - val_loss: 444.1346\n",
      "Epoch 528/1000\n",
      "6/6 - 0s - loss: 59.0458 - val_loss: 443.9606\n",
      "Epoch 529/1000\n",
      "6/6 - 0s - loss: 58.9737 - val_loss: 443.5703\n",
      "Epoch 530/1000\n",
      "6/6 - 0s - loss: 58.8881 - val_loss: 443.4001\n",
      "Epoch 531/1000\n",
      "6/6 - 0s - loss: 58.8147 - val_loss: 443.0777\n",
      "Epoch 532/1000\n",
      "6/6 - 0s - loss: 58.7394 - val_loss: 442.7904\n",
      "Epoch 533/1000\n",
      "6/6 - 0s - loss: 58.6594 - val_loss: 442.5425\n",
      "Epoch 534/1000\n",
      "6/6 - 0s - loss: 58.5833 - val_loss: 442.2200\n",
      "Epoch 535/1000\n",
      "6/6 - 0s - loss: 58.5034 - val_loss: 442.0211\n",
      "Epoch 536/1000\n",
      "6/6 - 0s - loss: 58.4222 - val_loss: 441.6888\n",
      "Epoch 537/1000\n",
      "6/6 - 0s - loss: 58.3616 - val_loss: 441.4385\n",
      "Epoch 538/1000\n",
      "6/6 - 0s - loss: 58.2722 - val_loss: 441.1090\n",
      "Epoch 539/1000\n",
      "6/6 - 0s - loss: 58.1866 - val_loss: 440.8683\n",
      "Epoch 540/1000\n",
      "6/6 - 0s - loss: 58.1165 - val_loss: 440.5786\n",
      "Epoch 541/1000\n",
      "6/6 - 0s - loss: 58.0344 - val_loss: 440.3255\n",
      "Epoch 542/1000\n",
      "6/6 - 0s - loss: 57.9647 - val_loss: 440.0059\n",
      "Epoch 543/1000\n",
      "6/6 - 0s - loss: 57.8832 - val_loss: 439.7613\n",
      "Epoch 544/1000\n",
      "6/6 - 0s - loss: 57.8003 - val_loss: 439.4884\n",
      "Epoch 545/1000\n",
      "6/6 - 0s - loss: 57.7258 - val_loss: 439.2109\n",
      "Epoch 546/1000\n",
      "6/6 - 0s - loss: 57.6482 - val_loss: 438.9750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 547/1000\n",
      "6/6 - 0s - loss: 57.5683 - val_loss: 438.6676\n",
      "Epoch 548/1000\n",
      "6/6 - 0s - loss: 57.4975 - val_loss: 438.4093\n",
      "Epoch 549/1000\n",
      "6/6 - 0s - loss: 57.4174 - val_loss: 438.1376\n",
      "Epoch 550/1000\n",
      "6/6 - 0s - loss: 57.3422 - val_loss: 437.8759\n",
      "Epoch 551/1000\n",
      "6/6 - 0s - loss: 57.2651 - val_loss: 437.6277\n",
      "Epoch 552/1000\n",
      "6/6 - 0s - loss: 57.1918 - val_loss: 437.3939\n",
      "Epoch 553/1000\n",
      "6/6 - 0s - loss: 57.1266 - val_loss: 437.0959\n",
      "Epoch 554/1000\n",
      "6/6 - 0s - loss: 57.0490 - val_loss: 436.8393\n",
      "Epoch 555/1000\n",
      "6/6 - 0s - loss: 56.9655 - val_loss: 436.5575\n",
      "Epoch 556/1000\n",
      "6/6 - 0s - loss: 56.8929 - val_loss: 436.3237\n",
      "Epoch 557/1000\n",
      "6/6 - 0s - loss: 56.8242 - val_loss: 436.0286\n",
      "Epoch 558/1000\n",
      "6/6 - 0s - loss: 56.7309 - val_loss: 435.7959\n",
      "Epoch 559/1000\n",
      "6/6 - 0s - loss: 56.6802 - val_loss: 435.4812\n",
      "Epoch 560/1000\n",
      "6/6 - 0s - loss: 56.5822 - val_loss: 435.2144\n",
      "Epoch 561/1000\n",
      "6/6 - 0s - loss: 56.5242 - val_loss: 434.9108\n",
      "Epoch 562/1000\n",
      "6/6 - 0s - loss: 56.4383 - val_loss: 434.6507\n",
      "Epoch 563/1000\n",
      "6/6 - 0s - loss: 56.3592 - val_loss: 434.3835\n",
      "Epoch 564/1000\n",
      "6/6 - 0s - loss: 56.2867 - val_loss: 434.1349\n",
      "Epoch 565/1000\n",
      "6/6 - 0s - loss: 56.2073 - val_loss: 433.8550\n",
      "Epoch 566/1000\n",
      "6/6 - 0s - loss: 56.1504 - val_loss: 433.5891\n",
      "Epoch 567/1000\n",
      "6/6 - 0s - loss: 56.0643 - val_loss: 433.3228\n",
      "Epoch 568/1000\n",
      "6/6 - 0s - loss: 55.9927 - val_loss: 433.0827\n",
      "Epoch 569/1000\n",
      "6/6 - 0s - loss: 55.9234 - val_loss: 432.8019\n",
      "Epoch 570/1000\n",
      "6/6 - 0s - loss: 55.8466 - val_loss: 432.5858\n",
      "Epoch 571/1000\n",
      "6/6 - 0s - loss: 55.7714 - val_loss: 432.3155\n",
      "Epoch 572/1000\n",
      "6/6 - 0s - loss: 55.7143 - val_loss: 432.0518\n",
      "Epoch 573/1000\n",
      "6/6 - 0s - loss: 55.6280 - val_loss: 431.7637\n",
      "Epoch 574/1000\n",
      "6/6 - 0s - loss: 55.5550 - val_loss: 431.5035\n",
      "Epoch 575/1000\n",
      "6/6 - 0s - loss: 55.4761 - val_loss: 431.1965\n",
      "Epoch 576/1000\n",
      "6/6 - 0s - loss: 55.4027 - val_loss: 430.9380\n",
      "Epoch 577/1000\n",
      "6/6 - 0s - loss: 55.3265 - val_loss: 430.6210\n",
      "Epoch 578/1000\n",
      "6/6 - 0s - loss: 55.2458 - val_loss: 430.3715\n",
      "Epoch 579/1000\n",
      "6/6 - 0s - loss: 55.1720 - val_loss: 430.0806\n",
      "Epoch 580/1000\n",
      "6/6 - 0s - loss: 55.0972 - val_loss: 429.8611\n",
      "Epoch 581/1000\n",
      "6/6 - 0s - loss: 55.0353 - val_loss: 429.5099\n",
      "Epoch 582/1000\n",
      "6/6 - 0s - loss: 54.9604 - val_loss: 429.3191\n",
      "Epoch 583/1000\n",
      "6/6 - 0s - loss: 54.8872 - val_loss: 428.9696\n",
      "Epoch 584/1000\n",
      "6/6 - 0s - loss: 54.8077 - val_loss: 428.8156\n",
      "Epoch 585/1000\n",
      "6/6 - 0s - loss: 54.7442 - val_loss: 428.3902\n",
      "Epoch 586/1000\n",
      "6/6 - 0s - loss: 54.6689 - val_loss: 428.2894\n",
      "Epoch 587/1000\n",
      "6/6 - 0s - loss: 54.5965 - val_loss: 427.8284\n",
      "Epoch 588/1000\n",
      "6/6 - 0s - loss: 54.5348 - val_loss: 427.8073\n",
      "Epoch 589/1000\n",
      "6/6 - 0s - loss: 54.4517 - val_loss: 427.3180\n",
      "Epoch 590/1000\n",
      "6/6 - 0s - loss: 54.3853 - val_loss: 427.2894\n",
      "Epoch 591/1000\n",
      "6/6 - 0s - loss: 54.3128 - val_loss: 426.7639\n",
      "Epoch 592/1000\n",
      "6/6 - 0s - loss: 54.2489 - val_loss: 426.6487\n",
      "Epoch 593/1000\n",
      "6/6 - 0s - loss: 54.1608 - val_loss: 426.1790\n",
      "Epoch 594/1000\n",
      "6/6 - 0s - loss: 54.0982 - val_loss: 426.1000\n",
      "Epoch 595/1000\n",
      "6/6 - 0s - loss: 54.0145 - val_loss: 425.6753\n",
      "Epoch 596/1000\n",
      "6/6 - 0s - loss: 53.9431 - val_loss: 425.5159\n",
      "Epoch 597/1000\n",
      "6/6 - 0s - loss: 53.8785 - val_loss: 425.1467\n",
      "Epoch 598/1000\n",
      "6/6 - 0s - loss: 53.8143 - val_loss: 424.9144\n",
      "Epoch 599/1000\n",
      "6/6 - 0s - loss: 53.7269 - val_loss: 424.6027\n",
      "Epoch 600/1000\n",
      "6/6 - 0s - loss: 53.6709 - val_loss: 424.3060\n",
      "Epoch 601/1000\n",
      "6/6 - 0s - loss: 53.5849 - val_loss: 424.1563\n",
      "Epoch 602/1000\n",
      "6/6 - 0s - loss: 53.5235 - val_loss: 423.7584\n",
      "Epoch 603/1000\n",
      "6/6 - 0s - loss: 53.4532 - val_loss: 423.7030\n",
      "Epoch 604/1000\n",
      "6/6 - 0s - loss: 53.3890 - val_loss: 423.2068\n",
      "Epoch 605/1000\n",
      "6/6 - 0s - loss: 53.3152 - val_loss: 423.1349\n",
      "Epoch 606/1000\n",
      "6/6 - 0s - loss: 53.2367 - val_loss: 422.6600\n",
      "Epoch 607/1000\n",
      "6/6 - 0s - loss: 53.1800 - val_loss: 422.6123\n",
      "Epoch 608/1000\n",
      "6/6 - 0s - loss: 53.1011 - val_loss: 422.0259\n",
      "Epoch 609/1000\n",
      "6/6 - 0s - loss: 53.0271 - val_loss: 422.1658\n",
      "Epoch 610/1000\n",
      "6/6 - 0s - loss: 52.9503 - val_loss: 421.4598\n",
      "Epoch 611/1000\n",
      "6/6 - 0s - loss: 52.8810 - val_loss: 421.6673\n",
      "Epoch 612/1000\n",
      "6/6 - 0s - loss: 52.8161 - val_loss: 420.8935\n",
      "Epoch 613/1000\n",
      "6/6 - 0s - loss: 52.7497 - val_loss: 421.1407\n",
      "Epoch 614/1000\n",
      "6/6 - 0s - loss: 52.6840 - val_loss: 420.2747\n",
      "Epoch 615/1000\n",
      "6/6 - 0s - loss: 52.6168 - val_loss: 420.6313\n",
      "Epoch 616/1000\n",
      "6/6 - 0s - loss: 52.5423 - val_loss: 419.8763\n",
      "Epoch 617/1000\n",
      "6/6 - 0s - loss: 52.4806 - val_loss: 419.9424\n",
      "Epoch 618/1000\n",
      "6/6 - 0s - loss: 52.4121 - val_loss: 419.4434\n",
      "Epoch 619/1000\n",
      "6/6 - 0s - loss: 52.3403 - val_loss: 419.4374\n",
      "Epoch 620/1000\n",
      "6/6 - 0s - loss: 52.2801 - val_loss: 418.9664\n",
      "Epoch 621/1000\n",
      "6/6 - 0s - loss: 52.2104 - val_loss: 418.8243\n",
      "Epoch 622/1000\n",
      "6/6 - 0s - loss: 52.1552 - val_loss: 418.4697\n",
      "Epoch 623/1000\n",
      "6/6 - 0s - loss: 52.0812 - val_loss: 418.2628\n",
      "Epoch 624/1000\n",
      "6/6 - 0s - loss: 52.0162 - val_loss: 418.0461\n",
      "Epoch 625/1000\n",
      "6/6 - 0s - loss: 51.9490 - val_loss: 417.6467\n",
      "Epoch 626/1000\n",
      "6/6 - 0s - loss: 51.8795 - val_loss: 417.4565\n",
      "Epoch 627/1000\n",
      "6/6 - 0s - loss: 51.8105 - val_loss: 417.0419\n",
      "Epoch 628/1000\n",
      "6/6 - 0s - loss: 51.7263 - val_loss: 416.8505\n",
      "Epoch 629/1000\n",
      "6/6 - 0s - loss: 51.6551 - val_loss: 416.4500\n",
      "Epoch 630/1000\n",
      "6/6 - 0s - loss: 51.5858 - val_loss: 416.1270\n",
      "Epoch 631/1000\n",
      "6/6 - 0s - loss: 51.4980 - val_loss: 415.7815\n",
      "Epoch 632/1000\n",
      "6/6 - 0s - loss: 51.4183 - val_loss: 415.5465\n",
      "Epoch 633/1000\n",
      "6/6 - 0s - loss: 51.3603 - val_loss: 415.2722\n",
      "Epoch 634/1000\n",
      "6/6 - 0s - loss: 51.2888 - val_loss: 414.9205\n",
      "Epoch 635/1000\n",
      "6/6 - 0s - loss: 51.2106 - val_loss: 414.6476\n",
      "Epoch 636/1000\n",
      "6/6 - 0s - loss: 51.1458 - val_loss: 414.3544\n",
      "Epoch 637/1000\n",
      "6/6 - 0s - loss: 51.0635 - val_loss: 414.0108\n",
      "Epoch 638/1000\n",
      "6/6 - 0s - loss: 50.9939 - val_loss: 413.8041\n",
      "Epoch 639/1000\n",
      "6/6 - 0s - loss: 50.9177 - val_loss: 413.4476\n",
      "Epoch 640/1000\n",
      "6/6 - 0s - loss: 50.8454 - val_loss: 413.2129\n",
      "Epoch 641/1000\n",
      "6/6 - 0s - loss: 50.7651 - val_loss: 412.9013\n",
      "Epoch 642/1000\n",
      "6/6 - 0s - loss: 50.7048 - val_loss: 412.7140\n",
      "Epoch 643/1000\n",
      "6/6 - 0s - loss: 50.6291 - val_loss: 412.3721\n",
      "Epoch 644/1000\n",
      "6/6 - 0s - loss: 50.5472 - val_loss: 412.2153\n",
      "Epoch 645/1000\n",
      "6/6 - 0s - loss: 50.4896 - val_loss: 411.9002\n",
      "Epoch 646/1000\n",
      "6/6 - 0s - loss: 50.4214 - val_loss: 411.6750\n",
      "Epoch 647/1000\n",
      "6/6 - 0s - loss: 50.3442 - val_loss: 411.4883\n",
      "Epoch 648/1000\n",
      "6/6 - 0s - loss: 50.2909 - val_loss: 411.1815\n",
      "Epoch 649/1000\n",
      "6/6 - 0s - loss: 50.2086 - val_loss: 410.9895\n",
      "Epoch 650/1000\n",
      "6/6 - 0s - loss: 50.1379 - val_loss: 410.6987\n",
      "Epoch 651/1000\n",
      "6/6 - 0s - loss: 50.0625 - val_loss: 410.4144\n",
      "Epoch 652/1000\n",
      "6/6 - 0s - loss: 49.9901 - val_loss: 410.1394\n",
      "Epoch 653/1000\n",
      "6/6 - 0s - loss: 49.9154 - val_loss: 409.8708\n",
      "Epoch 654/1000\n",
      "6/6 - 0s - loss: 49.8460 - val_loss: 409.6381\n",
      "Epoch 655/1000\n",
      "6/6 - 0s - loss: 49.7800 - val_loss: 409.4099\n",
      "Epoch 656/1000\n",
      "6/6 - 0s - loss: 49.7139 - val_loss: 409.1810\n",
      "Epoch 657/1000\n",
      "6/6 - 0s - loss: 49.6427 - val_loss: 408.9867\n",
      "Epoch 658/1000\n",
      "6/6 - 0s - loss: 49.5932 - val_loss: 408.7072\n",
      "Epoch 659/1000\n",
      "6/6 - 0s - loss: 49.5247 - val_loss: 408.4652\n",
      "Epoch 660/1000\n",
      "6/6 - 0s - loss: 49.4448 - val_loss: 408.2267\n",
      "Epoch 661/1000\n",
      "6/6 - 0s - loss: 49.3745 - val_loss: 407.9541\n",
      "Epoch 662/1000\n",
      "6/6 - 0s - loss: 49.3027 - val_loss: 407.6806\n",
      "Epoch 663/1000\n",
      "6/6 - 0s - loss: 49.2390 - val_loss: 407.3974\n",
      "Epoch 664/1000\n",
      "6/6 - 0s - loss: 49.1639 - val_loss: 407.1895\n",
      "Epoch 665/1000\n",
      "6/6 - 0s - loss: 49.1024 - val_loss: 406.9178\n",
      "Epoch 666/1000\n",
      "6/6 - 0s - loss: 49.0348 - val_loss: 406.7366\n",
      "Epoch 667/1000\n",
      "6/6 - 0s - loss: 48.9794 - val_loss: 406.4145\n",
      "Epoch 668/1000\n",
      "6/6 - 0s - loss: 48.9131 - val_loss: 406.2118\n",
      "Epoch 669/1000\n",
      "6/6 - 0s - loss: 48.8416 - val_loss: 405.9554\n",
      "Epoch 670/1000\n",
      "6/6 - 0s - loss: 48.7801 - val_loss: 405.7741\n",
      "Epoch 671/1000\n",
      "6/6 - 0s - loss: 48.7211 - val_loss: 405.5017\n",
      "Epoch 672/1000\n",
      "6/6 - 0s - loss: 48.6637 - val_loss: 405.2754\n",
      "Epoch 673/1000\n",
      "6/6 - 0s - loss: 48.6017 - val_loss: 405.0233\n",
      "Epoch 674/1000\n",
      "6/6 - 0s - loss: 48.5326 - val_loss: 404.8261\n",
      "Epoch 675/1000\n",
      "6/6 - 0s - loss: 48.4779 - val_loss: 404.5677\n",
      "Epoch 676/1000\n",
      "6/6 - 0s - loss: 48.4053 - val_loss: 404.3684\n",
      "Epoch 677/1000\n",
      "6/6 - 0s - loss: 48.3481 - val_loss: 404.0693\n",
      "Epoch 678/1000\n",
      "6/6 - 0s - loss: 48.2900 - val_loss: 403.8693\n",
      "Epoch 679/1000\n",
      "6/6 - 0s - loss: 48.2212 - val_loss: 403.5918\n",
      "Epoch 680/1000\n",
      "6/6 - 0s - loss: 48.1622 - val_loss: 403.4017\n",
      "Epoch 681/1000\n",
      "6/6 - 0s - loss: 48.1064 - val_loss: 403.1665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 682/1000\n",
      "6/6 - 0s - loss: 48.0433 - val_loss: 402.9426\n",
      "Epoch 683/1000\n",
      "6/6 - 0s - loss: 47.9906 - val_loss: 402.7267\n",
      "Epoch 684/1000\n",
      "6/6 - 0s - loss: 47.9297 - val_loss: 402.5226\n",
      "Epoch 685/1000\n",
      "6/6 - 0s - loss: 47.8775 - val_loss: 402.2379\n",
      "Epoch 686/1000\n",
      "6/6 - 0s - loss: 47.8094 - val_loss: 402.0381\n",
      "Epoch 687/1000\n",
      "6/6 - 0s - loss: 47.7408 - val_loss: 401.7716\n",
      "Epoch 688/1000\n",
      "6/6 - 0s - loss: 47.6831 - val_loss: 401.5676\n",
      "Epoch 689/1000\n",
      "6/6 - 0s - loss: 47.6275 - val_loss: 401.2779\n",
      "Epoch 690/1000\n",
      "6/6 - 0s - loss: 47.5593 - val_loss: 401.0743\n",
      "Epoch 691/1000\n",
      "6/6 - 0s - loss: 47.5087 - val_loss: 400.8268\n",
      "Epoch 692/1000\n",
      "6/6 - 0s - loss: 47.4440 - val_loss: 400.5328\n",
      "Epoch 693/1000\n",
      "6/6 - 0s - loss: 47.3833 - val_loss: 400.3517\n",
      "Epoch 694/1000\n",
      "6/6 - 0s - loss: 47.3110 - val_loss: 400.0378\n",
      "Epoch 695/1000\n",
      "6/6 - 0s - loss: 47.2602 - val_loss: 399.7999\n",
      "Epoch 696/1000\n",
      "6/6 - 0s - loss: 47.1811 - val_loss: 399.5346\n",
      "Epoch 697/1000\n",
      "6/6 - 0s - loss: 47.1249 - val_loss: 399.2194\n",
      "Epoch 698/1000\n",
      "6/6 - 0s - loss: 47.0596 - val_loss: 399.0063\n",
      "Epoch 699/1000\n",
      "6/6 - 0s - loss: 46.9914 - val_loss: 398.6494\n",
      "Epoch 700/1000\n",
      "6/6 - 0s - loss: 46.9395 - val_loss: 398.4576\n",
      "Epoch 701/1000\n",
      "6/6 - 0s - loss: 46.8672 - val_loss: 398.2025\n",
      "Epoch 702/1000\n",
      "6/6 - 0s - loss: 46.8219 - val_loss: 397.8830\n",
      "Epoch 703/1000\n",
      "6/6 - 0s - loss: 46.7567 - val_loss: 397.7171\n",
      "Epoch 704/1000\n",
      "6/6 - 0s - loss: 46.7002 - val_loss: 397.4136\n",
      "Epoch 705/1000\n",
      "6/6 - 0s - loss: 46.6293 - val_loss: 397.1158\n",
      "Epoch 706/1000\n",
      "6/6 - 0s - loss: 46.5760 - val_loss: 397.0309\n",
      "Epoch 707/1000\n",
      "6/6 - 0s - loss: 46.5035 - val_loss: 396.3313\n",
      "Epoch 708/1000\n",
      "6/6 - 0s - loss: 46.4572 - val_loss: 396.6060\n",
      "Epoch 709/1000\n",
      "6/6 - 0s - loss: 46.3868 - val_loss: 395.8937\n",
      "Epoch 710/1000\n",
      "6/6 - 0s - loss: 46.3307 - val_loss: 395.9615\n",
      "Epoch 711/1000\n",
      "6/6 - 0s - loss: 46.2726 - val_loss: 395.5004\n",
      "Epoch 712/1000\n",
      "6/6 - 0s - loss: 46.2041 - val_loss: 395.3297\n",
      "Epoch 713/1000\n",
      "6/6 - 0s - loss: 46.1432 - val_loss: 395.1885\n",
      "Epoch 714/1000\n",
      "6/6 - 0s - loss: 46.0878 - val_loss: 394.6823\n",
      "Epoch 715/1000\n",
      "6/6 - 0s - loss: 46.0146 - val_loss: 394.9010\n",
      "Epoch 716/1000\n",
      "6/6 - 0s - loss: 45.9692 - val_loss: 394.0325\n",
      "Epoch 717/1000\n",
      "6/6 - 0s - loss: 45.9047 - val_loss: 394.3293\n",
      "Epoch 718/1000\n",
      "6/6 - 0s - loss: 45.8477 - val_loss: 393.7611\n",
      "Epoch 719/1000\n",
      "6/6 - 0s - loss: 45.7813 - val_loss: 393.9027\n",
      "Epoch 720/1000\n",
      "6/6 - 0s - loss: 45.7252 - val_loss: 393.3769\n",
      "Epoch 721/1000\n",
      "6/6 - 0s - loss: 45.6606 - val_loss: 393.2199\n",
      "Epoch 722/1000\n",
      "6/6 - 0s - loss: 45.5934 - val_loss: 392.8015\n",
      "Epoch 723/1000\n",
      "6/6 - 0s - loss: 45.5210 - val_loss: 392.7828\n",
      "Epoch 724/1000\n",
      "6/6 - 0s - loss: 45.4761 - val_loss: 392.2836\n",
      "Epoch 725/1000\n",
      "6/6 - 0s - loss: 45.4077 - val_loss: 392.2766\n",
      "Epoch 726/1000\n",
      "6/6 - 0s - loss: 45.3535 - val_loss: 391.8188\n",
      "Epoch 727/1000\n",
      "6/6 - 0s - loss: 45.2885 - val_loss: 391.7602\n",
      "Epoch 728/1000\n",
      "6/6 - 0s - loss: 45.2310 - val_loss: 391.5204\n",
      "Epoch 729/1000\n",
      "6/6 - 0s - loss: 45.1862 - val_loss: 391.2166\n",
      "Epoch 730/1000\n",
      "6/6 - 0s - loss: 45.1181 - val_loss: 391.0155\n",
      "Epoch 731/1000\n",
      "6/6 - 0s - loss: 45.0561 - val_loss: 390.6888\n",
      "Epoch 732/1000\n",
      "6/6 - 0s - loss: 45.0065 - val_loss: 390.5386\n",
      "Epoch 733/1000\n",
      "6/6 - 0s - loss: 44.9312 - val_loss: 390.2556\n",
      "Epoch 734/1000\n",
      "6/6 - 0s - loss: 44.8798 - val_loss: 390.0859\n",
      "Epoch 735/1000\n",
      "6/6 - 0s - loss: 44.8156 - val_loss: 389.7684\n",
      "Epoch 736/1000\n",
      "6/6 - 0s - loss: 44.7498 - val_loss: 389.4950\n",
      "Epoch 737/1000\n",
      "6/6 - 0s - loss: 44.6905 - val_loss: 389.2152\n",
      "Epoch 738/1000\n",
      "6/6 - 0s - loss: 44.6311 - val_loss: 389.2262\n",
      "Epoch 739/1000\n",
      "6/6 - 0s - loss: 44.5800 - val_loss: 388.6354\n",
      "Epoch 740/1000\n",
      "6/6 - 0s - loss: 44.5096 - val_loss: 388.7433\n",
      "Epoch 741/1000\n",
      "6/6 - 0s - loss: 44.4397 - val_loss: 388.1190\n",
      "Epoch 742/1000\n",
      "6/6 - 0s - loss: 44.3729 - val_loss: 388.4011\n",
      "Epoch 743/1000\n",
      "6/6 - 0s - loss: 44.3156 - val_loss: 387.6759\n",
      "Epoch 744/1000\n",
      "6/6 - 0s - loss: 44.2572 - val_loss: 387.9220\n",
      "Epoch 745/1000\n",
      "6/6 - 0s - loss: 44.1910 - val_loss: 387.0551\n",
      "Epoch 746/1000\n",
      "6/6 - 0s - loss: 44.1370 - val_loss: 387.6233\n",
      "Epoch 747/1000\n",
      "6/6 - 0s - loss: 44.0820 - val_loss: 386.5676\n",
      "Epoch 748/1000\n",
      "6/6 - 0s - loss: 44.0159 - val_loss: 387.2342\n",
      "Epoch 749/1000\n",
      "6/6 - 0s - loss: 43.9640 - val_loss: 386.0487\n",
      "Epoch 750/1000\n",
      "6/6 - 0s - loss: 43.8983 - val_loss: 386.9561\n",
      "Epoch 751/1000\n",
      "6/6 - 0s - loss: 43.8156 - val_loss: 385.7542\n",
      "Epoch 752/1000\n",
      "6/6 - 0s - loss: 43.7459 - val_loss: 386.2365\n",
      "Epoch 753/1000\n",
      "6/6 - 0s - loss: 43.6820 - val_loss: 385.4776\n",
      "Epoch 754/1000\n",
      "6/6 - 0s - loss: 43.6184 - val_loss: 385.5916\n",
      "Epoch 755/1000\n",
      "6/6 - 0s - loss: 43.5630 - val_loss: 385.3064\n",
      "Epoch 756/1000\n",
      "6/6 - 0s - loss: 43.4815 - val_loss: 384.9905\n",
      "Epoch 757/1000\n",
      "6/6 - 0s - loss: 43.4274 - val_loss: 384.8925\n",
      "Epoch 758/1000\n",
      "6/6 - 0s - loss: 43.3666 - val_loss: 384.5062\n",
      "Epoch 759/1000\n",
      "6/6 - 0s - loss: 43.3034 - val_loss: 384.4482\n",
      "Epoch 760/1000\n",
      "6/6 - 0s - loss: 43.2427 - val_loss: 384.1765\n",
      "Epoch 761/1000\n",
      "6/6 - 0s - loss: 43.1841 - val_loss: 384.1305\n",
      "Epoch 762/1000\n",
      "6/6 - 0s - loss: 43.1278 - val_loss: 383.8170\n",
      "Epoch 763/1000\n",
      "6/6 - 0s - loss: 43.0714 - val_loss: 383.7598\n",
      "Epoch 764/1000\n",
      "6/6 - 0s - loss: 43.0225 - val_loss: 383.3882\n",
      "Epoch 765/1000\n",
      "6/6 - 0s - loss: 42.9498 - val_loss: 383.2904\n",
      "Epoch 766/1000\n",
      "6/6 - 0s - loss: 42.8959 - val_loss: 382.9823\n",
      "Epoch 767/1000\n",
      "6/6 - 0s - loss: 42.8338 - val_loss: 382.8752\n",
      "Epoch 768/1000\n",
      "6/6 - 0s - loss: 42.7728 - val_loss: 382.6192\n",
      "Epoch 769/1000\n",
      "6/6 - 0s - loss: 42.7231 - val_loss: 382.4862\n",
      "Epoch 770/1000\n",
      "6/6 - 0s - loss: 42.6632 - val_loss: 382.2517\n",
      "Epoch 771/1000\n",
      "6/6 - 0s - loss: 42.6073 - val_loss: 382.1181\n",
      "Epoch 772/1000\n",
      "6/6 - 0s - loss: 42.5591 - val_loss: 381.8577\n",
      "Epoch 773/1000\n",
      "6/6 - 0s - loss: 42.4906 - val_loss: 381.7155\n",
      "Epoch 774/1000\n",
      "6/6 - 0s - loss: 42.4385 - val_loss: 381.4565\n",
      "Epoch 775/1000\n",
      "6/6 - 0s - loss: 42.3803 - val_loss: 381.2789\n",
      "Epoch 776/1000\n",
      "6/6 - 0s - loss: 42.3159 - val_loss: 381.0140\n",
      "Epoch 777/1000\n",
      "6/6 - 0s - loss: 42.2487 - val_loss: 380.8662\n",
      "Epoch 778/1000\n",
      "6/6 - 0s - loss: 42.1905 - val_loss: 380.5584\n",
      "Epoch 779/1000\n",
      "6/6 - 0s - loss: 42.1319 - val_loss: 380.3869\n",
      "Epoch 780/1000\n",
      "6/6 - 0s - loss: 42.0741 - val_loss: 380.1017\n",
      "Epoch 781/1000\n",
      "6/6 - 0s - loss: 42.0112 - val_loss: 379.9830\n",
      "Epoch 782/1000\n",
      "6/6 - 0s - loss: 41.9583 - val_loss: 379.7028\n",
      "Epoch 783/1000\n",
      "6/6 - 0s - loss: 41.9076 - val_loss: 379.6025\n",
      "Epoch 784/1000\n",
      "6/6 - 0s - loss: 41.8480 - val_loss: 379.3453\n",
      "Epoch 785/1000\n",
      "6/6 - 0s - loss: 41.8028 - val_loss: 379.1884\n",
      "Epoch 786/1000\n",
      "6/6 - 0s - loss: 41.7523 - val_loss: 378.9670\n",
      "Epoch 787/1000\n",
      "6/6 - 0s - loss: 41.6957 - val_loss: 378.8073\n",
      "Epoch 788/1000\n",
      "6/6 - 0s - loss: 41.6371 - val_loss: 378.6091\n",
      "Epoch 789/1000\n",
      "6/6 - 0s - loss: 41.5956 - val_loss: 378.4539\n",
      "Epoch 790/1000\n",
      "6/6 - 0s - loss: 41.5407 - val_loss: 378.2483\n",
      "Epoch 791/1000\n",
      "6/6 - 0s - loss: 41.4949 - val_loss: 378.0538\n",
      "Epoch 792/1000\n",
      "6/6 - 0s - loss: 41.4442 - val_loss: 377.8895\n",
      "Epoch 793/1000\n",
      "6/6 - 0s - loss: 41.3902 - val_loss: 377.7032\n",
      "Epoch 794/1000\n",
      "6/6 - 0s - loss: 41.3344 - val_loss: 377.4956\n",
      "Epoch 795/1000\n",
      "6/6 - 0s - loss: 41.2870 - val_loss: 377.3052\n",
      "Epoch 796/1000\n",
      "6/6 - 0s - loss: 41.2280 - val_loss: 377.0891\n",
      "Epoch 797/1000\n",
      "6/6 - 0s - loss: 41.1742 - val_loss: 376.8937\n",
      "Epoch 798/1000\n",
      "6/6 - 0s - loss: 41.1179 - val_loss: 376.7036\n",
      "Epoch 799/1000\n",
      "6/6 - 0s - loss: 41.0661 - val_loss: 376.5214\n",
      "Epoch 800/1000\n",
      "6/6 - 0s - loss: 41.0236 - val_loss: 376.2204\n",
      "Epoch 801/1000\n",
      "6/6 - 0s - loss: 40.9598 - val_loss: 376.1108\n",
      "Epoch 802/1000\n",
      "6/6 - 0s - loss: 40.9079 - val_loss: 375.8353\n",
      "Epoch 803/1000\n",
      "6/6 - 0s - loss: 40.8583 - val_loss: 375.6784\n",
      "Epoch 804/1000\n",
      "6/6 - 0s - loss: 40.8014 - val_loss: 375.4384\n",
      "Epoch 805/1000\n",
      "6/6 - 0s - loss: 40.7520 - val_loss: 375.2272\n",
      "Epoch 806/1000\n",
      "6/6 - 0s - loss: 40.6867 - val_loss: 374.9956\n",
      "Epoch 807/1000\n",
      "6/6 - 0s - loss: 40.6299 - val_loss: 374.7973\n",
      "Epoch 808/1000\n",
      "6/6 - 0s - loss: 40.5768 - val_loss: 374.5661\n",
      "Epoch 809/1000\n",
      "6/6 - 0s - loss: 40.5153 - val_loss: 374.3525\n",
      "Epoch 810/1000\n",
      "6/6 - 0s - loss: 40.4609 - val_loss: 374.0562\n",
      "Epoch 811/1000\n",
      "6/6 - 0s - loss: 40.4024 - val_loss: 374.0016\n",
      "Epoch 812/1000\n",
      "6/6 - 0s - loss: 40.3474 - val_loss: 373.6808\n",
      "Epoch 813/1000\n",
      "6/6 - 0s - loss: 40.2948 - val_loss: 373.6013\n",
      "Epoch 814/1000\n",
      "6/6 - 0s - loss: 40.2515 - val_loss: 373.3325\n",
      "Epoch 815/1000\n",
      "6/6 - 0s - loss: 40.1941 - val_loss: 373.2155\n",
      "Epoch 816/1000\n",
      "6/6 - 0s - loss: 40.1450 - val_loss: 372.9867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 817/1000\n",
      "6/6 - 0s - loss: 40.1042 - val_loss: 372.8335\n",
      "Epoch 818/1000\n",
      "6/6 - 0s - loss: 40.0355 - val_loss: 372.6867\n",
      "Epoch 819/1000\n",
      "6/6 - 0s - loss: 39.9840 - val_loss: 372.5305\n",
      "Epoch 820/1000\n",
      "6/6 - 0s - loss: 39.9312 - val_loss: 372.2573\n",
      "Epoch 821/1000\n",
      "6/6 - 0s - loss: 39.8771 - val_loss: 372.1652\n",
      "Epoch 822/1000\n",
      "6/6 - 0s - loss: 39.8172 - val_loss: 371.8047\n",
      "Epoch 823/1000\n",
      "6/6 - 0s - loss: 39.7610 - val_loss: 371.8650\n",
      "Epoch 824/1000\n",
      "6/6 - 0s - loss: 39.7161 - val_loss: 371.3635\n",
      "Epoch 825/1000\n",
      "6/6 - 0s - loss: 39.6554 - val_loss: 371.5354\n",
      "Epoch 826/1000\n",
      "6/6 - 0s - loss: 39.6054 - val_loss: 370.9915\n",
      "Epoch 827/1000\n",
      "6/6 - 0s - loss: 39.5453 - val_loss: 371.0382\n",
      "Epoch 828/1000\n",
      "6/6 - 0s - loss: 39.4833 - val_loss: 370.6982\n",
      "Epoch 829/1000\n",
      "6/6 - 0s - loss: 39.4360 - val_loss: 370.5734\n",
      "Epoch 830/1000\n",
      "6/6 - 0s - loss: 39.3744 - val_loss: 370.2827\n",
      "Epoch 831/1000\n",
      "6/6 - 0s - loss: 39.3048 - val_loss: 370.2721\n",
      "Epoch 832/1000\n",
      "6/6 - 0s - loss: 39.2605 - val_loss: 369.9620\n",
      "Epoch 833/1000\n",
      "6/6 - 0s - loss: 39.2130 - val_loss: 369.8676\n",
      "Epoch 834/1000\n",
      "6/6 - 0s - loss: 39.1485 - val_loss: 369.6405\n",
      "Epoch 835/1000\n",
      "6/6 - 0s - loss: 39.0966 - val_loss: 369.5338\n",
      "Epoch 836/1000\n",
      "6/6 - 0s - loss: 39.0513 - val_loss: 369.3412\n",
      "Epoch 837/1000\n",
      "6/6 - 0s - loss: 38.9956 - val_loss: 369.1921\n",
      "Epoch 838/1000\n",
      "6/6 - 0s - loss: 38.9492 - val_loss: 369.0548\n",
      "Epoch 839/1000\n",
      "6/6 - 0s - loss: 38.9053 - val_loss: 368.8219\n",
      "Epoch 840/1000\n",
      "6/6 - 0s - loss: 38.8512 - val_loss: 368.7116\n",
      "Epoch 841/1000\n",
      "6/6 - 0s - loss: 38.7871 - val_loss: 368.5031\n",
      "Epoch 842/1000\n",
      "6/6 - 0s - loss: 38.7557 - val_loss: 368.3885\n",
      "Epoch 843/1000\n",
      "6/6 - 0s - loss: 38.6888 - val_loss: 368.2065\n",
      "Epoch 844/1000\n",
      "6/6 - 0s - loss: 38.6442 - val_loss: 368.0269\n",
      "Epoch 845/1000\n",
      "6/6 - 0s - loss: 38.5876 - val_loss: 367.9174\n",
      "Epoch 846/1000\n",
      "6/6 - 0s - loss: 38.5438 - val_loss: 367.6576\n",
      "Epoch 847/1000\n",
      "6/6 - 0s - loss: 38.4876 - val_loss: 367.6049\n",
      "Epoch 848/1000\n",
      "6/6 - 0s - loss: 38.4371 - val_loss: 367.3309\n",
      "Epoch 849/1000\n",
      "6/6 - 0s - loss: 38.3884 - val_loss: 367.1911\n",
      "Epoch 850/1000\n",
      "6/6 - 0s - loss: 38.3313 - val_loss: 367.0381\n",
      "Epoch 851/1000\n",
      "6/6 - 0s - loss: 38.2833 - val_loss: 366.8238\n",
      "Epoch 852/1000\n",
      "6/6 - 0s - loss: 38.2355 - val_loss: 366.7393\n",
      "Epoch 853/1000\n",
      "6/6 - 0s - loss: 38.1761 - val_loss: 366.4934\n",
      "Epoch 854/1000\n",
      "6/6 - 0s - loss: 38.1224 - val_loss: 366.4165\n",
      "Epoch 855/1000\n",
      "6/6 - 0s - loss: 38.0758 - val_loss: 366.1290\n",
      "Epoch 856/1000\n",
      "6/6 - 0s - loss: 38.0235 - val_loss: 366.0319\n",
      "Epoch 857/1000\n",
      "6/6 - 0s - loss: 37.9655 - val_loss: 365.7875\n",
      "Epoch 858/1000\n",
      "6/6 - 0s - loss: 37.9281 - val_loss: 365.6026\n",
      "Epoch 859/1000\n",
      "6/6 - 0s - loss: 37.8568 - val_loss: 365.4332\n",
      "Epoch 860/1000\n",
      "6/6 - 0s - loss: 37.8060 - val_loss: 365.1918\n",
      "Epoch 861/1000\n",
      "6/6 - 0s - loss: 37.7593 - val_loss: 365.1686\n",
      "Epoch 862/1000\n",
      "6/6 - 0s - loss: 37.7025 - val_loss: 364.8093\n",
      "Epoch 863/1000\n",
      "6/6 - 0s - loss: 37.6574 - val_loss: 364.7848\n",
      "Epoch 864/1000\n",
      "6/6 - 0s - loss: 37.6070 - val_loss: 364.5247\n",
      "Epoch 865/1000\n",
      "6/6 - 0s - loss: 37.5564 - val_loss: 364.3680\n",
      "Epoch 866/1000\n",
      "6/6 - 0s - loss: 37.5069 - val_loss: 364.2126\n",
      "Epoch 867/1000\n",
      "6/6 - 0s - loss: 37.4595 - val_loss: 364.0249\n",
      "Epoch 868/1000\n",
      "6/6 - 0s - loss: 37.4040 - val_loss: 363.8179\n",
      "Epoch 869/1000\n",
      "6/6 - 0s - loss: 37.3538 - val_loss: 363.7427\n",
      "Epoch 870/1000\n",
      "6/6 - 0s - loss: 37.3088 - val_loss: 363.4292\n",
      "Epoch 871/1000\n",
      "6/6 - 0s - loss: 37.2599 - val_loss: 363.3741\n",
      "Epoch 872/1000\n",
      "6/6 - 0s - loss: 37.2063 - val_loss: 363.1059\n",
      "Epoch 873/1000\n",
      "6/6 - 0s - loss: 37.1586 - val_loss: 362.9392\n",
      "Epoch 874/1000\n",
      "6/6 - 0s - loss: 37.1061 - val_loss: 362.7647\n",
      "Epoch 875/1000\n",
      "6/6 - 0s - loss: 37.0510 - val_loss: 362.5231\n",
      "Epoch 876/1000\n",
      "6/6 - 0s - loss: 37.0071 - val_loss: 362.3644\n",
      "Epoch 877/1000\n",
      "6/6 - 0s - loss: 36.9497 - val_loss: 362.1292\n",
      "Epoch 878/1000\n",
      "6/6 - 0s - loss: 36.9089 - val_loss: 361.9408\n",
      "Epoch 879/1000\n",
      "6/6 - 0s - loss: 36.8459 - val_loss: 361.7948\n",
      "Epoch 880/1000\n",
      "6/6 - 0s - loss: 36.8000 - val_loss: 361.5040\n",
      "Epoch 881/1000\n",
      "6/6 - 0s - loss: 36.7416 - val_loss: 361.3222\n",
      "Epoch 882/1000\n",
      "6/6 - 0s - loss: 36.6841 - val_loss: 361.1217\n",
      "Epoch 883/1000\n",
      "6/6 - 0s - loss: 36.6411 - val_loss: 360.7725\n",
      "Epoch 884/1000\n",
      "6/6 - 0s - loss: 36.5826 - val_loss: 360.7639\n",
      "Epoch 885/1000\n",
      "6/6 - 0s - loss: 36.5323 - val_loss: 360.3596\n",
      "Epoch 886/1000\n",
      "6/6 - 0s - loss: 36.4776 - val_loss: 360.3072\n",
      "Epoch 887/1000\n",
      "6/6 - 0s - loss: 36.4271 - val_loss: 359.9997\n",
      "Epoch 888/1000\n",
      "6/6 - 0s - loss: 36.3765 - val_loss: 359.8275\n",
      "Epoch 889/1000\n",
      "6/6 - 0s - loss: 36.3171 - val_loss: 359.5510\n",
      "Epoch 890/1000\n",
      "6/6 - 0s - loss: 36.2672 - val_loss: 359.4421\n",
      "Epoch 891/1000\n",
      "6/6 - 0s - loss: 36.2079 - val_loss: 358.8422\n",
      "Epoch 892/1000\n",
      "6/6 - 0s - loss: 36.1434 - val_loss: 359.0227\n",
      "Epoch 893/1000\n",
      "6/6 - 0s - loss: 36.0814 - val_loss: 358.5860\n",
      "Epoch 894/1000\n",
      "6/6 - 0s - loss: 36.0418 - val_loss: 358.2919\n",
      "Epoch 895/1000\n",
      "6/6 - 0s - loss: 35.9842 - val_loss: 358.3168\n",
      "Epoch 896/1000\n",
      "6/6 - 0s - loss: 35.9302 - val_loss: 357.7762\n",
      "Epoch 897/1000\n",
      "6/6 - 0s - loss: 35.8747 - val_loss: 357.9853\n",
      "Epoch 898/1000\n",
      "6/6 - 0s - loss: 35.8323 - val_loss: 357.7149\n",
      "Epoch 899/1000\n",
      "6/6 - 0s - loss: 35.7738 - val_loss: 357.2347\n",
      "Epoch 900/1000\n",
      "6/6 - 0s - loss: 35.7251 - val_loss: 357.7190\n",
      "Epoch 901/1000\n",
      "6/6 - 0s - loss: 35.6789 - val_loss: 356.9253\n",
      "Epoch 902/1000\n",
      "6/6 - 0s - loss: 35.6387 - val_loss: 357.2386\n",
      "Epoch 903/1000\n",
      "6/6 - 0s - loss: 35.5869 - val_loss: 356.8895\n",
      "Epoch 904/1000\n",
      "6/6 - 0s - loss: 35.5259 - val_loss: 356.6922\n",
      "Epoch 905/1000\n",
      "6/6 - 0s - loss: 35.4827 - val_loss: 356.5266\n",
      "Epoch 906/1000\n",
      "6/6 - 0s - loss: 35.4174 - val_loss: 356.3172\n",
      "Epoch 907/1000\n",
      "6/6 - 0s - loss: 35.3776 - val_loss: 356.0650\n",
      "Epoch 908/1000\n",
      "6/6 - 0s - loss: 35.3126 - val_loss: 356.0534\n",
      "Epoch 909/1000\n",
      "6/6 - 0s - loss: 35.2564 - val_loss: 355.6715\n",
      "Epoch 910/1000\n",
      "6/6 - 0s - loss: 35.1941 - val_loss: 355.4195\n",
      "Epoch 911/1000\n",
      "6/6 - 0s - loss: 35.1108 - val_loss: 355.1056\n",
      "Epoch 912/1000\n",
      "6/6 - 0s - loss: 35.0140 - val_loss: 354.4831\n",
      "Epoch 913/1000\n",
      "6/6 - 0s - loss: 34.8730 - val_loss: 354.0958\n",
      "Epoch 914/1000\n",
      "6/6 - 0s - loss: 34.7320 - val_loss: 353.1517\n",
      "Epoch 915/1000\n",
      "6/6 - 0s - loss: 34.5852 - val_loss: 352.5809\n",
      "Epoch 916/1000\n",
      "6/6 - 0s - loss: 34.4311 - val_loss: 352.1371\n",
      "Epoch 917/1000\n",
      "6/6 - 0s - loss: 34.2962 - val_loss: 351.4289\n",
      "Epoch 918/1000\n",
      "6/6 - 0s - loss: 34.1865 - val_loss: 351.1707\n",
      "Epoch 919/1000\n",
      "6/6 - 0s - loss: 34.0640 - val_loss: 350.4952\n",
      "Epoch 920/1000\n",
      "6/6 - 0s - loss: 33.9558 - val_loss: 350.3204\n",
      "Epoch 921/1000\n",
      "6/6 - 0s - loss: 33.8484 - val_loss: 349.8669\n",
      "Epoch 922/1000\n",
      "6/6 - 0s - loss: 33.7539 - val_loss: 349.4738\n",
      "Epoch 923/1000\n",
      "6/6 - 0s - loss: 33.6733 - val_loss: 349.4052\n",
      "Epoch 924/1000\n",
      "6/6 - 0s - loss: 33.5801 - val_loss: 348.8233\n",
      "Epoch 925/1000\n",
      "6/6 - 0s - loss: 33.5052 - val_loss: 348.6224\n",
      "Epoch 926/1000\n",
      "6/6 - 0s - loss: 33.4327 - val_loss: 348.6032\n",
      "Epoch 927/1000\n",
      "6/6 - 0s - loss: 33.3476 - val_loss: 347.9114\n",
      "Epoch 928/1000\n",
      "6/6 - 0s - loss: 33.2716 - val_loss: 347.9438\n",
      "Epoch 929/1000\n",
      "6/6 - 0s - loss: 33.1959 - val_loss: 347.7576\n",
      "Epoch 930/1000\n",
      "6/6 - 0s - loss: 33.1300 - val_loss: 347.1209\n",
      "Epoch 931/1000\n",
      "6/6 - 0s - loss: 33.0514 - val_loss: 347.3205\n",
      "Epoch 932/1000\n",
      "6/6 - 0s - loss: 32.9774 - val_loss: 346.8219\n",
      "Epoch 933/1000\n",
      "6/6 - 0s - loss: 32.9064 - val_loss: 346.2574\n",
      "Epoch 934/1000\n",
      "6/6 - 0s - loss: 32.8356 - val_loss: 346.8815\n",
      "Epoch 935/1000\n",
      "6/6 - 0s - loss: 32.7811 - val_loss: 345.5478\n",
      "Epoch 936/1000\n",
      "6/6 - 0s - loss: 32.7122 - val_loss: 345.9795\n",
      "Epoch 937/1000\n",
      "6/6 - 0s - loss: 32.6577 - val_loss: 345.6006\n",
      "Epoch 938/1000\n",
      "6/6 - 0s - loss: 32.5805 - val_loss: 345.1338\n",
      "Epoch 939/1000\n",
      "6/6 - 0s - loss: 32.5118 - val_loss: 345.6364\n",
      "Epoch 940/1000\n",
      "6/6 - 0s - loss: 32.4598 - val_loss: 344.7269\n",
      "Epoch 941/1000\n",
      "6/6 - 0s - loss: 32.3971 - val_loss: 344.3951\n",
      "Epoch 942/1000\n",
      "6/6 - 0s - loss: 32.3424 - val_loss: 344.9786\n",
      "Epoch 943/1000\n",
      "6/6 - 0s - loss: 32.2750 - val_loss: 343.2837\n",
      "Epoch 944/1000\n",
      "6/6 - 0s - loss: 32.2322 - val_loss: 344.4406\n",
      "Epoch 945/1000\n",
      "6/6 - 0s - loss: 32.1550 - val_loss: 342.6247\n",
      "Epoch 946/1000\n",
      "6/6 - 0s - loss: 32.1049 - val_loss: 344.2806\n",
      "Epoch 947/1000\n",
      "6/6 - 0s - loss: 32.0372 - val_loss: 342.5249\n",
      "Epoch 948/1000\n",
      "6/6 - 0s - loss: 31.9755 - val_loss: 343.1304\n",
      "Epoch 949/1000\n",
      "6/6 - 0s - loss: 31.9100 - val_loss: 341.8994\n",
      "Epoch 950/1000\n",
      "6/6 - 0s - loss: 31.8317 - val_loss: 342.5740\n",
      "Epoch 951/1000\n",
      "6/6 - 0s - loss: 31.7701 - val_loss: 341.4592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 952/1000\n",
      "6/6 - 0s - loss: 31.7118 - val_loss: 341.9381\n",
      "Epoch 953/1000\n",
      "6/6 - 0s - loss: 31.6436 - val_loss: 341.1579\n",
      "Epoch 954/1000\n",
      "6/6 - 0s - loss: 31.5780 - val_loss: 341.0698\n",
      "Epoch 955/1000\n",
      "6/6 - 0s - loss: 31.5185 - val_loss: 340.7654\n",
      "Epoch 956/1000\n",
      "6/6 - 0s - loss: 31.4548 - val_loss: 340.3164\n",
      "Epoch 957/1000\n",
      "6/6 - 0s - loss: 31.4116 - val_loss: 340.1988\n",
      "Epoch 958/1000\n",
      "6/6 - 0s - loss: 31.3346 - val_loss: 339.6873\n",
      "Epoch 959/1000\n",
      "6/6 - 0s - loss: 31.2807 - val_loss: 339.6642\n",
      "Epoch 960/1000\n",
      "6/6 - 0s - loss: 31.2054 - val_loss: 339.0304\n",
      "Epoch 961/1000\n",
      "6/6 - 0s - loss: 31.1500 - val_loss: 339.1730\n",
      "Epoch 962/1000\n",
      "6/6 - 0s - loss: 31.0725 - val_loss: 338.2267\n",
      "Epoch 963/1000\n",
      "6/6 - 0s - loss: 31.0041 - val_loss: 338.2998\n",
      "Epoch 964/1000\n",
      "6/6 - 0s - loss: 30.9194 - val_loss: 337.8638\n",
      "Epoch 965/1000\n",
      "6/6 - 0s - loss: 30.8617 - val_loss: 337.8129\n",
      "Epoch 966/1000\n",
      "6/6 - 0s - loss: 30.8030 - val_loss: 337.2659\n",
      "Epoch 967/1000\n",
      "6/6 - 0s - loss: 30.7366 - val_loss: 337.2156\n",
      "Epoch 968/1000\n",
      "6/6 - 0s - loss: 30.6785 - val_loss: 337.0043\n",
      "Epoch 969/1000\n",
      "6/6 - 0s - loss: 30.6250 - val_loss: 336.9056\n",
      "Epoch 970/1000\n",
      "6/6 - 0s - loss: 30.5541 - val_loss: 336.7932\n",
      "Epoch 971/1000\n",
      "6/6 - 0s - loss: 30.4922 - val_loss: 336.5234\n",
      "Epoch 972/1000\n",
      "6/6 - 0s - loss: 30.4374 - val_loss: 336.4604\n",
      "Epoch 973/1000\n",
      "6/6 - 0s - loss: 30.3875 - val_loss: 336.1475\n",
      "Epoch 974/1000\n",
      "6/6 - 0s - loss: 30.3279 - val_loss: 336.1446\n",
      "Epoch 975/1000\n",
      "6/6 - 0s - loss: 30.2590 - val_loss: 335.7803\n",
      "Epoch 976/1000\n",
      "6/6 - 0s - loss: 30.1995 - val_loss: 335.7908\n",
      "Epoch 977/1000\n",
      "6/6 - 0s - loss: 30.1493 - val_loss: 335.4897\n",
      "Epoch 978/1000\n",
      "6/6 - 0s - loss: 30.0815 - val_loss: 335.4001\n",
      "Epoch 979/1000\n",
      "6/6 - 0s - loss: 30.0262 - val_loss: 335.1299\n",
      "Epoch 980/1000\n",
      "6/6 - 0s - loss: 29.9677 - val_loss: 334.9880\n",
      "Epoch 981/1000\n",
      "6/6 - 0s - loss: 29.9073 - val_loss: 334.7854\n",
      "Epoch 982/1000\n",
      "6/6 - 0s - loss: 29.8461 - val_loss: 334.6787\n",
      "Epoch 983/1000\n",
      "6/6 - 0s - loss: 29.8052 - val_loss: 334.4605\n",
      "Epoch 984/1000\n",
      "6/6 - 0s - loss: 29.7439 - val_loss: 334.3530\n",
      "Epoch 985/1000\n",
      "6/6 - 0s - loss: 29.6921 - val_loss: 334.2009\n",
      "Epoch 986/1000\n",
      "6/6 - 0s - loss: 29.6452 - val_loss: 334.0456\n",
      "Epoch 987/1000\n",
      "6/6 - 0s - loss: 29.5918 - val_loss: 333.8908\n",
      "Epoch 988/1000\n",
      "6/6 - 0s - loss: 29.5332 - val_loss: 333.7237\n",
      "Epoch 989/1000\n",
      "6/6 - 0s - loss: 29.4842 - val_loss: 333.6210\n",
      "Epoch 990/1000\n",
      "6/6 - 0s - loss: 29.4322 - val_loss: 333.3814\n",
      "Epoch 991/1000\n",
      "6/6 - 0s - loss: 29.3797 - val_loss: 333.2474\n",
      "Epoch 992/1000\n",
      "6/6 - 0s - loss: 29.3140 - val_loss: 333.0869\n",
      "Epoch 993/1000\n",
      "6/6 - 0s - loss: 29.2627 - val_loss: 332.8943\n",
      "Epoch 994/1000\n",
      "6/6 - 0s - loss: 29.2151 - val_loss: 332.7955\n",
      "Epoch 995/1000\n",
      "6/6 - 0s - loss: 29.1621 - val_loss: 332.5776\n",
      "Epoch 996/1000\n",
      "6/6 - 0s - loss: 29.1071 - val_loss: 332.5027\n",
      "Epoch 997/1000\n",
      "6/6 - 0s - loss: 29.0572 - val_loss: 332.3267\n",
      "Epoch 998/1000\n",
      "6/6 - 0s - loss: 29.0126 - val_loss: 332.1790\n",
      "Epoch 999/1000\n",
      "6/6 - 0s - loss: 28.9598 - val_loss: 332.0992\n",
      "Epoch 1000/1000\n",
      "6/6 - 0s - loss: 28.9217 - val_loss: 331.8192\n",
      "Score (MSE): 331.81922035914465\n",
      "Score(RMSE): 18.215905696921705\n"
     ]
    }
   ],
   "source": [
    "#Fully Connected Neural Network\n",
    "for i in range (3):\n",
    "    print(\"\\nRun \", i+1)\n",
    "    print(\"Activation: Sigmoid\")\n",
    "    print(\"Optimizer: Adam\\n\")\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(25, input_dim = x.shape[1], activation = 'sigmoid'))\n",
    "    model.add(Dense(10, activation = 'sigmoid'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "    monitor = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 3, verbose = 1, mode = 'auto')\n",
    "    model.fit(x_array_train, y_array_train, validation_data = (x_array_test, y_array_test), callbacks = [monitor], verbose = 2, epochs = 1000)\n",
    "\n",
    "    pred = model.predict(x_test)\n",
    "    score_mse = metrics.mean_squared_error(pred, y_test)\n",
    "    print(\"Score (MSE): {}\".format(score_mse))\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    score_rmse = np.sqrt(metrics.mean_squared_error(pred, y_test))\n",
    "    print(\"Score(RMSE): {}\".format(score_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33865bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chart_regression(pred.flatten(), y_test, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0d9cef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>recommended</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>15.380561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>3.628603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>6.615132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>217</td>\n",
       "      <td>55</td>\n",
       "      <td>26.897705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>7.071515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>4.267108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>144</td>\n",
       "      <td>2</td>\n",
       "      <td>7.555851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>141</td>\n",
       "      <td>3</td>\n",
       "      <td>2.218406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>151</td>\n",
       "      <td>17</td>\n",
       "      <td>23.681932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>213</td>\n",
       "      <td>3</td>\n",
       "      <td>5.193067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>5.345913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>2.215224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>4.014054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>2.036754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>170</td>\n",
       "      <td>4</td>\n",
       "      <td>5.605259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>5.214295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>3.498497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94</td>\n",
       "      <td>10</td>\n",
       "      <td>19.658707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>149</td>\n",
       "      <td>36</td>\n",
       "      <td>27.039762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>98</td>\n",
       "      <td>26</td>\n",
       "      <td>26.794903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>135</td>\n",
       "      <td>127</td>\n",
       "      <td>27.052637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>3.544752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.101093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>4.012080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>4.155113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>27.043806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>5.931900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>6.401213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>97</td>\n",
       "      <td>11</td>\n",
       "      <td>16.075254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3.858183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>5.754010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>69</td>\n",
       "      <td>5</td>\n",
       "      <td>13.585722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.020278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>8.648832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>95</td>\n",
       "      <td>26</td>\n",
       "      <td>26.038633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>3.082040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>2.542518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>146</td>\n",
       "      <td>5</td>\n",
       "      <td>7.052459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>16.132647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>26.975380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>127</td>\n",
       "      <td>6</td>\n",
       "      <td>2.942878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>139</td>\n",
       "      <td>4</td>\n",
       "      <td>11.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>11.427690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2.628334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    app_id  recommended  Prediction\n",
       "0       73            0   15.380561\n",
       "1      202            1    3.628603\n",
       "2       36            5    6.615132\n",
       "3      217           55   26.897705\n",
       "4       60            6    7.071515\n",
       "5      112            3    4.267108\n",
       "6      144            2    7.555851\n",
       "7      141            3    2.218406\n",
       "8      151           17   23.681932\n",
       "9      213            3    5.193067\n",
       "10     108            4    5.345913\n",
       "11     181            0    2.215224\n",
       "12     165            1    4.014054\n",
       "13     148            0    2.036754\n",
       "14     170            4    5.605259\n",
       "15     115            0    5.214295\n",
       "16     120            4    3.498497\n",
       "17      94           10   19.658707\n",
       "18     149           36   27.039762\n",
       "19      98           26   26.794903\n",
       "20     135          127   27.052637\n",
       "21      46            5    3.544752\n",
       "22       3            0    3.101093\n",
       "23      22            3    4.012080\n",
       "24      33            5    4.155113\n",
       "25       2           72   27.043806\n",
       "26      53            5    5.931900\n",
       "27      14            1    6.401213\n",
       "28      97           11   16.075254\n",
       "29      16            0    3.858183\n",
       "30      41            3    5.754010\n",
       "31      69            5   13.585722\n",
       "32       0            1    4.020278\n",
       "33      56            9    8.648832\n",
       "34      95           26   26.038633\n",
       "35      63            3    3.082040\n",
       "36     169            0    2.542518\n",
       "37     146            5    7.052459\n",
       "38     180            1   16.132647\n",
       "39      52           54   26.975380\n",
       "40     127            6    2.942878\n",
       "41     139            4   11.074904\n",
       "42      29            5   11.427690\n",
       "43      25            2    2.628334"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(pred, columns = ['Prediction'])\n",
    "df_x = pd.DataFrame(x_test).sort_index().reset_index()\n",
    "true_recommended = y_test.reset_index()\n",
    "\n",
    "result = pd.concat([df_x, true_recommended, predictions], axis = 1)\n",
    "show = result\n",
    "show = show.drop(show.loc[:, ~show.columns.isin(['index', 'recommended', 'Prediction'])], axis = 1)\n",
    "show.columns = ['index', 'app_id', 'recommended', 'Prediction']\n",
    "show = show.drop(['index'], axis = 1)\n",
    "show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21f1181",
   "metadata": {},
   "source": [
    "**Activation = Tanh**<br>\n",
    "**Optimizer = Adam**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99f6c319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run  1\n",
      "Activation: Tanh\n",
      "Optimizer: Adam\n",
      "\n",
      "Epoch 1/1000\n",
      "6/6 - 0s - loss: 154.6954 - val_loss: 668.8152\n",
      "Epoch 2/1000\n",
      "6/6 - 0s - loss: 146.2847 - val_loss: 655.5797\n",
      "Epoch 3/1000\n",
      "6/6 - 0s - loss: 139.5996 - val_loss: 646.3557\n",
      "Epoch 4/1000\n",
      "6/6 - 0s - loss: 135.5353 - val_loss: 640.0416\n",
      "Epoch 5/1000\n",
      "6/6 - 0s - loss: 132.2196 - val_loss: 634.8522\n",
      "Epoch 6/1000\n",
      "6/6 - 0s - loss: 129.9055 - val_loss: 629.9195\n",
      "Epoch 7/1000\n",
      "6/6 - 0s - loss: 128.2260 - val_loss: 627.0938\n",
      "Epoch 8/1000\n",
      "6/6 - 0s - loss: 126.8161 - val_loss: 625.0982\n",
      "Epoch 9/1000\n",
      "6/6 - 0s - loss: 125.7595 - val_loss: 623.2416\n",
      "Epoch 10/1000\n",
      "6/6 - 0s - loss: 124.7026 - val_loss: 621.6230\n",
      "Epoch 11/1000\n",
      "6/6 - 0s - loss: 123.8999 - val_loss: 620.0834\n",
      "Epoch 12/1000\n",
      "6/6 - 0s - loss: 123.1174 - val_loss: 618.6386\n",
      "Epoch 13/1000\n",
      "6/6 - 0s - loss: 122.4261 - val_loss: 617.2249\n",
      "Epoch 14/1000\n",
      "6/6 - 0s - loss: 121.7443 - val_loss: 615.8730\n",
      "Epoch 15/1000\n",
      "6/6 - 0s - loss: 121.1209 - val_loss: 614.5215\n",
      "Epoch 16/1000\n",
      "6/6 - 0s - loss: 120.5207 - val_loss: 613.2296\n",
      "Epoch 17/1000\n",
      "6/6 - 0s - loss: 119.8336 - val_loss: 612.0558\n",
      "Epoch 18/1000\n",
      "6/6 - 0s - loss: 119.2471 - val_loss: 610.8500\n",
      "Epoch 19/1000\n",
      "6/6 - 0s - loss: 118.7003 - val_loss: 609.6260\n",
      "Epoch 20/1000\n",
      "6/6 - 0s - loss: 118.0981 - val_loss: 608.4311\n",
      "Epoch 21/1000\n",
      "6/6 - 0s - loss: 117.5610 - val_loss: 607.2170\n",
      "Epoch 22/1000\n",
      "6/6 - 0s - loss: 116.9194 - val_loss: 606.1133\n",
      "Epoch 23/1000\n",
      "6/6 - 0s - loss: 116.4128 - val_loss: 604.9498\n",
      "Epoch 24/1000\n",
      "6/6 - 0s - loss: 115.7813 - val_loss: 603.8870\n",
      "Epoch 25/1000\n",
      "6/6 - 0s - loss: 115.2790 - val_loss: 602.6825\n",
      "Epoch 26/1000\n",
      "6/6 - 0s - loss: 114.7251 - val_loss: 601.4536\n",
      "Epoch 27/1000\n",
      "6/6 - 0s - loss: 114.1471 - val_loss: 600.3124\n",
      "Epoch 28/1000\n",
      "6/6 - 0s - loss: 113.6240 - val_loss: 599.1426\n",
      "Epoch 29/1000\n",
      "6/6 - 0s - loss: 113.0323 - val_loss: 598.0334\n",
      "Epoch 30/1000\n",
      "6/6 - 0s - loss: 112.5507 - val_loss: 596.8641\n",
      "Epoch 31/1000\n",
      "6/6 - 0s - loss: 112.0476 - val_loss: 595.7527\n",
      "Epoch 32/1000\n",
      "6/6 - 0s - loss: 111.5630 - val_loss: 594.6349\n",
      "Epoch 33/1000\n",
      "6/6 - 0s - loss: 111.0644 - val_loss: 593.5693\n",
      "Epoch 34/1000\n",
      "6/6 - 0s - loss: 110.6161 - val_loss: 592.5340\n",
      "Epoch 35/1000\n",
      "6/6 - 0s - loss: 110.1553 - val_loss: 591.5351\n",
      "Epoch 36/1000\n",
      "6/6 - 0s - loss: 109.7283 - val_loss: 590.5519\n",
      "Epoch 37/1000\n",
      "6/6 - 0s - loss: 109.3034 - val_loss: 589.5900\n",
      "Epoch 38/1000\n",
      "6/6 - 0s - loss: 108.8557 - val_loss: 588.6560\n",
      "Epoch 39/1000\n",
      "6/6 - 0s - loss: 108.4492 - val_loss: 587.6982\n",
      "Epoch 40/1000\n",
      "6/6 - 0s - loss: 108.0412 - val_loss: 586.7523\n",
      "Epoch 41/1000\n",
      "6/6 - 0s - loss: 107.6376 - val_loss: 585.7949\n",
      "Epoch 42/1000\n",
      "6/6 - 0s - loss: 107.1946 - val_loss: 584.8880\n",
      "Epoch 43/1000\n",
      "6/6 - 0s - loss: 106.8232 - val_loss: 583.9133\n",
      "Epoch 44/1000\n",
      "6/6 - 0s - loss: 106.4284 - val_loss: 582.9166\n",
      "Epoch 45/1000\n",
      "6/6 - 0s - loss: 105.9748 - val_loss: 581.9662\n",
      "Epoch 46/1000\n",
      "6/6 - 0s - loss: 105.5725 - val_loss: 581.0100\n",
      "Epoch 47/1000\n",
      "6/6 - 0s - loss: 105.2081 - val_loss: 580.0330\n",
      "Epoch 48/1000\n",
      "6/6 - 0s - loss: 104.8286 - val_loss: 579.0548\n",
      "Epoch 49/1000\n",
      "6/6 - 0s - loss: 104.3971 - val_loss: 578.1770\n",
      "Epoch 50/1000\n",
      "6/6 - 0s - loss: 104.0144 - val_loss: 577.3276\n",
      "Epoch 51/1000\n",
      "6/6 - 0s - loss: 103.6812 - val_loss: 576.4080\n",
      "Epoch 52/1000\n",
      "6/6 - 0s - loss: 103.3374 - val_loss: 575.4844\n",
      "Epoch 53/1000\n",
      "6/6 - 0s - loss: 102.9184 - val_loss: 574.6530\n",
      "Epoch 54/1000\n",
      "6/6 - 0s - loss: 102.5655 - val_loss: 573.8442\n",
      "Epoch 55/1000\n",
      "6/6 - 0s - loss: 102.2727 - val_loss: 572.9424\n",
      "Epoch 56/1000\n",
      "6/6 - 0s - loss: 101.8986 - val_loss: 572.0588\n",
      "Epoch 57/1000\n",
      "6/6 - 0s - loss: 101.5535 - val_loss: 571.1401\n",
      "Epoch 58/1000\n",
      "6/6 - 0s - loss: 101.1817 - val_loss: 570.2614\n",
      "Epoch 59/1000\n",
      "6/6 - 0s - loss: 100.8342 - val_loss: 569.4178\n",
      "Epoch 60/1000\n",
      "6/6 - 0s - loss: 100.5187 - val_loss: 568.5709\n",
      "Epoch 61/1000\n",
      "6/6 - 0s - loss: 100.1725 - val_loss: 567.7589\n",
      "Epoch 62/1000\n",
      "6/6 - 0s - loss: 99.8364 - val_loss: 566.9507\n",
      "Epoch 63/1000\n",
      "6/6 - 0s - loss: 99.5134 - val_loss: 566.1148\n",
      "Epoch 64/1000\n",
      "6/6 - 0s - loss: 99.1990 - val_loss: 565.2584\n",
      "Epoch 65/1000\n",
      "6/6 - 0s - loss: 98.8586 - val_loss: 564.3982\n",
      "Epoch 66/1000\n",
      "6/6 - 0s - loss: 98.5213 - val_loss: 563.5517\n",
      "Epoch 67/1000\n",
      "6/6 - 0s - loss: 98.1924 - val_loss: 562.7198\n",
      "Epoch 68/1000\n",
      "6/6 - 0s - loss: 97.8612 - val_loss: 561.9117\n",
      "Epoch 69/1000\n",
      "6/6 - 0s - loss: 97.5571 - val_loss: 561.0771\n",
      "Epoch 70/1000\n",
      "6/6 - 0s - loss: 97.2360 - val_loss: 560.2055\n",
      "Epoch 71/1000\n",
      "6/6 - 0s - loss: 96.9149 - val_loss: 559.3555\n",
      "Epoch 72/1000\n",
      "6/6 - 0s - loss: 96.5850 - val_loss: 558.5547\n",
      "Epoch 73/1000\n",
      "6/6 - 0s - loss: 96.2930 - val_loss: 557.7410\n",
      "Epoch 74/1000\n",
      "6/6 - 0s - loss: 95.9887 - val_loss: 556.9247\n",
      "Epoch 75/1000\n",
      "6/6 - 0s - loss: 95.6423 - val_loss: 556.1511\n",
      "Epoch 76/1000\n",
      "6/6 - 0s - loss: 95.3453 - val_loss: 555.3448\n",
      "Epoch 77/1000\n",
      "6/6 - 0s - loss: 95.0795 - val_loss: 554.4932\n",
      "Epoch 78/1000\n",
      "6/6 - 0s - loss: 94.7384 - val_loss: 553.6934\n",
      "Epoch 79/1000\n",
      "6/6 - 0s - loss: 94.4517 - val_loss: 552.8591\n",
      "Epoch 80/1000\n",
      "6/6 - 0s - loss: 94.1123 - val_loss: 552.1123\n",
      "Epoch 81/1000\n",
      "6/6 - 0s - loss: 93.8378 - val_loss: 551.3011\n",
      "Epoch 82/1000\n",
      "6/6 - 0s - loss: 93.5350 - val_loss: 550.4835\n",
      "Epoch 83/1000\n",
      "6/6 - 0s - loss: 93.2312 - val_loss: 549.6834\n",
      "Epoch 84/1000\n",
      "6/6 - 0s - loss: 92.9288 - val_loss: 548.9021\n",
      "Epoch 85/1000\n",
      "6/6 - 0s - loss: 92.6412 - val_loss: 548.1331\n",
      "Epoch 86/1000\n",
      "6/6 - 0s - loss: 92.3490 - val_loss: 547.3824\n",
      "Epoch 87/1000\n",
      "6/6 - 0s - loss: 92.0737 - val_loss: 546.6132\n",
      "Epoch 88/1000\n",
      "6/6 - 0s - loss: 91.7907 - val_loss: 545.8419\n",
      "Epoch 89/1000\n",
      "6/6 - 0s - loss: 91.5023 - val_loss: 545.0797\n",
      "Epoch 90/1000\n",
      "6/6 - 0s - loss: 91.2251 - val_loss: 544.3651\n",
      "Epoch 91/1000\n",
      "6/6 - 0s - loss: 90.9463 - val_loss: 543.6214\n",
      "Epoch 92/1000\n",
      "6/6 - 0s - loss: 90.6455 - val_loss: 542.9377\n",
      "Epoch 93/1000\n",
      "6/6 - 0s - loss: 90.3833 - val_loss: 542.2252\n",
      "Epoch 94/1000\n",
      "6/6 - 0s - loss: 90.1050 - val_loss: 541.4243\n",
      "Epoch 95/1000\n",
      "6/6 - 0s - loss: 89.8141 - val_loss: 540.6738\n",
      "Epoch 96/1000\n",
      "6/6 - 0s - loss: 89.5584 - val_loss: 539.9382\n",
      "Epoch 97/1000\n",
      "6/6 - 0s - loss: 89.2842 - val_loss: 539.1744\n",
      "Epoch 98/1000\n",
      "6/6 - 0s - loss: 89.0342 - val_loss: 538.3929\n",
      "Epoch 99/1000\n",
      "6/6 - 0s - loss: 88.7286 - val_loss: 537.7327\n",
      "Epoch 100/1000\n",
      "6/6 - 0s - loss: 88.5095 - val_loss: 536.9749\n",
      "Epoch 101/1000\n",
      "6/6 - 0s - loss: 88.2033 - val_loss: 536.3167\n",
      "Epoch 102/1000\n",
      "6/6 - 0s - loss: 87.9598 - val_loss: 535.6830\n",
      "Epoch 103/1000\n",
      "6/6 - 0s - loss: 87.7256 - val_loss: 535.0072\n",
      "Epoch 104/1000\n",
      "6/6 - 0s - loss: 87.5013 - val_loss: 534.3373\n",
      "Epoch 105/1000\n",
      "6/6 - 0s - loss: 87.2228 - val_loss: 533.6711\n",
      "Epoch 106/1000\n",
      "6/6 - 0s - loss: 86.9974 - val_loss: 532.9863\n",
      "Epoch 107/1000\n",
      "6/6 - 0s - loss: 86.7376 - val_loss: 532.2833\n",
      "Epoch 108/1000\n",
      "6/6 - 0s - loss: 86.5042 - val_loss: 531.6473\n",
      "Epoch 109/1000\n",
      "6/6 - 0s - loss: 86.2568 - val_loss: 530.9559\n",
      "Epoch 110/1000\n",
      "6/6 - 0s - loss: 86.0157 - val_loss: 530.3029\n",
      "Epoch 111/1000\n",
      "6/6 - 0s - loss: 85.7692 - val_loss: 529.6217\n",
      "Epoch 112/1000\n",
      "6/6 - 0s - loss: 85.5201 - val_loss: 528.9772\n",
      "Epoch 113/1000\n",
      "6/6 - 0s - loss: 85.2955 - val_loss: 528.3080\n",
      "Epoch 114/1000\n",
      "6/6 - 0s - loss: 85.0554 - val_loss: 527.6091\n",
      "Epoch 115/1000\n",
      "6/6 - 0s - loss: 84.8099 - val_loss: 526.9582\n",
      "Epoch 116/1000\n",
      "6/6 - 0s - loss: 84.5623 - val_loss: 526.2830\n",
      "Epoch 117/1000\n",
      "6/6 - 0s - loss: 84.3400 - val_loss: 525.5670\n",
      "Epoch 118/1000\n",
      "6/6 - 0s - loss: 84.0747 - val_loss: 524.9383\n",
      "Epoch 119/1000\n",
      "6/6 - 0s - loss: 83.8609 - val_loss: 524.2519\n",
      "Epoch 120/1000\n",
      "6/6 - 0s - loss: 83.6298 - val_loss: 523.5801\n",
      "Epoch 121/1000\n",
      "6/6 - 0s - loss: 83.3834 - val_loss: 522.9730\n",
      "Epoch 122/1000\n",
      "6/6 - 0s - loss: 83.1809 - val_loss: 522.3250\n",
      "Epoch 123/1000\n",
      "6/6 - 0s - loss: 82.9550 - val_loss: 521.7030\n",
      "Epoch 124/1000\n",
      "6/6 - 0s - loss: 82.7436 - val_loss: 521.0553\n",
      "Epoch 125/1000\n",
      "6/6 - 0s - loss: 82.5219 - val_loss: 520.4711\n",
      "Epoch 126/1000\n",
      "6/6 - 0s - loss: 82.2836 - val_loss: 519.8129\n",
      "Epoch 127/1000\n",
      "6/6 - 0s - loss: 82.0957 - val_loss: 519.1251\n",
      "Epoch 128/1000\n",
      "6/6 - 0s - loss: 81.8641 - val_loss: 518.4133\n",
      "Epoch 129/1000\n",
      "6/6 - 0s - loss: 81.6020 - val_loss: 517.7339\n",
      "Epoch 130/1000\n",
      "6/6 - 0s - loss: 81.3901 - val_loss: 517.0173\n",
      "Epoch 131/1000\n",
      "6/6 - 0s - loss: 81.1243 - val_loss: 516.3828\n",
      "Epoch 132/1000\n",
      "6/6 - 0s - loss: 80.9031 - val_loss: 515.7119\n",
      "Epoch 133/1000\n",
      "6/6 - 0s - loss: 80.6879 - val_loss: 515.0696\n",
      "Epoch 134/1000\n",
      "6/6 - 0s - loss: 80.4668 - val_loss: 514.3943\n",
      "Epoch 135/1000\n",
      "6/6 - 0s - loss: 80.2317 - val_loss: 513.6778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/1000\n",
      "6/6 - 0s - loss: 79.9858 - val_loss: 513.0928\n",
      "Epoch 137/1000\n",
      "6/6 - 0s - loss: 79.7605 - val_loss: 512.4681\n",
      "Epoch 138/1000\n",
      "6/6 - 0s - loss: 79.5648 - val_loss: 511.8612\n",
      "Epoch 139/1000\n",
      "6/6 - 0s - loss: 79.3400 - val_loss: 511.3103\n",
      "Epoch 140/1000\n",
      "6/6 - 0s - loss: 79.1529 - val_loss: 510.6969\n",
      "Epoch 141/1000\n",
      "6/6 - 0s - loss: 78.9327 - val_loss: 510.1286\n",
      "Epoch 142/1000\n",
      "6/6 - 0s - loss: 78.7571 - val_loss: 509.5060\n",
      "Epoch 143/1000\n",
      "6/6 - 0s - loss: 78.5537 - val_loss: 508.8425\n",
      "Epoch 144/1000\n",
      "6/6 - 0s - loss: 78.3256 - val_loss: 508.2725\n",
      "Epoch 145/1000\n",
      "6/6 - 0s - loss: 78.1299 - val_loss: 507.6904\n",
      "Epoch 146/1000\n",
      "6/6 - 0s - loss: 77.9260 - val_loss: 507.0449\n",
      "Epoch 147/1000\n",
      "6/6 - 0s - loss: 77.7289 - val_loss: 506.4840\n",
      "Epoch 148/1000\n",
      "6/6 - 0s - loss: 77.5165 - val_loss: 505.7531\n",
      "Epoch 149/1000\n",
      "6/6 - 0s - loss: 77.3246 - val_loss: 505.2135\n",
      "Epoch 150/1000\n",
      "6/6 - 0s - loss: 77.0856 - val_loss: 504.4559\n",
      "Epoch 151/1000\n",
      "6/6 - 0s - loss: 76.8847 - val_loss: 503.9069\n",
      "Epoch 152/1000\n",
      "6/6 - 0s - loss: 76.6688 - val_loss: 503.1749\n",
      "Epoch 153/1000\n",
      "6/6 - 0s - loss: 76.4561 - val_loss: 502.5741\n",
      "Epoch 154/1000\n",
      "6/6 - 0s - loss: 76.2546 - val_loss: 501.9350\n",
      "Epoch 155/1000\n",
      "6/6 - 0s - loss: 76.0453 - val_loss: 501.2797\n",
      "Epoch 156/1000\n",
      "6/6 - 0s - loss: 75.8343 - val_loss: 500.7335\n",
      "Epoch 157/1000\n",
      "6/6 - 0s - loss: 75.6385 - val_loss: 500.1266\n",
      "Epoch 158/1000\n",
      "6/6 - 0s - loss: 75.4222 - val_loss: 499.5883\n",
      "Epoch 159/1000\n",
      "6/6 - 0s - loss: 75.2443 - val_loss: 498.8994\n",
      "Epoch 160/1000\n",
      "6/6 - 0s - loss: 75.0179 - val_loss: 498.3999\n",
      "Epoch 161/1000\n",
      "6/6 - 0s - loss: 74.8388 - val_loss: 497.7540\n",
      "Epoch 162/1000\n",
      "6/6 - 0s - loss: 74.6289 - val_loss: 497.2404\n",
      "Epoch 163/1000\n",
      "6/6 - 0s - loss: 74.4430 - val_loss: 496.6062\n",
      "Epoch 164/1000\n",
      "6/6 - 0s - loss: 74.2557 - val_loss: 496.0282\n",
      "Epoch 165/1000\n",
      "6/6 - 0s - loss: 74.0614 - val_loss: 495.4396\n",
      "Epoch 166/1000\n",
      "6/6 - 0s - loss: 73.8738 - val_loss: 494.8694\n",
      "Epoch 167/1000\n",
      "6/6 - 0s - loss: 73.6601 - val_loss: 494.4152\n",
      "Epoch 168/1000\n",
      "6/6 - 0s - loss: 73.5060 - val_loss: 493.6982\n",
      "Epoch 169/1000\n",
      "6/6 - 0s - loss: 73.2732 - val_loss: 493.2596\n",
      "Epoch 170/1000\n",
      "6/6 - 0s - loss: 73.1045 - val_loss: 492.5243\n",
      "Epoch 171/1000\n",
      "6/6 - 0s - loss: 72.8643 - val_loss: 492.0070\n",
      "Epoch 172/1000\n",
      "6/6 - 0s - loss: 72.6774 - val_loss: 491.3812\n",
      "Epoch 173/1000\n",
      "6/6 - 0s - loss: 72.4787 - val_loss: 490.7133\n",
      "Epoch 174/1000\n",
      "6/6 - 0s - loss: 72.2788 - val_loss: 490.1507\n",
      "Epoch 175/1000\n",
      "6/6 - 0s - loss: 72.0853 - val_loss: 489.5271\n",
      "Epoch 176/1000\n",
      "6/6 - 0s - loss: 71.8796 - val_loss: 489.0276\n",
      "Epoch 177/1000\n",
      "6/6 - 0s - loss: 71.6850 - val_loss: 488.3745\n",
      "Epoch 178/1000\n",
      "6/6 - 0s - loss: 71.5038 - val_loss: 487.9339\n",
      "Epoch 179/1000\n",
      "6/6 - 0s - loss: 71.2966 - val_loss: 487.2648\n",
      "Epoch 180/1000\n",
      "6/6 - 0s - loss: 71.0944 - val_loss: 486.8795\n",
      "Epoch 181/1000\n",
      "6/6 - 0s - loss: 70.9130 - val_loss: 486.1237\n",
      "Epoch 182/1000\n",
      "6/6 - 0s - loss: 70.7352 - val_loss: 485.6349\n",
      "Epoch 183/1000\n",
      "6/6 - 0s - loss: 70.5298 - val_loss: 484.9977\n",
      "Epoch 184/1000\n",
      "6/6 - 0s - loss: 70.3256 - val_loss: 484.4375\n",
      "Epoch 185/1000\n",
      "6/6 - 0s - loss: 70.1101 - val_loss: 483.8876\n",
      "Epoch 186/1000\n",
      "6/6 - 0s - loss: 69.9264 - val_loss: 483.2839\n",
      "Epoch 187/1000\n",
      "6/6 - 0s - loss: 69.7190 - val_loss: 482.6927\n",
      "Epoch 188/1000\n",
      "6/6 - 0s - loss: 69.5344 - val_loss: 482.1158\n",
      "Epoch 189/1000\n",
      "6/6 - 0s - loss: 69.3416 - val_loss: 481.3126\n",
      "Epoch 190/1000\n",
      "6/6 - 0s - loss: 69.1252 - val_loss: 480.9693\n",
      "Epoch 191/1000\n",
      "6/6 - 0s - loss: 68.9418 - val_loss: 480.1890\n",
      "Epoch 192/1000\n",
      "6/6 - 0s - loss: 68.7889 - val_loss: 480.0061\n",
      "Epoch 193/1000\n",
      "6/6 - 0s - loss: 68.6015 - val_loss: 478.9685\n",
      "Epoch 194/1000\n",
      "6/6 - 0s - loss: 68.4329 - val_loss: 479.0939\n",
      "Epoch 195/1000\n",
      "6/6 - 0s - loss: 68.2582 - val_loss: 477.7867\n",
      "Epoch 196/1000\n",
      "6/6 - 0s - loss: 68.1105 - val_loss: 478.1223\n",
      "Epoch 197/1000\n",
      "6/6 - 0s - loss: 67.9026 - val_loss: 476.4312\n",
      "Epoch 198/1000\n",
      "6/6 - 0s - loss: 67.7681 - val_loss: 477.3401\n",
      "Epoch 199/1000\n",
      "6/6 - 0s - loss: 67.5767 - val_loss: 475.1759\n",
      "Epoch 200/1000\n",
      "6/6 - 0s - loss: 67.3727 - val_loss: 476.1024\n",
      "Epoch 201/1000\n",
      "6/6 - 0s - loss: 67.2715 - val_loss: 474.0293\n",
      "Epoch 202/1000\n",
      "6/6 - 0s - loss: 67.0896 - val_loss: 474.5904\n",
      "Epoch 203/1000\n",
      "6/6 - 0s - loss: 66.8876 - val_loss: 473.3705\n",
      "Epoch 204/1000\n",
      "6/6 - 0s - loss: 66.7148 - val_loss: 473.0097\n",
      "Epoch 205/1000\n",
      "6/6 - 0s - loss: 66.5169 - val_loss: 472.7137\n",
      "Epoch 206/1000\n",
      "6/6 - 0s - loss: 66.3491 - val_loss: 471.4910\n",
      "Epoch 207/1000\n",
      "6/6 - 0s - loss: 66.1720 - val_loss: 471.9346\n",
      "Epoch 208/1000\n",
      "6/6 - 0s - loss: 66.0067 - val_loss: 470.5205\n",
      "Epoch 209/1000\n",
      "6/6 - 0s - loss: 65.8555 - val_loss: 470.6360\n",
      "Epoch 210/1000\n",
      "6/6 - 0s - loss: 65.6813 - val_loss: 469.5985\n",
      "Epoch 211/1000\n",
      "6/6 - 0s - loss: 65.4762 - val_loss: 469.1897\n",
      "Epoch 212/1000\n",
      "6/6 - 0s - loss: 65.3108 - val_loss: 468.6085\n",
      "Epoch 213/1000\n",
      "6/6 - 0s - loss: 65.1001 - val_loss: 467.7697\n",
      "Epoch 214/1000\n",
      "6/6 - 0s - loss: 64.9263 - val_loss: 467.5305\n",
      "Epoch 215/1000\n",
      "6/6 - 0s - loss: 64.7670 - val_loss: 466.5592\n",
      "Epoch 216/1000\n",
      "6/6 - 0s - loss: 64.5558 - val_loss: 466.3928\n",
      "Epoch 217/1000\n",
      "6/6 - 0s - loss: 64.4233 - val_loss: 465.4492\n",
      "Epoch 218/1000\n",
      "6/6 - 0s - loss: 64.2270 - val_loss: 465.1606\n",
      "Epoch 219/1000\n",
      "6/6 - 0s - loss: 64.0590 - val_loss: 464.2590\n",
      "Epoch 220/1000\n",
      "6/6 - 0s - loss: 63.9016 - val_loss: 463.7934\n",
      "Epoch 221/1000\n",
      "6/6 - 0s - loss: 63.7407 - val_loss: 463.2122\n",
      "Epoch 222/1000\n",
      "6/6 - 0s - loss: 63.5721 - val_loss: 462.6480\n",
      "Epoch 223/1000\n",
      "6/6 - 0s - loss: 63.4237 - val_loss: 462.3057\n",
      "Epoch 224/1000\n",
      "6/6 - 0s - loss: 63.2737 - val_loss: 461.6711\n",
      "Epoch 225/1000\n",
      "6/6 - 0s - loss: 63.1187 - val_loss: 461.4147\n",
      "Epoch 226/1000\n",
      "6/6 - 0s - loss: 62.9888 - val_loss: 460.7301\n",
      "Epoch 227/1000\n",
      "6/6 - 0s - loss: 62.8017 - val_loss: 460.3668\n",
      "Epoch 228/1000\n",
      "6/6 - 0s - loss: 62.6516 - val_loss: 459.7507\n",
      "Epoch 229/1000\n",
      "6/6 - 0s - loss: 62.4735 - val_loss: 459.3249\n",
      "Epoch 230/1000\n",
      "6/6 - 0s - loss: 62.3362 - val_loss: 458.7763\n",
      "Epoch 231/1000\n",
      "6/6 - 0s - loss: 62.1680 - val_loss: 458.2864\n",
      "Epoch 232/1000\n",
      "6/6 - 0s - loss: 62.0139 - val_loss: 457.8336\n",
      "Epoch 233/1000\n",
      "6/6 - 0s - loss: 61.8618 - val_loss: 457.2823\n",
      "Epoch 234/1000\n",
      "6/6 - 0s - loss: 61.7077 - val_loss: 456.8398\n",
      "Epoch 235/1000\n",
      "6/6 - 0s - loss: 61.5539 - val_loss: 456.3267\n",
      "Epoch 236/1000\n",
      "6/6 - 0s - loss: 61.4172 - val_loss: 455.8086\n",
      "Epoch 237/1000\n",
      "6/6 - 0s - loss: 61.2482 - val_loss: 455.4088\n",
      "Epoch 238/1000\n",
      "6/6 - 0s - loss: 61.0991 - val_loss: 454.8969\n",
      "Epoch 239/1000\n",
      "6/6 - 0s - loss: 60.9720 - val_loss: 454.4800\n",
      "Epoch 240/1000\n",
      "6/6 - 0s - loss: 60.8102 - val_loss: 454.0827\n",
      "Epoch 241/1000\n",
      "6/6 - 0s - loss: 60.6836 - val_loss: 453.6333\n",
      "Epoch 242/1000\n",
      "6/6 - 0s - loss: 60.5281 - val_loss: 453.2298\n",
      "Epoch 243/1000\n",
      "6/6 - 0s - loss: 60.3983 - val_loss: 452.8240\n",
      "Epoch 244/1000\n",
      "6/6 - 0s - loss: 60.2633 - val_loss: 452.3919\n",
      "Epoch 245/1000\n",
      "6/6 - 0s - loss: 60.1146 - val_loss: 451.8733\n",
      "Epoch 246/1000\n",
      "6/6 - 0s - loss: 59.9532 - val_loss: 451.5587\n",
      "Epoch 247/1000\n",
      "6/6 - 0s - loss: 59.8376 - val_loss: 451.0233\n",
      "Epoch 248/1000\n",
      "6/6 - 0s - loss: 59.6984 - val_loss: 450.6402\n",
      "Epoch 249/1000\n",
      "6/6 - 0s - loss: 59.5577 - val_loss: 450.1588\n",
      "Epoch 250/1000\n",
      "6/6 - 0s - loss: 59.4266 - val_loss: 449.7305\n",
      "Epoch 251/1000\n",
      "6/6 - 0s - loss: 59.2823 - val_loss: 449.3229\n",
      "Epoch 252/1000\n",
      "6/6 - 0s - loss: 59.1355 - val_loss: 448.8601\n",
      "Epoch 253/1000\n",
      "6/6 - 0s - loss: 59.0166 - val_loss: 448.3023\n",
      "Epoch 254/1000\n",
      "6/6 - 0s - loss: 58.8757 - val_loss: 447.9511\n",
      "Epoch 255/1000\n",
      "6/6 - 0s - loss: 58.7217 - val_loss: 447.3296\n",
      "Epoch 256/1000\n",
      "6/6 - 0s - loss: 58.5887 - val_loss: 447.0900\n",
      "Epoch 257/1000\n",
      "6/6 - 0s - loss: 58.4746 - val_loss: 446.3353\n",
      "Epoch 258/1000\n",
      "6/6 - 0s - loss: 58.3297 - val_loss: 446.1765\n",
      "Epoch 259/1000\n",
      "6/6 - 0s - loss: 58.2009 - val_loss: 445.2806\n",
      "Epoch 260/1000\n",
      "6/6 - 0s - loss: 58.0670 - val_loss: 445.6540\n",
      "Epoch 261/1000\n",
      "6/6 - 0s - loss: 57.9534 - val_loss: 444.2990\n",
      "Epoch 262/1000\n",
      "6/6 - 0s - loss: 57.8132 - val_loss: 445.0181\n",
      "Epoch 263/1000\n",
      "6/6 - 0s - loss: 57.6973 - val_loss: 443.3108\n",
      "Epoch 264/1000\n",
      "6/6 - 0s - loss: 57.5615 - val_loss: 444.2004\n",
      "Epoch 265/1000\n",
      "6/6 - 0s - loss: 57.4304 - val_loss: 442.3222\n",
      "Epoch 266/1000\n",
      "6/6 - 0s - loss: 57.3283 - val_loss: 443.8368\n",
      "Epoch 267/1000\n",
      "6/6 - 0s - loss: 57.2076 - val_loss: 441.0044\n",
      "Epoch 268/1000\n",
      "6/6 - 0s - loss: 57.0961 - val_loss: 443.1837\n",
      "Epoch 269/1000\n",
      "6/6 - 0s - loss: 56.9660 - val_loss: 439.7601\n",
      "Epoch 270/1000\n",
      "6/6 - 0s - loss: 56.8865 - val_loss: 442.2703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/1000\n",
      "6/6 - 0s - loss: 56.7468 - val_loss: 438.7780\n",
      "Epoch 272/1000\n",
      "6/6 - 0s - loss: 56.6242 - val_loss: 440.9905\n",
      "Epoch 273/1000\n",
      "6/6 - 0s - loss: 56.5248 - val_loss: 438.1588\n",
      "Epoch 274/1000\n",
      "6/6 - 0s - loss: 56.3894 - val_loss: 438.7394\n",
      "Epoch 275/1000\n",
      "6/6 - 0s - loss: 56.2046 - val_loss: 437.8973\n",
      "Epoch 276/1000\n",
      "6/6 - 0s - loss: 56.0494 - val_loss: 436.7285\n",
      "Epoch 277/1000\n",
      "6/6 - 0s - loss: 55.9025 - val_loss: 437.7071\n",
      "Epoch 278/1000\n",
      "6/6 - 0s - loss: 55.7754 - val_loss: 435.8796\n",
      "Epoch 279/1000\n",
      "6/6 - 0s - loss: 55.6681 - val_loss: 436.6356\n",
      "Epoch 280/1000\n",
      "6/6 - 0s - loss: 55.5182 - val_loss: 435.1729\n",
      "Epoch 281/1000\n",
      "6/6 - 0s - loss: 55.3810 - val_loss: 435.2539\n",
      "Epoch 282/1000\n",
      "6/6 - 0s - loss: 55.2534 - val_loss: 434.8189\n",
      "Epoch 283/1000\n",
      "6/6 - 0s - loss: 55.1211 - val_loss: 434.2525\n",
      "Epoch 284/1000\n",
      "6/6 - 0s - loss: 54.9978 - val_loss: 433.9869\n",
      "Epoch 285/1000\n",
      "6/6 - 0s - loss: 54.8890 - val_loss: 433.2684\n",
      "Epoch 286/1000\n",
      "6/6 - 0s - loss: 54.7502 - val_loss: 433.1003\n",
      "Epoch 287/1000\n",
      "6/6 - 0s - loss: 54.6335 - val_loss: 432.4132\n",
      "Epoch 288/1000\n",
      "6/6 - 0s - loss: 54.5228 - val_loss: 432.0889\n",
      "Epoch 289/1000\n",
      "6/6 - 0s - loss: 54.3930 - val_loss: 431.5496\n",
      "Epoch 290/1000\n",
      "6/6 - 0s - loss: 54.2576 - val_loss: 431.0284\n",
      "Epoch 291/1000\n",
      "6/6 - 0s - loss: 54.1461 - val_loss: 430.5959\n",
      "Epoch 292/1000\n",
      "6/6 - 0s - loss: 54.0154 - val_loss: 430.1501\n",
      "Epoch 293/1000\n",
      "6/6 - 0s - loss: 53.8923 - val_loss: 429.6948\n",
      "Epoch 294/1000\n",
      "6/6 - 0s - loss: 53.7959 - val_loss: 429.0673\n",
      "Epoch 295/1000\n",
      "6/6 - 0s - loss: 53.6538 - val_loss: 428.8997\n",
      "Epoch 296/1000\n",
      "6/6 - 0s - loss: 53.5339 - val_loss: 428.4785\n",
      "Epoch 297/1000\n",
      "6/6 - 0s - loss: 53.4143 - val_loss: 427.9422\n",
      "Epoch 298/1000\n",
      "6/6 - 0s - loss: 53.2831 - val_loss: 427.3448\n",
      "Epoch 299/1000\n",
      "6/6 - 0s - loss: 53.1402 - val_loss: 426.9970\n",
      "Epoch 300/1000\n",
      "6/6 - 0s - loss: 53.0217 - val_loss: 426.4792\n",
      "Epoch 301/1000\n",
      "6/6 - 0s - loss: 52.8952 - val_loss: 425.9872\n",
      "Epoch 302/1000\n",
      "6/6 - 0s - loss: 52.7455 - val_loss: 425.5839\n",
      "Epoch 303/1000\n",
      "6/6 - 0s - loss: 52.6423 - val_loss: 425.2248\n",
      "Epoch 304/1000\n",
      "6/6 - 0s - loss: 52.5187 - val_loss: 424.9412\n",
      "Epoch 305/1000\n",
      "6/6 - 0s - loss: 52.3933 - val_loss: 424.4326\n",
      "Epoch 306/1000\n",
      "6/6 - 0s - loss: 52.2728 - val_loss: 424.2138\n",
      "Epoch 307/1000\n",
      "6/6 - 0s - loss: 52.1551 - val_loss: 423.8105\n",
      "Epoch 308/1000\n",
      "6/6 - 0s - loss: 52.0350 - val_loss: 423.5802\n",
      "Epoch 309/1000\n",
      "6/6 - 0s - loss: 51.9154 - val_loss: 423.0827\n",
      "Epoch 310/1000\n",
      "6/6 - 0s - loss: 51.8197 - val_loss: 422.8434\n",
      "Epoch 311/1000\n",
      "6/6 - 0s - loss: 51.6896 - val_loss: 422.3351\n",
      "Epoch 312/1000\n",
      "6/6 - 0s - loss: 51.5657 - val_loss: 422.1749\n",
      "Epoch 313/1000\n",
      "6/6 - 0s - loss: 51.4404 - val_loss: 421.6813\n",
      "Epoch 314/1000\n",
      "6/6 - 0s - loss: 51.3486 - val_loss: 421.4360\n",
      "Epoch 315/1000\n",
      "6/6 - 0s - loss: 51.2114 - val_loss: 420.8184\n",
      "Epoch 316/1000\n",
      "6/6 - 0s - loss: 51.0902 - val_loss: 420.6167\n",
      "Epoch 317/1000\n",
      "6/6 - 0s - loss: 50.9716 - val_loss: 420.0923\n",
      "Epoch 318/1000\n",
      "6/6 - 0s - loss: 50.8733 - val_loss: 419.9263\n",
      "Epoch 319/1000\n",
      "6/6 - 0s - loss: 50.7502 - val_loss: 419.3181\n",
      "Epoch 320/1000\n",
      "6/6 - 0s - loss: 50.6393 - val_loss: 419.1504\n",
      "Epoch 321/1000\n",
      "6/6 - 0s - loss: 50.5124 - val_loss: 418.6335\n",
      "Epoch 322/1000\n",
      "6/6 - 0s - loss: 50.4051 - val_loss: 418.4886\n",
      "Epoch 323/1000\n",
      "6/6 - 0s - loss: 50.3153 - val_loss: 417.8112\n",
      "Epoch 324/1000\n",
      "6/6 - 0s - loss: 50.1982 - val_loss: 417.8216\n",
      "Epoch 325/1000\n",
      "6/6 - 0s - loss: 50.0925 - val_loss: 417.0070\n",
      "Epoch 326/1000\n",
      "6/6 - 0s - loss: 49.9795 - val_loss: 417.0415\n",
      "Epoch 327/1000\n",
      "6/6 - 0s - loss: 49.8612 - val_loss: 416.0815\n",
      "Epoch 328/1000\n",
      "6/6 - 0s - loss: 49.7371 - val_loss: 416.3922\n",
      "Epoch 329/1000\n",
      "6/6 - 0s - loss: 49.6244 - val_loss: 415.3747\n",
      "Epoch 330/1000\n",
      "6/6 - 0s - loss: 49.5467 - val_loss: 415.6121\n",
      "Epoch 331/1000\n",
      "6/6 - 0s - loss: 49.4247 - val_loss: 414.5044\n",
      "Epoch 332/1000\n",
      "6/6 - 0s - loss: 49.3231 - val_loss: 414.8802\n",
      "Epoch 333/1000\n",
      "6/6 - 0s - loss: 49.2037 - val_loss: 413.6898\n",
      "Epoch 334/1000\n",
      "6/6 - 0s - loss: 49.1130 - val_loss: 414.0909\n",
      "Epoch 335/1000\n",
      "6/6 - 0s - loss: 49.0120 - val_loss: 412.7822\n",
      "Epoch 336/1000\n",
      "6/6 - 0s - loss: 48.8820 - val_loss: 413.2723\n",
      "Epoch 337/1000\n",
      "6/6 - 0s - loss: 48.7804 - val_loss: 411.7630\n",
      "Epoch 338/1000\n",
      "6/6 - 0s - loss: 48.6760 - val_loss: 412.5556\n",
      "Epoch 339/1000\n",
      "6/6 - 0s - loss: 48.5724 - val_loss: 410.6950\n",
      "Epoch 340/1000\n",
      "6/6 - 0s - loss: 48.4577 - val_loss: 411.7223\n",
      "Epoch 341/1000\n",
      "6/6 - 0s - loss: 48.3547 - val_loss: 409.5158\n",
      "Epoch 342/1000\n",
      "6/6 - 0s - loss: 48.2531 - val_loss: 410.9817\n",
      "Epoch 343/1000\n",
      "6/6 - 0s - loss: 48.1444 - val_loss: 408.1703\n",
      "Epoch 344/1000\n",
      "6/6 - 0s - loss: 48.0507 - val_loss: 410.8703\n",
      "Epoch 345/1000\n",
      "6/6 - 0s - loss: 47.9798 - val_loss: 407.0137\n",
      "Epoch 346/1000\n",
      "6/6 - 0s - loss: 47.8833 - val_loss: 409.9749\n",
      "Epoch 347/1000\n",
      "6/6 - 0s - loss: 47.8203 - val_loss: 406.0723\n",
      "Epoch 348/1000\n",
      "6/6 - 0s - loss: 47.6866 - val_loss: 408.5794\n",
      "Epoch 349/1000\n",
      "6/6 - 0s - loss: 47.5937 - val_loss: 405.3962\n",
      "Epoch 350/1000\n",
      "6/6 - 0s - loss: 47.4692 - val_loss: 407.3340\n",
      "Epoch 351/1000\n",
      "6/6 - 0s - loss: 47.3570 - val_loss: 405.0599\n",
      "Epoch 352/1000\n",
      "6/6 - 0s - loss: 47.2066 - val_loss: 405.4125\n",
      "Epoch 353/1000\n",
      "6/6 - 0s - loss: 47.1005 - val_loss: 404.4825\n",
      "Epoch 354/1000\n",
      "6/6 - 0s - loss: 46.9740 - val_loss: 403.9797\n",
      "Epoch 355/1000\n",
      "6/6 - 0s - loss: 46.8506 - val_loss: 403.6920\n",
      "Epoch 356/1000\n",
      "6/6 - 0s - loss: 46.7275 - val_loss: 402.8305\n",
      "Epoch 357/1000\n",
      "6/6 - 0s - loss: 46.5992 - val_loss: 403.1607\n",
      "Epoch 358/1000\n",
      "6/6 - 0s - loss: 46.4923 - val_loss: 401.7785\n",
      "Epoch 359/1000\n",
      "6/6 - 0s - loss: 46.3552 - val_loss: 402.4053\n",
      "Epoch 360/1000\n",
      "6/6 - 0s - loss: 46.2532 - val_loss: 401.2763\n",
      "Epoch 361/1000\n",
      "6/6 - 0s - loss: 46.1464 - val_loss: 401.4829\n",
      "Epoch 362/1000\n",
      "6/6 - 0s - loss: 46.0279 - val_loss: 400.9100\n",
      "Epoch 363/1000\n",
      "6/6 - 0s - loss: 45.9285 - val_loss: 400.7039\n",
      "Epoch 364/1000\n",
      "6/6 - 0s - loss: 45.7955 - val_loss: 400.4375\n",
      "Epoch 365/1000\n",
      "6/6 - 0s - loss: 45.7004 - val_loss: 399.9182\n",
      "Epoch 366/1000\n",
      "6/6 - 0s - loss: 45.5911 - val_loss: 399.9127\n",
      "Epoch 367/1000\n",
      "6/6 - 0s - loss: 45.5024 - val_loss: 399.2710\n",
      "Epoch 368/1000\n",
      "6/6 - 0s - loss: 45.3952 - val_loss: 399.2933\n",
      "Epoch 369/1000\n",
      "6/6 - 0s - loss: 45.2840 - val_loss: 398.6308\n",
      "Epoch 370/1000\n",
      "6/6 - 0s - loss: 45.1787 - val_loss: 398.6355\n",
      "Epoch 371/1000\n",
      "6/6 - 0s - loss: 45.0804 - val_loss: 398.1069\n",
      "Epoch 372/1000\n",
      "6/6 - 0s - loss: 44.9824 - val_loss: 397.9090\n",
      "Epoch 373/1000\n",
      "6/6 - 0s - loss: 44.8829 - val_loss: 397.4008\n",
      "Epoch 374/1000\n",
      "6/6 - 0s - loss: 44.7551 - val_loss: 397.1847\n",
      "Epoch 375/1000\n",
      "6/6 - 0s - loss: 44.6590 - val_loss: 396.7251\n",
      "Epoch 376/1000\n",
      "6/6 - 0s - loss: 44.5404 - val_loss: 396.4538\n",
      "Epoch 377/1000\n",
      "6/6 - 0s - loss: 44.4382 - val_loss: 396.0396\n",
      "Epoch 378/1000\n",
      "6/6 - 0s - loss: 44.3368 - val_loss: 395.7435\n",
      "Epoch 379/1000\n",
      "6/6 - 0s - loss: 44.2116 - val_loss: 395.3803\n",
      "Epoch 380/1000\n",
      "6/6 - 0s - loss: 44.1166 - val_loss: 395.0575\n",
      "Epoch 381/1000\n",
      "6/6 - 0s - loss: 44.0248 - val_loss: 394.6171\n",
      "Epoch 382/1000\n",
      "6/6 - 0s - loss: 43.9087 - val_loss: 394.3656\n",
      "Epoch 383/1000\n",
      "6/6 - 0s - loss: 43.8013 - val_loss: 394.0016\n",
      "Epoch 384/1000\n",
      "6/6 - 0s - loss: 43.7131 - val_loss: 393.7452\n",
      "Epoch 385/1000\n",
      "6/6 - 0s - loss: 43.5978 - val_loss: 393.3858\n",
      "Epoch 386/1000\n",
      "6/6 - 0s - loss: 43.5380 - val_loss: 393.0966\n",
      "Epoch 387/1000\n",
      "6/6 - 0s - loss: 43.4053 - val_loss: 392.6958\n",
      "Epoch 388/1000\n",
      "6/6 - 0s - loss: 43.3210 - val_loss: 392.4148\n",
      "Epoch 389/1000\n",
      "6/6 - 0s - loss: 43.2164 - val_loss: 392.0289\n",
      "Epoch 390/1000\n",
      "6/6 - 0s - loss: 43.1270 - val_loss: 391.7229\n",
      "Epoch 391/1000\n",
      "6/6 - 0s - loss: 43.0235 - val_loss: 391.3934\n",
      "Epoch 392/1000\n",
      "6/6 - 0s - loss: 42.9300 - val_loss: 391.1073\n",
      "Epoch 393/1000\n",
      "6/6 - 0s - loss: 42.8426 - val_loss: 390.7885\n",
      "Epoch 394/1000\n",
      "6/6 - 0s - loss: 42.7443 - val_loss: 390.5114\n",
      "Epoch 395/1000\n",
      "6/6 - 0s - loss: 42.6471 - val_loss: 390.1568\n",
      "Epoch 396/1000\n",
      "6/6 - 0s - loss: 42.5729 - val_loss: 389.8124\n",
      "Epoch 397/1000\n",
      "6/6 - 0s - loss: 42.4578 - val_loss: 389.3458\n",
      "Epoch 398/1000\n",
      "6/6 - 0s - loss: 42.3516 - val_loss: 389.0974\n",
      "Epoch 399/1000\n",
      "6/6 - 0s - loss: 42.2531 - val_loss: 388.5847\n",
      "Epoch 400/1000\n",
      "6/6 - 0s - loss: 42.1731 - val_loss: 388.2639\n",
      "Epoch 401/1000\n",
      "6/6 - 0s - loss: 42.0567 - val_loss: 387.6856\n",
      "Epoch 402/1000\n",
      "6/6 - 0s - loss: 41.9523 - val_loss: 387.5792\n",
      "Epoch 403/1000\n",
      "6/6 - 0s - loss: 41.8518 - val_loss: 386.7766\n",
      "Epoch 404/1000\n",
      "6/6 - 0s - loss: 41.7544 - val_loss: 386.8941\n",
      "Epoch 405/1000\n",
      "6/6 - 0s - loss: 41.6481 - val_loss: 386.1535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406/1000\n",
      "6/6 - 0s - loss: 41.5588 - val_loss: 386.3053\n",
      "Epoch 407/1000\n",
      "6/6 - 0s - loss: 41.4550 - val_loss: 385.4722\n",
      "Epoch 408/1000\n",
      "6/6 - 0s - loss: 41.3572 - val_loss: 385.7866\n",
      "Epoch 409/1000\n",
      "6/6 - 0s - loss: 41.2736 - val_loss: 384.8119\n",
      "Epoch 410/1000\n",
      "6/6 - 0s - loss: 41.1602 - val_loss: 385.3242\n",
      "Epoch 411/1000\n",
      "6/6 - 0s - loss: 41.0772 - val_loss: 384.1505\n",
      "Epoch 412/1000\n",
      "6/6 - 0s - loss: 40.9893 - val_loss: 384.8899\n",
      "Epoch 413/1000\n",
      "6/6 - 0s - loss: 40.8909 - val_loss: 383.4669\n",
      "Epoch 414/1000\n",
      "6/6 - 0s - loss: 40.8153 - val_loss: 384.3792\n",
      "Epoch 415/1000\n",
      "6/6 - 0s - loss: 40.7189 - val_loss: 383.0101\n",
      "Epoch 416/1000\n",
      "6/6 - 0s - loss: 40.6377 - val_loss: 383.8502\n",
      "Epoch 417/1000\n",
      "6/6 - 0s - loss: 40.5312 - val_loss: 382.2603\n",
      "Epoch 418/1000\n",
      "6/6 - 0s - loss: 40.4611 - val_loss: 383.3919\n",
      "Epoch 419/1000\n",
      "6/6 - 0s - loss: 40.3574 - val_loss: 381.6710\n",
      "Epoch 420/1000\n",
      "6/6 - 0s - loss: 40.2894 - val_loss: 383.0230\n",
      "Epoch 421/1000\n",
      "6/6 - 0s - loss: 40.1763 - val_loss: 380.7325\n",
      "Epoch 422/1000\n",
      "6/6 - 0s - loss: 40.0923 - val_loss: 382.6978\n",
      "Epoch 423/1000\n",
      "6/6 - 0s - loss: 40.0129 - val_loss: 379.4109\n",
      "Epoch 424/1000\n",
      "6/6 - 0s - loss: 39.9204 - val_loss: 382.3428\n",
      "Epoch 425/1000\n",
      "6/6 - 0s - loss: 39.8290 - val_loss: 379.0512\n",
      "Epoch 426/1000\n",
      "6/6 - 0s - loss: 39.7530 - val_loss: 381.7598\n",
      "Epoch 427/1000\n",
      "6/6 - 0s - loss: 39.6484 - val_loss: 377.8397\n",
      "Epoch 428/1000\n",
      "6/6 - 0s - loss: 39.5750 - val_loss: 380.8452\n",
      "Epoch 429/1000\n",
      "6/6 - 0s - loss: 39.4358 - val_loss: 376.9772\n",
      "Epoch 430/1000\n",
      "6/6 - 0s - loss: 39.3902 - val_loss: 379.7129\n",
      "Epoch 431/1000\n",
      "6/6 - 0s - loss: 39.2644 - val_loss: 375.9938\n",
      "Epoch 432/1000\n",
      "6/6 - 0s - loss: 39.2013 - val_loss: 379.5719\n",
      "Epoch 433/1000\n",
      "6/6 - 0s - loss: 39.0958 - val_loss: 375.2133\n",
      "Epoch 434/1000\n",
      "6/6 - 0s - loss: 39.0142 - val_loss: 378.3944\n",
      "Epoch 435/1000\n",
      "6/6 - 0s - loss: 38.9130 - val_loss: 374.3806\n",
      "Epoch 436/1000\n",
      "6/6 - 0s - loss: 38.8139 - val_loss: 377.0314\n",
      "Epoch 437/1000\n",
      "6/6 - 0s - loss: 38.7309 - val_loss: 373.9529\n",
      "Epoch 438/1000\n",
      "6/6 - 0s - loss: 38.6374 - val_loss: 376.1879\n",
      "Epoch 439/1000\n",
      "6/6 - 0s - loss: 38.5379 - val_loss: 373.6986\n",
      "Epoch 440/1000\n",
      "6/6 - 0s - loss: 38.4314 - val_loss: 374.5214\n",
      "Epoch 441/1000\n",
      "6/6 - 0s - loss: 38.3417 - val_loss: 373.4395\n",
      "Epoch 442/1000\n",
      "6/6 - 0s - loss: 38.2426 - val_loss: 373.5021\n",
      "Epoch 443/1000\n",
      "6/6 - 0s - loss: 38.1408 - val_loss: 372.8666\n",
      "Epoch 444/1000\n",
      "6/6 - 0s - loss: 38.0604 - val_loss: 372.8240\n",
      "Epoch 445/1000\n",
      "6/6 - 0s - loss: 37.9853 - val_loss: 372.2064\n",
      "Epoch 446/1000\n",
      "6/6 - 0s - loss: 37.9083 - val_loss: 372.0535\n",
      "Epoch 447/1000\n",
      "6/6 - 0s - loss: 37.8095 - val_loss: 371.7746\n",
      "Epoch 448/1000\n",
      "6/6 - 0s - loss: 37.7349 - val_loss: 371.2293\n",
      "Epoch 449/1000\n",
      "6/6 - 0s - loss: 37.6486 - val_loss: 371.2575\n",
      "Epoch 450/1000\n",
      "6/6 - 0s - loss: 37.5532 - val_loss: 370.6722\n",
      "Epoch 451/1000\n",
      "6/6 - 0s - loss: 37.4663 - val_loss: 370.6636\n",
      "Epoch 452/1000\n",
      "6/6 - 0s - loss: 37.3845 - val_loss: 370.0657\n",
      "Epoch 453/1000\n",
      "6/6 - 0s - loss: 37.3079 - val_loss: 370.1431\n",
      "Epoch 454/1000\n",
      "6/6 - 0s - loss: 37.2186 - val_loss: 369.5813\n",
      "Epoch 455/1000\n",
      "6/6 - 0s - loss: 37.1504 - val_loss: 369.5990\n",
      "Epoch 456/1000\n",
      "6/6 - 0s - loss: 37.0511 - val_loss: 369.0772\n",
      "Epoch 457/1000\n",
      "6/6 - 0s - loss: 36.9745 - val_loss: 369.1505\n",
      "Epoch 458/1000\n",
      "6/6 - 0s - loss: 36.8966 - val_loss: 368.6392\n",
      "Epoch 459/1000\n",
      "6/6 - 0s - loss: 36.8165 - val_loss: 368.5721\n",
      "Epoch 460/1000\n",
      "6/6 - 0s - loss: 36.7368 - val_loss: 368.0794\n",
      "Epoch 461/1000\n",
      "6/6 - 0s - loss: 36.6470 - val_loss: 368.0295\n",
      "Epoch 462/1000\n",
      "6/6 - 0s - loss: 36.5556 - val_loss: 367.6234\n",
      "Epoch 463/1000\n",
      "6/6 - 0s - loss: 36.4855 - val_loss: 367.4980\n",
      "Epoch 464/1000\n",
      "6/6 - 0s - loss: 36.4147 - val_loss: 367.0620\n",
      "Epoch 465/1000\n",
      "6/6 - 0s - loss: 36.3105 - val_loss: 366.9432\n",
      "Epoch 466/1000\n",
      "6/6 - 0s - loss: 36.2396 - val_loss: 366.5893\n",
      "Epoch 467/1000\n",
      "6/6 - 0s - loss: 36.1653 - val_loss: 366.4559\n",
      "Epoch 468/1000\n",
      "6/6 - 0s - loss: 36.0743 - val_loss: 366.0780\n",
      "Epoch 469/1000\n",
      "6/6 - 0s - loss: 36.0005 - val_loss: 365.9275\n",
      "Epoch 470/1000\n",
      "6/6 - 0s - loss: 35.9314 - val_loss: 365.5899\n",
      "Epoch 471/1000\n",
      "6/6 - 0s - loss: 35.8458 - val_loss: 365.3637\n",
      "Epoch 472/1000\n",
      "6/6 - 0s - loss: 35.7587 - val_loss: 365.1048\n",
      "Epoch 473/1000\n",
      "6/6 - 0s - loss: 35.6831 - val_loss: 364.8563\n",
      "Epoch 474/1000\n",
      "6/6 - 0s - loss: 35.5949 - val_loss: 364.5622\n",
      "Epoch 475/1000\n",
      "6/6 - 0s - loss: 35.5235 - val_loss: 364.3386\n",
      "Epoch 476/1000\n",
      "6/6 - 0s - loss: 35.4430 - val_loss: 364.0495\n",
      "Epoch 477/1000\n",
      "6/6 - 0s - loss: 35.3747 - val_loss: 363.7579\n",
      "Epoch 478/1000\n",
      "6/6 - 0s - loss: 35.2895 - val_loss: 363.4982\n",
      "Epoch 479/1000\n",
      "6/6 - 0s - loss: 35.2088 - val_loss: 363.2458\n",
      "Epoch 480/1000\n",
      "6/6 - 0s - loss: 35.1444 - val_loss: 362.9516\n",
      "Epoch 481/1000\n",
      "6/6 - 0s - loss: 35.0607 - val_loss: 362.6635\n",
      "Epoch 482/1000\n",
      "6/6 - 0s - loss: 34.9614 - val_loss: 362.4265\n",
      "Epoch 483/1000\n",
      "6/6 - 0s - loss: 34.8883 - val_loss: 362.1486\n",
      "Epoch 484/1000\n",
      "6/6 - 0s - loss: 34.8133 - val_loss: 361.7691\n",
      "Epoch 485/1000\n",
      "6/6 - 0s - loss: 34.7371 - val_loss: 361.4485\n",
      "Epoch 486/1000\n",
      "6/6 - 0s - loss: 34.6332 - val_loss: 361.0877\n",
      "Epoch 487/1000\n",
      "6/6 - 0s - loss: 34.5542 - val_loss: 360.8318\n",
      "Epoch 488/1000\n",
      "6/6 - 0s - loss: 34.4737 - val_loss: 360.4258\n",
      "Epoch 489/1000\n",
      "6/6 - 0s - loss: 34.3919 - val_loss: 360.1115\n",
      "Epoch 490/1000\n",
      "6/6 - 0s - loss: 34.3182 - val_loss: 359.7213\n",
      "Epoch 491/1000\n",
      "6/6 - 0s - loss: 34.2187 - val_loss: 359.3797\n",
      "Epoch 492/1000\n",
      "6/6 - 0s - loss: 34.1380 - val_loss: 358.9320\n",
      "Epoch 493/1000\n",
      "6/6 - 0s - loss: 34.0436 - val_loss: 358.9441\n",
      "Epoch 494/1000\n",
      "6/6 - 0s - loss: 33.9661 - val_loss: 358.4983\n",
      "Epoch 495/1000\n",
      "6/6 - 0s - loss: 33.9041 - val_loss: 358.4127\n",
      "Epoch 496/1000\n",
      "6/6 - 0s - loss: 33.8183 - val_loss: 357.7558\n",
      "Epoch 497/1000\n",
      "6/6 - 0s - loss: 33.7259 - val_loss: 358.1649\n",
      "Epoch 498/1000\n",
      "6/6 - 0s - loss: 33.6507 - val_loss: 357.1473\n",
      "Epoch 499/1000\n",
      "6/6 - 0s - loss: 33.5672 - val_loss: 357.8240\n",
      "Epoch 500/1000\n",
      "6/6 - 0s - loss: 33.4971 - val_loss: 356.6768\n",
      "Epoch 501/1000\n",
      "6/6 - 0s - loss: 33.4081 - val_loss: 357.3347\n",
      "Epoch 502/1000\n",
      "6/6 - 0s - loss: 33.3347 - val_loss: 356.0941\n",
      "Epoch 503/1000\n",
      "6/6 - 0s - loss: 33.2714 - val_loss: 357.0394\n",
      "Epoch 504/1000\n",
      "6/6 - 0s - loss: 33.1842 - val_loss: 355.2235\n",
      "Epoch 505/1000\n",
      "6/6 - 0s - loss: 33.1170 - val_loss: 357.0328\n",
      "Epoch 506/1000\n",
      "6/6 - 0s - loss: 33.0274 - val_loss: 354.5065\n",
      "Epoch 507/1000\n",
      "6/6 - 0s - loss: 32.9583 - val_loss: 356.2537\n",
      "Epoch 508/1000\n",
      "6/6 - 0s - loss: 32.8957 - val_loss: 354.0671\n",
      "Epoch 509/1000\n",
      "6/6 - 0s - loss: 32.8350 - val_loss: 355.8755\n",
      "Epoch 510/1000\n",
      "6/6 - 0s - loss: 32.7376 - val_loss: 353.3064\n",
      "Epoch 511/1000\n",
      "6/6 - 0s - loss: 32.6796 - val_loss: 355.3557\n",
      "Epoch 512/1000\n",
      "6/6 - 0s - loss: 32.5735 - val_loss: 352.7538\n",
      "Epoch 513/1000\n",
      "6/6 - 0s - loss: 32.4988 - val_loss: 355.2382\n",
      "Epoch 514/1000\n",
      "6/6 - 0s - loss: 32.4474 - val_loss: 352.0175\n",
      "Epoch 515/1000\n",
      "6/6 - 0s - loss: 32.3878 - val_loss: 354.7991\n",
      "Epoch 516/1000\n",
      "6/6 - 0s - loss: 32.3204 - val_loss: 350.9969\n",
      "Epoch 517/1000\n",
      "6/6 - 0s - loss: 32.2594 - val_loss: 354.5515\n",
      "Epoch 518/1000\n",
      "6/6 - 0s - loss: 32.1834 - val_loss: 350.4861\n",
      "Epoch 519/1000\n",
      "6/6 - 0s - loss: 32.1314 - val_loss: 354.0078\n",
      "Epoch 520/1000\n",
      "6/6 - 0s - loss: 32.0628 - val_loss: 349.6405\n",
      "Epoch 521/1000\n",
      "6/6 - 0s - loss: 31.9467 - val_loss: 352.7210\n",
      "Epoch 522/1000\n",
      "6/6 - 0s - loss: 31.8679 - val_loss: 349.4437\n",
      "Epoch 523/1000\n",
      "6/6 - 0s - loss: 31.7863 - val_loss: 351.6605\n",
      "Epoch 524/1000\n",
      "6/6 - 0s - loss: 31.6964 - val_loss: 348.7246\n",
      "Epoch 525/1000\n",
      "6/6 - 0s - loss: 31.6194 - val_loss: 351.1675\n",
      "Epoch 526/1000\n",
      "6/6 - 0s - loss: 31.5383 - val_loss: 348.2080\n",
      "Epoch 527/1000\n",
      "6/6 - 0s - loss: 31.4524 - val_loss: 350.4704\n",
      "Epoch 528/1000\n",
      "6/6 - 0s - loss: 31.3659 - val_loss: 347.8265\n",
      "Epoch 529/1000\n",
      "6/6 - 0s - loss: 31.2980 - val_loss: 349.2191\n",
      "Epoch 530/1000\n",
      "6/6 - 0s - loss: 31.2215 - val_loss: 347.3719\n",
      "Epoch 531/1000\n",
      "6/6 - 0s - loss: 31.1390 - val_loss: 348.6665\n",
      "Epoch 532/1000\n",
      "6/6 - 0s - loss: 31.0565 - val_loss: 347.0795\n",
      "Epoch 533/1000\n",
      "6/6 - 0s - loss: 30.9936 - val_loss: 347.8044\n",
      "Epoch 534/1000\n",
      "6/6 - 0s - loss: 30.9182 - val_loss: 346.8548\n",
      "Epoch 535/1000\n",
      "6/6 - 0s - loss: 30.8295 - val_loss: 347.0009\n",
      "Epoch 536/1000\n",
      "6/6 - 0s - loss: 30.7604 - val_loss: 346.5061\n",
      "Epoch 537/1000\n",
      "6/6 - 0s - loss: 30.7012 - val_loss: 346.4826\n",
      "Epoch 538/1000\n",
      "6/6 - 0s - loss: 30.6107 - val_loss: 346.1364\n",
      "Epoch 539/1000\n",
      "6/6 - 0s - loss: 30.5387 - val_loss: 345.9588\n",
      "Epoch 540/1000\n",
      "6/6 - 0s - loss: 30.4684 - val_loss: 345.7619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/1000\n",
      "6/6 - 0s - loss: 30.3831 - val_loss: 345.3028\n",
      "Epoch 542/1000\n",
      "6/6 - 0s - loss: 30.3093 - val_loss: 345.4157\n",
      "Epoch 543/1000\n",
      "6/6 - 0s - loss: 30.2555 - val_loss: 344.7590\n",
      "Epoch 544/1000\n",
      "6/6 - 0s - loss: 30.1452 - val_loss: 344.7958\n",
      "Epoch 545/1000\n",
      "6/6 - 0s - loss: 30.0975 - val_loss: 344.2704\n",
      "Epoch 546/1000\n",
      "6/6 - 0s - loss: 29.9948 - val_loss: 344.3295\n",
      "Epoch 547/1000\n",
      "6/6 - 0s - loss: 29.9429 - val_loss: 343.7422\n",
      "Epoch 548/1000\n",
      "6/6 - 0s - loss: 29.8552 - val_loss: 343.9719\n",
      "Epoch 549/1000\n",
      "6/6 - 0s - loss: 29.7894 - val_loss: 343.3222\n",
      "Epoch 550/1000\n",
      "6/6 - 0s - loss: 29.7268 - val_loss: 343.5738\n",
      "Epoch 551/1000\n",
      "6/6 - 0s - loss: 29.6599 - val_loss: 342.9162\n",
      "Epoch 552/1000\n",
      "6/6 - 0s - loss: 29.5870 - val_loss: 343.1726\n",
      "Epoch 553/1000\n",
      "6/6 - 0s - loss: 29.5304 - val_loss: 342.4165\n",
      "Epoch 554/1000\n",
      "6/6 - 0s - loss: 29.4602 - val_loss: 342.6639\n",
      "Epoch 555/1000\n",
      "6/6 - 0s - loss: 29.3898 - val_loss: 342.0067\n",
      "Epoch 556/1000\n",
      "6/6 - 0s - loss: 29.3222 - val_loss: 342.3996\n",
      "Epoch 557/1000\n",
      "6/6 - 0s - loss: 29.2708 - val_loss: 341.5625\n",
      "Epoch 558/1000\n",
      "6/6 - 0s - loss: 29.1970 - val_loss: 341.9777\n",
      "Epoch 559/1000\n",
      "6/6 - 0s - loss: 29.1351 - val_loss: 341.1220\n",
      "Epoch 560/1000\n",
      "6/6 - 0s - loss: 29.0723 - val_loss: 341.6131\n",
      "Epoch 561/1000\n",
      "6/6 - 0s - loss: 29.0104 - val_loss: 340.6748\n",
      "Epoch 562/1000\n",
      "6/6 - 0s - loss: 28.9425 - val_loss: 341.2133\n",
      "Epoch 563/1000\n",
      "6/6 - 0s - loss: 28.8772 - val_loss: 340.1449\n",
      "Epoch 564/1000\n",
      "6/6 - 0s - loss: 28.8016 - val_loss: 340.7240\n",
      "Epoch 565/1000\n",
      "6/6 - 0s - loss: 28.7440 - val_loss: 339.9778\n",
      "Epoch 566/1000\n",
      "6/6 - 0s - loss: 28.6769 - val_loss: 339.9594\n",
      "Epoch 567/1000\n",
      "6/6 - 0s - loss: 28.5836 - val_loss: 339.6534\n",
      "Epoch 568/1000\n",
      "6/6 - 0s - loss: 28.5324 - val_loss: 339.3958\n",
      "Epoch 569/1000\n",
      "6/6 - 0s - loss: 28.4551 - val_loss: 339.3123\n",
      "Epoch 570/1000\n",
      "6/6 - 0s - loss: 28.3791 - val_loss: 338.7906\n",
      "Epoch 571/1000\n",
      "6/6 - 0s - loss: 28.3270 - val_loss: 339.0837\n",
      "Epoch 572/1000\n",
      "6/6 - 0s - loss: 28.2431 - val_loss: 338.1623\n",
      "Epoch 573/1000\n",
      "6/6 - 0s - loss: 28.1968 - val_loss: 338.8515\n",
      "Epoch 574/1000\n",
      "6/6 - 0s - loss: 28.1119 - val_loss: 337.6246\n",
      "Epoch 575/1000\n",
      "6/6 - 0s - loss: 28.0579 - val_loss: 338.2922\n",
      "Epoch 576/1000\n",
      "6/6 - 0s - loss: 27.9904 - val_loss: 337.4930\n",
      "Epoch 577/1000\n",
      "6/6 - 0s - loss: 27.9274 - val_loss: 337.7114\n",
      "Epoch 578/1000\n",
      "6/6 - 0s - loss: 27.8583 - val_loss: 337.4291\n",
      "Epoch 579/1000\n",
      "6/6 - 0s - loss: 27.8099 - val_loss: 336.8071\n",
      "Epoch 580/1000\n",
      "6/6 - 0s - loss: 27.7500 - val_loss: 337.3794\n",
      "Epoch 581/1000\n",
      "6/6 - 0s - loss: 27.6744 - val_loss: 336.2100\n",
      "Epoch 582/1000\n",
      "6/6 - 0s - loss: 27.6283 - val_loss: 337.0656\n",
      "Epoch 583/1000\n",
      "6/6 - 0s - loss: 27.5509 - val_loss: 335.6231\n",
      "Epoch 584/1000\n",
      "6/6 - 0s - loss: 27.4880 - val_loss: 336.6508\n",
      "Epoch 585/1000\n",
      "6/6 - 0s - loss: 27.4325 - val_loss: 335.5344\n",
      "Epoch 586/1000\n",
      "6/6 - 0s - loss: 27.3651 - val_loss: 335.8094\n",
      "Epoch 587/1000\n",
      "6/6 - 0s - loss: 27.3088 - val_loss: 335.4776\n",
      "Epoch 588/1000\n",
      "6/6 - 0s - loss: 27.2299 - val_loss: 335.3341\n",
      "Epoch 589/1000\n",
      "6/6 - 0s - loss: 27.1747 - val_loss: 334.9602\n",
      "Epoch 590/1000\n",
      "6/6 - 0s - loss: 27.1055 - val_loss: 334.5515\n",
      "Epoch 591/1000\n",
      "6/6 - 0s - loss: 27.0269 - val_loss: 334.7717\n",
      "Epoch 592/1000\n",
      "6/6 - 0s - loss: 26.9721 - val_loss: 333.9032\n",
      "Epoch 593/1000\n",
      "6/6 - 0s - loss: 26.8992 - val_loss: 334.5148\n",
      "Epoch 594/1000\n",
      "6/6 - 0s - loss: 26.8198 - val_loss: 333.4078\n",
      "Epoch 595/1000\n",
      "6/6 - 0s - loss: 26.7619 - val_loss: 333.9282\n",
      "Epoch 596/1000\n",
      "6/6 - 0s - loss: 26.6989 - val_loss: 333.2660\n",
      "Epoch 597/1000\n",
      "6/6 - 0s - loss: 26.6365 - val_loss: 333.0746\n",
      "Epoch 598/1000\n",
      "6/6 - 0s - loss: 26.5709 - val_loss: 333.3596\n",
      "Epoch 599/1000\n",
      "6/6 - 0s - loss: 26.4986 - val_loss: 332.3472\n",
      "Epoch 600/1000\n",
      "6/6 - 0s - loss: 26.4426 - val_loss: 333.0198\n",
      "Epoch 601/1000\n",
      "6/6 - 0s - loss: 26.3862 - val_loss: 331.7551\n",
      "Epoch 602/1000\n",
      "6/6 - 0s - loss: 26.3234 - val_loss: 332.7856\n",
      "Epoch 603/1000\n",
      "6/6 - 0s - loss: 26.2641 - val_loss: 331.4669\n",
      "Epoch 604/1000\n",
      "6/6 - 0s - loss: 26.2026 - val_loss: 332.0164\n",
      "Epoch 605/1000\n",
      "6/6 - 0s - loss: 26.1356 - val_loss: 331.3671\n",
      "Epoch 606/1000\n",
      "6/6 - 0s - loss: 26.0713 - val_loss: 331.0864\n",
      "Epoch 607/1000\n",
      "6/6 - 0s - loss: 26.0112 - val_loss: 331.2742\n",
      "Epoch 608/1000\n",
      "6/6 - 0s - loss: 25.9431 - val_loss: 330.4868\n",
      "Epoch 609/1000\n",
      "6/6 - 0s - loss: 25.9006 - val_loss: 331.0282\n",
      "Epoch 610/1000\n",
      "6/6 - 0s - loss: 25.8355 - val_loss: 330.1472\n",
      "Epoch 611/1000\n",
      "6/6 - 0s - loss: 25.7745 - val_loss: 330.6457\n",
      "Epoch 612/1000\n",
      "6/6 - 0s - loss: 25.7149 - val_loss: 329.6482\n",
      "Epoch 613/1000\n",
      "6/6 - 0s - loss: 25.6707 - val_loss: 330.3309\n",
      "Epoch 614/1000\n",
      "6/6 - 0s - loss: 25.6116 - val_loss: 329.6463\n",
      "Epoch 615/1000\n",
      "6/6 - 0s - loss: 25.5522 - val_loss: 329.2717\n",
      "Epoch 616/1000\n",
      "6/6 - 0s - loss: 25.4988 - val_loss: 330.0135\n",
      "Epoch 617/1000\n",
      "6/6 - 0s - loss: 25.4396 - val_loss: 328.3604\n",
      "Epoch 618/1000\n",
      "6/6 - 0s - loss: 25.3690 - val_loss: 329.7696\n",
      "Epoch 619/1000\n",
      "6/6 - 0s - loss: 25.3103 - val_loss: 327.7563\n",
      "Epoch 620/1000\n",
      "6/6 - 0s - loss: 25.2449 - val_loss: 329.1670\n",
      "Epoch 621/1000\n",
      "6/6 - 0s - loss: 25.1926 - val_loss: 327.8627\n",
      "Epoch 622/1000\n",
      "6/6 - 0s - loss: 25.1294 - val_loss: 327.9713\n",
      "Epoch 00622: early stopping\n",
      "Score (MSE): 327.9713338526489\n",
      "Score(RMSE): 18.109978847382703\n",
      "\n",
      "Run  2\n",
      "Activation: Tanh\n",
      "Optimizer: Adam\n",
      "\n",
      "Epoch 1/1000\n",
      "6/6 - 0s - loss: 159.5926 - val_loss: 684.2979\n",
      "Epoch 2/1000\n",
      "6/6 - 0s - loss: 149.4746 - val_loss: 662.1513\n",
      "Epoch 3/1000\n",
      "6/6 - 0s - loss: 139.8510 - val_loss: 646.5110\n",
      "Epoch 4/1000\n",
      "6/6 - 0s - loss: 134.0117 - val_loss: 636.8410\n",
      "Epoch 5/1000\n",
      "6/6 - 0s - loss: 129.7526 - val_loss: 629.0247\n",
      "Epoch 6/1000\n",
      "6/6 - 0s - loss: 127.1444 - val_loss: 624.4599\n",
      "Epoch 7/1000\n",
      "6/6 - 0s - loss: 125.5532 - val_loss: 622.0006\n",
      "Epoch 8/1000\n",
      "6/6 - 0s - loss: 124.4504 - val_loss: 620.1940\n",
      "Epoch 9/1000\n",
      "6/6 - 0s - loss: 123.4831 - val_loss: 618.6445\n",
      "Epoch 10/1000\n",
      "6/6 - 0s - loss: 122.6975 - val_loss: 617.1729\n",
      "Epoch 11/1000\n",
      "6/6 - 0s - loss: 121.9868 - val_loss: 615.7751\n",
      "Epoch 12/1000\n",
      "6/6 - 0s - loss: 121.2940 - val_loss: 614.4272\n",
      "Epoch 13/1000\n",
      "6/6 - 0s - loss: 120.6331 - val_loss: 613.0801\n",
      "Epoch 14/1000\n",
      "6/6 - 0s - loss: 120.0088 - val_loss: 611.7475\n",
      "Epoch 15/1000\n",
      "6/6 - 0s - loss: 119.3554 - val_loss: 610.4820\n",
      "Epoch 16/1000\n",
      "6/6 - 0s - loss: 118.7161 - val_loss: 609.2833\n",
      "Epoch 17/1000\n",
      "6/6 - 0s - loss: 118.0993 - val_loss: 608.0455\n",
      "Epoch 18/1000\n",
      "6/6 - 0s - loss: 117.5304 - val_loss: 606.7739\n",
      "Epoch 19/1000\n",
      "6/6 - 0s - loss: 116.9575 - val_loss: 605.5189\n",
      "Epoch 20/1000\n",
      "6/6 - 0s - loss: 116.2757 - val_loss: 604.4308\n",
      "Epoch 21/1000\n",
      "6/6 - 0s - loss: 115.7676 - val_loss: 603.2380\n",
      "Epoch 22/1000\n",
      "6/6 - 0s - loss: 115.2307 - val_loss: 602.0707\n",
      "Epoch 23/1000\n",
      "6/6 - 0s - loss: 114.6485 - val_loss: 600.9561\n",
      "Epoch 24/1000\n",
      "6/6 - 0s - loss: 114.1007 - val_loss: 599.8557\n",
      "Epoch 25/1000\n",
      "6/6 - 0s - loss: 113.6008 - val_loss: 598.7512\n",
      "Epoch 26/1000\n",
      "6/6 - 0s - loss: 113.0449 - val_loss: 597.6896\n",
      "Epoch 27/1000\n",
      "6/6 - 0s - loss: 112.5408 - val_loss: 596.5784\n",
      "Epoch 28/1000\n",
      "6/6 - 0s - loss: 112.0216 - val_loss: 595.4810\n",
      "Epoch 29/1000\n",
      "6/6 - 0s - loss: 111.5325 - val_loss: 594.4137\n",
      "Epoch 30/1000\n",
      "6/6 - 0s - loss: 111.0865 - val_loss: 593.2727\n",
      "Epoch 31/1000\n",
      "6/6 - 0s - loss: 110.5772 - val_loss: 592.1952\n",
      "Epoch 32/1000\n",
      "6/6 - 0s - loss: 110.0965 - val_loss: 591.1841\n",
      "Epoch 33/1000\n",
      "6/6 - 0s - loss: 109.6375 - val_loss: 590.1961\n",
      "Epoch 34/1000\n",
      "6/6 - 0s - loss: 109.2078 - val_loss: 589.1807\n",
      "Epoch 35/1000\n",
      "6/6 - 0s - loss: 108.7359 - val_loss: 588.2175\n",
      "Epoch 36/1000\n",
      "6/6 - 0s - loss: 108.2803 - val_loss: 587.2416\n",
      "Epoch 37/1000\n",
      "6/6 - 0s - loss: 107.8791 - val_loss: 586.1403\n",
      "Epoch 38/1000\n",
      "6/6 - 0s - loss: 107.4073 - val_loss: 585.0699\n",
      "Epoch 39/1000\n",
      "6/6 - 0s - loss: 106.9219 - val_loss: 584.0652\n",
      "Epoch 40/1000\n",
      "6/6 - 0s - loss: 106.5341 - val_loss: 583.0026\n",
      "Epoch 41/1000\n",
      "6/6 - 0s - loss: 106.0978 - val_loss: 581.9895\n",
      "Epoch 42/1000\n",
      "6/6 - 0s - loss: 105.6520 - val_loss: 581.0694\n",
      "Epoch 43/1000\n",
      "6/6 - 0s - loss: 105.2975 - val_loss: 580.1060\n",
      "Epoch 44/1000\n",
      "6/6 - 0s - loss: 104.8939 - val_loss: 579.1402\n",
      "Epoch 45/1000\n",
      "6/6 - 0s - loss: 104.4890 - val_loss: 578.2276\n",
      "Epoch 46/1000\n",
      "6/6 - 0s - loss: 104.0853 - val_loss: 577.3663\n",
      "Epoch 47/1000\n",
      "6/6 - 0s - loss: 103.7755 - val_loss: 576.4601\n",
      "Epoch 48/1000\n",
      "6/6 - 0s - loss: 103.3787 - val_loss: 575.6029\n",
      "Epoch 49/1000\n",
      "6/6 - 0s - loss: 103.0345 - val_loss: 574.6992\n",
      "Epoch 50/1000\n",
      "6/6 - 0s - loss: 102.6884 - val_loss: 573.7725\n",
      "Epoch 51/1000\n",
      "6/6 - 0s - loss: 102.3051 - val_loss: 572.8970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/1000\n",
      "6/6 - 0s - loss: 101.9182 - val_loss: 572.0808\n",
      "Epoch 53/1000\n",
      "6/6 - 0s - loss: 101.5977 - val_loss: 571.1890\n",
      "Epoch 54/1000\n",
      "6/6 - 0s - loss: 101.2342 - val_loss: 570.3337\n",
      "Epoch 55/1000\n",
      "6/6 - 0s - loss: 100.8892 - val_loss: 569.4885\n",
      "Epoch 56/1000\n",
      "6/6 - 0s - loss: 100.5454 - val_loss: 568.6589\n",
      "Epoch 57/1000\n",
      "6/6 - 0s - loss: 100.2380 - val_loss: 567.7556\n",
      "Epoch 58/1000\n",
      "6/6 - 0s - loss: 99.8642 - val_loss: 566.8963\n",
      "Epoch 59/1000\n",
      "6/6 - 0s - loss: 99.5110 - val_loss: 566.0650\n",
      "Epoch 60/1000\n",
      "6/6 - 0s - loss: 99.1911 - val_loss: 565.2195\n",
      "Epoch 61/1000\n",
      "6/6 - 0s - loss: 98.8606 - val_loss: 564.3806\n",
      "Epoch 62/1000\n",
      "6/6 - 0s - loss: 98.5606 - val_loss: 563.4731\n",
      "Epoch 63/1000\n",
      "6/6 - 0s - loss: 98.1910 - val_loss: 562.6424\n",
      "Epoch 64/1000\n",
      "6/6 - 0s - loss: 97.8708 - val_loss: 561.8223\n",
      "Epoch 65/1000\n",
      "6/6 - 0s - loss: 97.5161 - val_loss: 560.9957\n",
      "Epoch 66/1000\n",
      "6/6 - 0s - loss: 97.2433 - val_loss: 560.1121\n",
      "Epoch 67/1000\n",
      "6/6 - 0s - loss: 96.8842 - val_loss: 559.2703\n",
      "Epoch 68/1000\n",
      "6/6 - 0s - loss: 96.5549 - val_loss: 558.4061\n",
      "Epoch 69/1000\n",
      "6/6 - 0s - loss: 96.2532 - val_loss: 557.5606\n",
      "Epoch 70/1000\n",
      "6/6 - 0s - loss: 95.9256 - val_loss: 556.7213\n",
      "Epoch 71/1000\n",
      "6/6 - 0s - loss: 95.5956 - val_loss: 555.8889\n",
      "Epoch 72/1000\n",
      "6/6 - 0s - loss: 95.2840 - val_loss: 555.0307\n",
      "Epoch 73/1000\n",
      "6/6 - 0s - loss: 94.9631 - val_loss: 554.2308\n",
      "Epoch 74/1000\n",
      "6/6 - 0s - loss: 94.6864 - val_loss: 553.4197\n",
      "Epoch 75/1000\n",
      "6/6 - 0s - loss: 94.3480 - val_loss: 552.6730\n",
      "Epoch 76/1000\n",
      "6/6 - 0s - loss: 94.0500 - val_loss: 551.9011\n",
      "Epoch 77/1000\n",
      "6/6 - 0s - loss: 93.7832 - val_loss: 551.0753\n",
      "Epoch 78/1000\n",
      "6/6 - 0s - loss: 93.4646 - val_loss: 550.2814\n",
      "Epoch 79/1000\n",
      "6/6 - 0s - loss: 93.1666 - val_loss: 549.4927\n",
      "Epoch 80/1000\n",
      "6/6 - 0s - loss: 92.8938 - val_loss: 548.7350\n",
      "Epoch 81/1000\n",
      "6/6 - 0s - loss: 92.5762 - val_loss: 548.0024\n",
      "Epoch 82/1000\n",
      "6/6 - 0s - loss: 92.3489 - val_loss: 547.2151\n",
      "Epoch 83/1000\n",
      "6/6 - 0s - loss: 92.0445 - val_loss: 546.4739\n",
      "Epoch 84/1000\n",
      "6/6 - 0s - loss: 91.7663 - val_loss: 545.7560\n",
      "Epoch 85/1000\n",
      "6/6 - 0s - loss: 91.4952 - val_loss: 545.0402\n",
      "Epoch 86/1000\n",
      "6/6 - 0s - loss: 91.2256 - val_loss: 544.3388\n",
      "Epoch 87/1000\n",
      "6/6 - 0s - loss: 90.9653 - val_loss: 543.5880\n",
      "Epoch 88/1000\n",
      "6/6 - 0s - loss: 90.6719 - val_loss: 542.8508\n",
      "Epoch 89/1000\n",
      "6/6 - 0s - loss: 90.4307 - val_loss: 542.1078\n",
      "Epoch 90/1000\n",
      "6/6 - 0s - loss: 90.1358 - val_loss: 541.4153\n",
      "Epoch 91/1000\n",
      "6/6 - 0s - loss: 89.8644 - val_loss: 540.7097\n",
      "Epoch 92/1000\n",
      "6/6 - 0s - loss: 89.6064 - val_loss: 539.9409\n",
      "Epoch 93/1000\n",
      "6/6 - 0s - loss: 89.3392 - val_loss: 539.1606\n",
      "Epoch 94/1000\n",
      "6/6 - 0s - loss: 89.0425 - val_loss: 538.4047\n",
      "Epoch 95/1000\n",
      "6/6 - 0s - loss: 88.7877 - val_loss: 537.6629\n",
      "Epoch 96/1000\n",
      "6/6 - 0s - loss: 88.5396 - val_loss: 536.9195\n",
      "Epoch 97/1000\n",
      "6/6 - 0s - loss: 88.2744 - val_loss: 536.2026\n",
      "Epoch 98/1000\n",
      "6/6 - 0s - loss: 87.9744 - val_loss: 535.5729\n",
      "Epoch 99/1000\n",
      "6/6 - 0s - loss: 87.7445 - val_loss: 534.9025\n",
      "Epoch 100/1000\n",
      "6/6 - 0s - loss: 87.5048 - val_loss: 534.1613\n",
      "Epoch 101/1000\n",
      "6/6 - 0s - loss: 87.2650 - val_loss: 533.4183\n",
      "Epoch 102/1000\n",
      "6/6 - 0s - loss: 86.9867 - val_loss: 532.7732\n",
      "Epoch 103/1000\n",
      "6/6 - 0s - loss: 86.7412 - val_loss: 532.0710\n",
      "Epoch 104/1000\n",
      "6/6 - 0s - loss: 86.5083 - val_loss: 531.3971\n",
      "Epoch 105/1000\n",
      "6/6 - 0s - loss: 86.2414 - val_loss: 530.7797\n",
      "Epoch 106/1000\n",
      "6/6 - 0s - loss: 86.0353 - val_loss: 530.0902\n",
      "Epoch 107/1000\n",
      "6/6 - 0s - loss: 85.7997 - val_loss: 529.4145\n",
      "Epoch 108/1000\n",
      "6/6 - 0s - loss: 85.5591 - val_loss: 528.7560\n",
      "Epoch 109/1000\n",
      "6/6 - 0s - loss: 85.3276 - val_loss: 528.0836\n",
      "Epoch 110/1000\n",
      "6/6 - 0s - loss: 85.0531 - val_loss: 527.4604\n",
      "Epoch 111/1000\n",
      "6/6 - 0s - loss: 84.8306 - val_loss: 526.8116\n",
      "Epoch 112/1000\n",
      "6/6 - 0s - loss: 84.6333 - val_loss: 526.0207\n",
      "Epoch 113/1000\n",
      "6/6 - 0s - loss: 84.3470 - val_loss: 525.3093\n",
      "Epoch 114/1000\n",
      "6/6 - 0s - loss: 84.1068 - val_loss: 524.6209\n",
      "Epoch 115/1000\n",
      "6/6 - 0s - loss: 83.8793 - val_loss: 524.0007\n",
      "Epoch 116/1000\n",
      "6/6 - 0s - loss: 83.6497 - val_loss: 523.3253\n",
      "Epoch 117/1000\n",
      "6/6 - 0s - loss: 83.3995 - val_loss: 522.7231\n",
      "Epoch 118/1000\n",
      "6/6 - 0s - loss: 83.1820 - val_loss: 522.0317\n",
      "Epoch 119/1000\n",
      "6/6 - 0s - loss: 82.9474 - val_loss: 521.2725\n",
      "Epoch 120/1000\n",
      "6/6 - 0s - loss: 82.6926 - val_loss: 520.5956\n",
      "Epoch 121/1000\n",
      "6/6 - 0s - loss: 82.4606 - val_loss: 519.9084\n",
      "Epoch 122/1000\n",
      "6/6 - 0s - loss: 82.2438 - val_loss: 519.1824\n",
      "Epoch 123/1000\n",
      "6/6 - 0s - loss: 82.0107 - val_loss: 518.4905\n",
      "Epoch 124/1000\n",
      "6/6 - 0s - loss: 81.7615 - val_loss: 517.7698\n",
      "Epoch 125/1000\n",
      "6/6 - 0s - loss: 81.5523 - val_loss: 517.1259\n",
      "Epoch 126/1000\n",
      "6/6 - 0s - loss: 81.3031 - val_loss: 516.5184\n",
      "Epoch 127/1000\n",
      "6/6 - 0s - loss: 81.0900 - val_loss: 515.8183\n",
      "Epoch 128/1000\n",
      "6/6 - 0s - loss: 80.8666 - val_loss: 515.1735\n",
      "Epoch 129/1000\n",
      "6/6 - 0s - loss: 80.6148 - val_loss: 514.4056\n",
      "Epoch 130/1000\n",
      "6/6 - 0s - loss: 80.3978 - val_loss: 513.6422\n",
      "Epoch 131/1000\n",
      "6/6 - 0s - loss: 80.1445 - val_loss: 512.9774\n",
      "Epoch 132/1000\n",
      "6/6 - 0s - loss: 79.9242 - val_loss: 512.2139\n",
      "Epoch 133/1000\n",
      "6/6 - 0s - loss: 79.6769 - val_loss: 511.5776\n",
      "Epoch 134/1000\n",
      "6/6 - 0s - loss: 79.4672 - val_loss: 510.9179\n",
      "Epoch 135/1000\n",
      "6/6 - 0s - loss: 79.2522 - val_loss: 510.2208\n",
      "Epoch 136/1000\n",
      "6/6 - 0s - loss: 79.0281 - val_loss: 509.6988\n",
      "Epoch 137/1000\n",
      "6/6 - 0s - loss: 78.8164 - val_loss: 509.0180\n",
      "Epoch 138/1000\n",
      "6/6 - 0s - loss: 78.6159 - val_loss: 508.4452\n",
      "Epoch 139/1000\n",
      "6/6 - 0s - loss: 78.4247 - val_loss: 507.8491\n",
      "Epoch 140/1000\n",
      "6/6 - 0s - loss: 78.1984 - val_loss: 507.1050\n",
      "Epoch 141/1000\n",
      "6/6 - 0s - loss: 77.9962 - val_loss: 506.5989\n",
      "Epoch 142/1000\n",
      "6/6 - 0s - loss: 77.7878 - val_loss: 505.9630\n",
      "Epoch 143/1000\n",
      "6/6 - 0s - loss: 77.5877 - val_loss: 505.2612\n",
      "Epoch 144/1000\n",
      "6/6 - 0s - loss: 77.4177 - val_loss: 504.6550\n",
      "Epoch 145/1000\n",
      "6/6 - 0s - loss: 77.1692 - val_loss: 503.9770\n",
      "Epoch 146/1000\n",
      "6/6 - 0s - loss: 76.9810 - val_loss: 503.3784\n",
      "Epoch 147/1000\n",
      "6/6 - 0s - loss: 76.7580 - val_loss: 502.7468\n",
      "Epoch 148/1000\n",
      "6/6 - 0s - loss: 76.5815 - val_loss: 502.0036\n",
      "Epoch 149/1000\n",
      "6/6 - 0s - loss: 76.3550 - val_loss: 501.3172\n",
      "Epoch 150/1000\n",
      "6/6 - 0s - loss: 76.1240 - val_loss: 500.6428\n",
      "Epoch 151/1000\n",
      "6/6 - 0s - loss: 75.9603 - val_loss: 499.9775\n",
      "Epoch 152/1000\n",
      "6/6 - 0s - loss: 75.7110 - val_loss: 499.3197\n",
      "Epoch 153/1000\n",
      "6/6 - 0s - loss: 75.5252 - val_loss: 498.7456\n",
      "Epoch 154/1000\n",
      "6/6 - 0s - loss: 75.3197 - val_loss: 498.0435\n",
      "Epoch 155/1000\n",
      "6/6 - 0s - loss: 75.1399 - val_loss: 497.5636\n",
      "Epoch 156/1000\n",
      "6/6 - 0s - loss: 74.9418 - val_loss: 496.8387\n",
      "Epoch 157/1000\n",
      "6/6 - 0s - loss: 74.7189 - val_loss: 496.3153\n",
      "Epoch 158/1000\n",
      "6/6 - 0s - loss: 74.5534 - val_loss: 495.7039\n",
      "Epoch 159/1000\n",
      "6/6 - 0s - loss: 74.3498 - val_loss: 495.1832\n",
      "Epoch 160/1000\n",
      "6/6 - 0s - loss: 74.1667 - val_loss: 494.5571\n",
      "Epoch 161/1000\n",
      "6/6 - 0s - loss: 73.9878 - val_loss: 494.0469\n",
      "Epoch 162/1000\n",
      "6/6 - 0s - loss: 73.7923 - val_loss: 493.4414\n",
      "Epoch 163/1000\n",
      "6/6 - 0s - loss: 73.6084 - val_loss: 492.9422\n",
      "Epoch 164/1000\n",
      "6/6 - 0s - loss: 73.4215 - val_loss: 492.3240\n",
      "Epoch 165/1000\n",
      "6/6 - 0s - loss: 73.2423 - val_loss: 491.7417\n",
      "Epoch 166/1000\n",
      "6/6 - 0s - loss: 73.0523 - val_loss: 491.1694\n",
      "Epoch 167/1000\n",
      "6/6 - 0s - loss: 72.8511 - val_loss: 490.4659\n",
      "Epoch 168/1000\n",
      "6/6 - 0s - loss: 72.6486 - val_loss: 489.9246\n",
      "Epoch 169/1000\n",
      "6/6 - 0s - loss: 72.4707 - val_loss: 489.2251\n",
      "Epoch 170/1000\n",
      "6/6 - 0s - loss: 72.2692 - val_loss: 488.7430\n",
      "Epoch 171/1000\n",
      "6/6 - 0s - loss: 72.0782 - val_loss: 488.0869\n",
      "Epoch 172/1000\n",
      "6/6 - 0s - loss: 71.8848 - val_loss: 487.5658\n",
      "Epoch 173/1000\n",
      "6/6 - 0s - loss: 71.6892 - val_loss: 487.0200\n",
      "Epoch 174/1000\n",
      "6/6 - 0s - loss: 71.5294 - val_loss: 486.4573\n",
      "Epoch 175/1000\n",
      "6/6 - 0s - loss: 71.3400 - val_loss: 485.9202\n",
      "Epoch 176/1000\n",
      "6/6 - 0s - loss: 71.1733 - val_loss: 485.3026\n",
      "Epoch 177/1000\n",
      "6/6 - 0s - loss: 70.9663 - val_loss: 484.8270\n",
      "Epoch 178/1000\n",
      "6/6 - 0s - loss: 70.7792 - val_loss: 484.3100\n",
      "Epoch 179/1000\n",
      "6/6 - 0s - loss: 70.6203 - val_loss: 483.7378\n",
      "Epoch 180/1000\n",
      "6/6 - 0s - loss: 70.4284 - val_loss: 483.0786\n",
      "Epoch 181/1000\n",
      "6/6 - 0s - loss: 70.2290 - val_loss: 482.5920\n",
      "Epoch 182/1000\n",
      "6/6 - 0s - loss: 70.0600 - val_loss: 481.9987\n",
      "Epoch 183/1000\n",
      "6/6 - 0s - loss: 69.8824 - val_loss: 481.4962\n",
      "Epoch 184/1000\n",
      "6/6 - 0s - loss: 69.7071 - val_loss: 480.9004\n",
      "Epoch 185/1000\n",
      "6/6 - 0s - loss: 69.5449 - val_loss: 480.4001\n",
      "Epoch 186/1000\n",
      "6/6 - 0s - loss: 69.3548 - val_loss: 479.8286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/1000\n",
      "6/6 - 0s - loss: 69.1984 - val_loss: 479.3488\n",
      "Epoch 188/1000\n",
      "6/6 - 0s - loss: 69.0402 - val_loss: 478.6229\n",
      "Epoch 189/1000\n",
      "6/6 - 0s - loss: 68.8588 - val_loss: 478.1466\n",
      "Epoch 190/1000\n",
      "6/6 - 0s - loss: 68.6713 - val_loss: 477.5832\n",
      "Epoch 191/1000\n",
      "6/6 - 0s - loss: 68.4923 - val_loss: 477.0948\n",
      "Epoch 192/1000\n",
      "6/6 - 0s - loss: 68.3475 - val_loss: 476.3725\n",
      "Epoch 193/1000\n",
      "6/6 - 0s - loss: 68.1347 - val_loss: 476.0587\n",
      "Epoch 194/1000\n",
      "6/6 - 0s - loss: 67.9886 - val_loss: 475.3521\n",
      "Epoch 195/1000\n",
      "6/6 - 0s - loss: 67.8142 - val_loss: 475.0801\n",
      "Epoch 196/1000\n",
      "6/6 - 0s - loss: 67.6635 - val_loss: 474.2470\n",
      "Epoch 197/1000\n",
      "6/6 - 0s - loss: 67.4970 - val_loss: 474.0863\n",
      "Epoch 198/1000\n",
      "6/6 - 0s - loss: 67.3083 - val_loss: 473.1865\n",
      "Epoch 199/1000\n",
      "6/6 - 0s - loss: 67.1609 - val_loss: 473.2497\n",
      "Epoch 200/1000\n",
      "6/6 - 0s - loss: 66.9941 - val_loss: 471.9797\n",
      "Epoch 201/1000\n",
      "6/6 - 0s - loss: 66.8434 - val_loss: 472.3398\n",
      "Epoch 202/1000\n",
      "6/6 - 0s - loss: 66.6786 - val_loss: 470.8184\n",
      "Epoch 203/1000\n",
      "6/6 - 0s - loss: 66.5350 - val_loss: 471.3088\n",
      "Epoch 204/1000\n",
      "6/6 - 0s - loss: 66.3536 - val_loss: 469.5045\n",
      "Epoch 205/1000\n",
      "6/6 - 0s - loss: 66.2012 - val_loss: 470.2940\n",
      "Epoch 206/1000\n",
      "6/6 - 0s - loss: 66.0486 - val_loss: 468.2471\n",
      "Epoch 207/1000\n",
      "6/6 - 0s - loss: 65.9515 - val_loss: 468.9770\n",
      "Epoch 208/1000\n",
      "6/6 - 0s - loss: 65.7510 - val_loss: 467.4770\n",
      "Epoch 209/1000\n",
      "6/6 - 0s - loss: 65.5717 - val_loss: 467.1600\n",
      "Epoch 210/1000\n",
      "6/6 - 0s - loss: 65.3861 - val_loss: 466.6929\n",
      "Epoch 211/1000\n",
      "6/6 - 0s - loss: 65.2124 - val_loss: 465.6917\n",
      "Epoch 212/1000\n",
      "6/6 - 0s - loss: 65.0425 - val_loss: 465.8907\n",
      "Epoch 213/1000\n",
      "6/6 - 0s - loss: 64.8796 - val_loss: 464.4972\n",
      "Epoch 214/1000\n",
      "6/6 - 0s - loss: 64.7034 - val_loss: 464.4595\n",
      "Epoch 215/1000\n",
      "6/6 - 0s - loss: 64.5308 - val_loss: 463.3484\n",
      "Epoch 216/1000\n",
      "6/6 - 0s - loss: 64.3638 - val_loss: 463.1258\n",
      "Epoch 217/1000\n",
      "6/6 - 0s - loss: 64.1759 - val_loss: 462.4053\n",
      "Epoch 218/1000\n",
      "6/6 - 0s - loss: 64.0247 - val_loss: 461.8959\n",
      "Epoch 219/1000\n",
      "6/6 - 0s - loss: 63.8654 - val_loss: 461.3662\n",
      "Epoch 220/1000\n",
      "6/6 - 0s - loss: 63.6866 - val_loss: 460.7365\n",
      "Epoch 221/1000\n",
      "6/6 - 0s - loss: 63.5300 - val_loss: 460.3304\n",
      "Epoch 222/1000\n",
      "6/6 - 0s - loss: 63.3494 - val_loss: 459.6689\n",
      "Epoch 223/1000\n",
      "6/6 - 0s - loss: 63.2237 - val_loss: 459.2896\n",
      "Epoch 224/1000\n",
      "6/6 - 0s - loss: 63.0500 - val_loss: 458.6237\n",
      "Epoch 225/1000\n",
      "6/6 - 0s - loss: 62.9107 - val_loss: 458.2205\n",
      "Epoch 226/1000\n",
      "6/6 - 0s - loss: 62.7179 - val_loss: 457.6672\n",
      "Epoch 227/1000\n",
      "6/6 - 0s - loss: 62.6030 - val_loss: 457.2224\n",
      "Epoch 228/1000\n",
      "6/6 - 0s - loss: 62.4270 - val_loss: 456.6108\n",
      "Epoch 229/1000\n",
      "6/6 - 0s - loss: 62.2669 - val_loss: 456.2027\n",
      "Epoch 230/1000\n",
      "6/6 - 0s - loss: 62.1161 - val_loss: 455.5823\n",
      "Epoch 231/1000\n",
      "6/6 - 0s - loss: 61.9556 - val_loss: 455.1144\n",
      "Epoch 232/1000\n",
      "6/6 - 0s - loss: 61.8029 - val_loss: 454.4804\n",
      "Epoch 233/1000\n",
      "6/6 - 0s - loss: 61.6548 - val_loss: 454.0162\n",
      "Epoch 234/1000\n",
      "6/6 - 0s - loss: 61.4861 - val_loss: 453.4524\n",
      "Epoch 235/1000\n",
      "6/6 - 0s - loss: 61.3232 - val_loss: 453.0814\n",
      "Epoch 236/1000\n",
      "6/6 - 0s - loss: 61.1599 - val_loss: 452.4900\n",
      "Epoch 237/1000\n",
      "6/6 - 0s - loss: 60.9975 - val_loss: 452.0978\n",
      "Epoch 238/1000\n",
      "6/6 - 0s - loss: 60.8542 - val_loss: 451.4955\n",
      "Epoch 239/1000\n",
      "6/6 - 0s - loss: 60.7061 - val_loss: 451.1521\n",
      "Epoch 240/1000\n",
      "6/6 - 0s - loss: 60.5816 - val_loss: 450.4646\n",
      "Epoch 241/1000\n",
      "6/6 - 0s - loss: 60.4346 - val_loss: 450.1553\n",
      "Epoch 242/1000\n",
      "6/6 - 0s - loss: 60.2688 - val_loss: 449.4720\n",
      "Epoch 243/1000\n",
      "6/6 - 0s - loss: 60.1239 - val_loss: 449.2552\n",
      "Epoch 244/1000\n",
      "6/6 - 0s - loss: 59.9984 - val_loss: 448.5896\n",
      "Epoch 245/1000\n",
      "6/6 - 0s - loss: 59.8468 - val_loss: 448.4032\n",
      "Epoch 246/1000\n",
      "6/6 - 0s - loss: 59.7151 - val_loss: 447.6306\n",
      "Epoch 247/1000\n",
      "6/6 - 0s - loss: 59.5785 - val_loss: 447.5107\n",
      "Epoch 248/1000\n",
      "6/6 - 0s - loss: 59.4229 - val_loss: 446.6717\n",
      "Epoch 249/1000\n",
      "6/6 - 0s - loss: 59.2897 - val_loss: 446.7580\n",
      "Epoch 250/1000\n",
      "6/6 - 0s - loss: 59.1603 - val_loss: 445.7060\n",
      "Epoch 251/1000\n",
      "6/6 - 0s - loss: 59.0186 - val_loss: 445.8895\n",
      "Epoch 252/1000\n",
      "6/6 - 0s - loss: 58.8872 - val_loss: 444.6231\n",
      "Epoch 253/1000\n",
      "6/6 - 0s - loss: 58.7647 - val_loss: 445.0246\n",
      "Epoch 254/1000\n",
      "6/6 - 0s - loss: 58.6334 - val_loss: 443.6238\n",
      "Epoch 255/1000\n",
      "6/6 - 0s - loss: 58.5024 - val_loss: 444.1783\n",
      "Epoch 256/1000\n",
      "6/6 - 0s - loss: 58.3631 - val_loss: 442.7512\n",
      "Epoch 257/1000\n",
      "6/6 - 0s - loss: 58.2408 - val_loss: 443.1791\n",
      "Epoch 258/1000\n",
      "6/6 - 0s - loss: 58.1087 - val_loss: 441.5225\n",
      "Epoch 259/1000\n",
      "6/6 - 0s - loss: 57.9654 - val_loss: 442.4435\n",
      "Epoch 260/1000\n",
      "6/6 - 0s - loss: 57.8475 - val_loss: 440.3362\n",
      "Epoch 261/1000\n",
      "6/6 - 0s - loss: 57.6904 - val_loss: 441.3195\n",
      "Epoch 262/1000\n",
      "6/6 - 0s - loss: 57.5606 - val_loss: 439.0125\n",
      "Epoch 263/1000\n",
      "6/6 - 0s - loss: 57.4478 - val_loss: 440.3810\n",
      "Epoch 264/1000\n",
      "6/6 - 0s - loss: 57.2975 - val_loss: 437.8971\n",
      "Epoch 265/1000\n",
      "6/6 - 0s - loss: 57.1758 - val_loss: 439.3928\n",
      "Epoch 266/1000\n",
      "6/6 - 0s - loss: 57.0689 - val_loss: 436.8586\n",
      "Epoch 267/1000\n",
      "6/6 - 0s - loss: 56.9124 - val_loss: 438.7278\n",
      "Epoch 268/1000\n",
      "6/6 - 0s - loss: 56.7781 - val_loss: 435.7212\n",
      "Epoch 269/1000\n",
      "6/6 - 0s - loss: 56.7036 - val_loss: 437.7062\n",
      "Epoch 270/1000\n",
      "6/6 - 0s - loss: 56.5815 - val_loss: 434.5869\n",
      "Epoch 271/1000\n",
      "6/6 - 0s - loss: 56.4663 - val_loss: 436.5703\n",
      "Epoch 272/1000\n",
      "6/6 - 0s - loss: 56.3477 - val_loss: 433.8115\n",
      "Epoch 273/1000\n",
      "6/6 - 0s - loss: 56.2077 - val_loss: 434.5637\n",
      "Epoch 274/1000\n",
      "6/6 - 0s - loss: 56.0456 - val_loss: 433.6543\n",
      "Epoch 275/1000\n",
      "6/6 - 0s - loss: 55.8594 - val_loss: 432.6818\n",
      "Epoch 276/1000\n",
      "6/6 - 0s - loss: 55.6764 - val_loss: 433.1021\n",
      "Epoch 277/1000\n",
      "6/6 - 0s - loss: 55.5425 - val_loss: 431.4843\n",
      "Epoch 278/1000\n",
      "6/6 - 0s - loss: 55.3953 - val_loss: 432.2169\n",
      "Epoch 279/1000\n",
      "6/6 - 0s - loss: 55.2863 - val_loss: 430.7027\n",
      "Epoch 280/1000\n",
      "6/6 - 0s - loss: 55.1605 - val_loss: 431.0475\n",
      "Epoch 281/1000\n",
      "6/6 - 0s - loss: 55.0079 - val_loss: 429.9873\n",
      "Epoch 282/1000\n",
      "6/6 - 0s - loss: 54.9107 - val_loss: 429.8312\n",
      "Epoch 283/1000\n",
      "6/6 - 0s - loss: 54.7304 - val_loss: 429.3922\n",
      "Epoch 284/1000\n",
      "6/6 - 0s - loss: 54.6211 - val_loss: 428.7163\n",
      "Epoch 285/1000\n",
      "6/6 - 0s - loss: 54.4715 - val_loss: 428.5390\n",
      "Epoch 286/1000\n",
      "6/6 - 0s - loss: 54.3425 - val_loss: 427.7932\n",
      "Epoch 287/1000\n",
      "6/6 - 0s - loss: 54.2381 - val_loss: 427.5820\n",
      "Epoch 288/1000\n",
      "6/6 - 0s - loss: 54.0822 - val_loss: 426.7729\n",
      "Epoch 289/1000\n",
      "6/6 - 0s - loss: 53.9725 - val_loss: 426.4944\n",
      "Epoch 290/1000\n",
      "6/6 - 0s - loss: 53.8540 - val_loss: 425.7592\n",
      "Epoch 291/1000\n",
      "6/6 - 0s - loss: 53.6937 - val_loss: 425.4211\n",
      "Epoch 292/1000\n",
      "6/6 - 0s - loss: 53.5567 - val_loss: 424.9099\n",
      "Epoch 293/1000\n",
      "6/6 - 0s - loss: 53.4202 - val_loss: 424.4476\n",
      "Epoch 294/1000\n",
      "6/6 - 0s - loss: 53.3241 - val_loss: 424.0342\n",
      "Epoch 295/1000\n",
      "6/6 - 0s - loss: 53.1580 - val_loss: 423.5352\n",
      "Epoch 296/1000\n",
      "6/6 - 0s - loss: 53.0401 - val_loss: 423.0971\n",
      "Epoch 297/1000\n",
      "6/6 - 0s - loss: 52.9126 - val_loss: 422.6458\n",
      "Epoch 298/1000\n",
      "6/6 - 0s - loss: 52.7982 - val_loss: 422.1788\n",
      "Epoch 299/1000\n",
      "6/6 - 0s - loss: 52.6663 - val_loss: 421.7851\n",
      "Epoch 300/1000\n",
      "6/6 - 0s - loss: 52.5540 - val_loss: 421.2983\n",
      "Epoch 301/1000\n",
      "6/6 - 0s - loss: 52.4314 - val_loss: 420.8229\n",
      "Epoch 302/1000\n",
      "6/6 - 0s - loss: 52.3095 - val_loss: 420.4547\n",
      "Epoch 303/1000\n",
      "6/6 - 0s - loss: 52.1732 - val_loss: 419.9905\n",
      "Epoch 304/1000\n",
      "6/6 - 0s - loss: 52.0488 - val_loss: 419.5679\n",
      "Epoch 305/1000\n",
      "6/6 - 0s - loss: 51.9274 - val_loss: 419.0264\n",
      "Epoch 306/1000\n",
      "6/6 - 0s - loss: 51.8090 - val_loss: 418.6734\n",
      "Epoch 307/1000\n",
      "6/6 - 0s - loss: 51.6874 - val_loss: 418.2954\n",
      "Epoch 308/1000\n",
      "6/6 - 0s - loss: 51.5693 - val_loss: 417.8178\n",
      "Epoch 309/1000\n",
      "6/6 - 0s - loss: 51.4428 - val_loss: 417.5782\n",
      "Epoch 310/1000\n",
      "6/6 - 0s - loss: 51.3340 - val_loss: 417.1245\n",
      "Epoch 311/1000\n",
      "6/6 - 0s - loss: 51.2207 - val_loss: 416.7896\n",
      "Epoch 312/1000\n",
      "6/6 - 0s - loss: 51.0937 - val_loss: 416.2986\n",
      "Epoch 313/1000\n",
      "6/6 - 0s - loss: 50.9853 - val_loss: 416.0013\n",
      "Epoch 314/1000\n",
      "6/6 - 0s - loss: 50.8442 - val_loss: 415.4931\n",
      "Epoch 315/1000\n",
      "6/6 - 0s - loss: 50.7463 - val_loss: 415.2221\n",
      "Epoch 316/1000\n",
      "6/6 - 0s - loss: 50.6275 - val_loss: 414.6639\n",
      "Epoch 317/1000\n",
      "6/6 - 0s - loss: 50.4953 - val_loss: 414.4880\n",
      "Epoch 318/1000\n",
      "6/6 - 0s - loss: 50.3950 - val_loss: 413.8823\n",
      "Epoch 319/1000\n",
      "6/6 - 0s - loss: 50.2737 - val_loss: 413.7732\n",
      "Epoch 320/1000\n",
      "6/6 - 0s - loss: 50.1619 - val_loss: 412.9491\n",
      "Epoch 321/1000\n",
      "6/6 - 0s - loss: 50.0472 - val_loss: 413.0139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 322/1000\n",
      "6/6 - 0s - loss: 49.9484 - val_loss: 412.1188\n",
      "Epoch 323/1000\n",
      "6/6 - 0s - loss: 49.8166 - val_loss: 412.3210\n",
      "Epoch 324/1000\n",
      "6/6 - 0s - loss: 49.7127 - val_loss: 411.2029\n",
      "Epoch 325/1000\n",
      "6/6 - 0s - loss: 49.6035 - val_loss: 411.5304\n",
      "Epoch 326/1000\n",
      "6/6 - 0s - loss: 49.4907 - val_loss: 410.4685\n",
      "Epoch 327/1000\n",
      "6/6 - 0s - loss: 49.3837 - val_loss: 410.7564\n",
      "Epoch 328/1000\n",
      "6/6 - 0s - loss: 49.2881 - val_loss: 409.5472\n",
      "Epoch 329/1000\n",
      "6/6 - 0s - loss: 49.1699 - val_loss: 409.9671\n",
      "Epoch 330/1000\n",
      "6/6 - 0s - loss: 49.0655 - val_loss: 408.8848\n",
      "Epoch 331/1000\n",
      "6/6 - 0s - loss: 48.9504 - val_loss: 409.1063\n",
      "Epoch 332/1000\n",
      "6/6 - 0s - loss: 48.8496 - val_loss: 408.1712\n",
      "Epoch 333/1000\n",
      "6/6 - 0s - loss: 48.7312 - val_loss: 408.1130\n",
      "Epoch 334/1000\n",
      "6/6 - 0s - loss: 48.6120 - val_loss: 407.3603\n",
      "Epoch 335/1000\n",
      "6/6 - 0s - loss: 48.5130 - val_loss: 407.0706\n",
      "Epoch 336/1000\n",
      "6/6 - 0s - loss: 48.3902 - val_loss: 406.3408\n",
      "Epoch 337/1000\n",
      "6/6 - 0s - loss: 48.2818 - val_loss: 406.3494\n",
      "Epoch 338/1000\n",
      "6/6 - 0s - loss: 48.1771 - val_loss: 405.3771\n",
      "Epoch 339/1000\n",
      "6/6 - 0s - loss: 48.0739 - val_loss: 405.3885\n",
      "Epoch 340/1000\n",
      "6/6 - 0s - loss: 47.9652 - val_loss: 404.6767\n",
      "Epoch 341/1000\n",
      "6/6 - 0s - loss: 47.8418 - val_loss: 404.6130\n",
      "Epoch 342/1000\n",
      "6/6 - 0s - loss: 47.7649 - val_loss: 403.8311\n",
      "Epoch 343/1000\n",
      "6/6 - 0s - loss: 47.6390 - val_loss: 404.0188\n",
      "Epoch 344/1000\n",
      "6/6 - 0s - loss: 47.5349 - val_loss: 402.9113\n",
      "Epoch 345/1000\n",
      "6/6 - 0s - loss: 47.4618 - val_loss: 403.3683\n",
      "Epoch 346/1000\n",
      "6/6 - 0s - loss: 47.3517 - val_loss: 402.2646\n",
      "Epoch 347/1000\n",
      "6/6 - 0s - loss: 47.2423 - val_loss: 402.3652\n",
      "Epoch 348/1000\n",
      "6/6 - 0s - loss: 47.1206 - val_loss: 401.7179\n",
      "Epoch 349/1000\n",
      "6/6 - 0s - loss: 47.0348 - val_loss: 401.5054\n",
      "Epoch 350/1000\n",
      "6/6 - 0s - loss: 46.9265 - val_loss: 401.0486\n",
      "Epoch 351/1000\n",
      "6/6 - 0s - loss: 46.8352 - val_loss: 400.4244\n",
      "Epoch 352/1000\n",
      "6/6 - 0s - loss: 46.7091 - val_loss: 400.4014\n",
      "Epoch 353/1000\n",
      "6/6 - 0s - loss: 46.6159 - val_loss: 399.6469\n",
      "Epoch 354/1000\n",
      "6/6 - 0s - loss: 46.4936 - val_loss: 399.1472\n",
      "Epoch 355/1000\n",
      "6/6 - 0s - loss: 46.3746 - val_loss: 398.9915\n",
      "Epoch 356/1000\n",
      "6/6 - 0s - loss: 46.2722 - val_loss: 398.0005\n",
      "Epoch 357/1000\n",
      "6/6 - 0s - loss: 46.1625 - val_loss: 398.1599\n",
      "Epoch 358/1000\n",
      "6/6 - 0s - loss: 46.0601 - val_loss: 396.9176\n",
      "Epoch 359/1000\n",
      "6/6 - 0s - loss: 45.8969 - val_loss: 397.2238\n",
      "Epoch 360/1000\n",
      "6/6 - 0s - loss: 45.8055 - val_loss: 396.4749\n",
      "Epoch 361/1000\n",
      "6/6 - 0s - loss: 45.6863 - val_loss: 396.4262\n",
      "Epoch 362/1000\n",
      "6/6 - 0s - loss: 45.6029 - val_loss: 395.8759\n",
      "Epoch 363/1000\n",
      "6/6 - 0s - loss: 45.4883 - val_loss: 395.6104\n",
      "Epoch 364/1000\n",
      "6/6 - 0s - loss: 45.3715 - val_loss: 395.3561\n",
      "Epoch 365/1000\n",
      "6/6 - 0s - loss: 45.2693 - val_loss: 394.4145\n",
      "Epoch 366/1000\n",
      "6/6 - 0s - loss: 45.1688 - val_loss: 394.8857\n",
      "Epoch 367/1000\n",
      "6/6 - 0s - loss: 45.0436 - val_loss: 393.9761\n",
      "Epoch 368/1000\n",
      "6/6 - 0s - loss: 44.9538 - val_loss: 393.9528\n",
      "Epoch 369/1000\n",
      "6/6 - 0s - loss: 44.8216 - val_loss: 393.5128\n",
      "Epoch 370/1000\n",
      "6/6 - 0s - loss: 44.7572 - val_loss: 392.9080\n",
      "Epoch 371/1000\n",
      "6/6 - 0s - loss: 44.6233 - val_loss: 393.3941\n",
      "Epoch 372/1000\n",
      "6/6 - 0s - loss: 44.5336 - val_loss: 391.9465\n",
      "Epoch 373/1000\n",
      "6/6 - 0s - loss: 44.4444 - val_loss: 392.6528\n",
      "Epoch 374/1000\n",
      "6/6 - 0s - loss: 44.3412 - val_loss: 391.4493\n",
      "Epoch 375/1000\n",
      "6/6 - 0s - loss: 44.2540 - val_loss: 391.6009\n",
      "Epoch 376/1000\n",
      "6/6 - 0s - loss: 44.1312 - val_loss: 391.2603\n",
      "Epoch 377/1000\n",
      "6/6 - 0s - loss: 44.0154 - val_loss: 390.4375\n",
      "Epoch 378/1000\n",
      "6/6 - 0s - loss: 43.9651 - val_loss: 391.3292\n",
      "Epoch 379/1000\n",
      "6/6 - 0s - loss: 43.8596 - val_loss: 388.9476\n",
      "Epoch 380/1000\n",
      "6/6 - 0s - loss: 43.8024 - val_loss: 390.3737\n",
      "Epoch 381/1000\n",
      "6/6 - 0s - loss: 43.6681 - val_loss: 388.6877\n",
      "Epoch 382/1000\n",
      "6/6 - 0s - loss: 43.5827 - val_loss: 390.1393\n",
      "Epoch 383/1000\n",
      "6/6 - 0s - loss: 43.4968 - val_loss: 387.8627\n",
      "Epoch 384/1000\n",
      "6/6 - 0s - loss: 43.4055 - val_loss: 388.2232\n",
      "Epoch 385/1000\n",
      "6/6 - 0s - loss: 43.2898 - val_loss: 388.0124\n",
      "Epoch 386/1000\n",
      "6/6 - 0s - loss: 43.1711 - val_loss: 387.0725\n",
      "Epoch 387/1000\n",
      "6/6 - 0s - loss: 43.0672 - val_loss: 388.0468\n",
      "Epoch 388/1000\n",
      "6/6 - 0s - loss: 42.9829 - val_loss: 385.5841\n",
      "Epoch 389/1000\n",
      "6/6 - 0s - loss: 42.9131 - val_loss: 387.4322\n",
      "Epoch 390/1000\n",
      "6/6 - 0s - loss: 42.7850 - val_loss: 384.8076\n",
      "Epoch 391/1000\n",
      "6/6 - 0s - loss: 42.7497 - val_loss: 386.0426\n",
      "Epoch 392/1000\n",
      "6/6 - 0s - loss: 42.6044 - val_loss: 385.3345\n",
      "Epoch 393/1000\n",
      "6/6 - 0s - loss: 42.5159 - val_loss: 384.7759\n",
      "Epoch 394/1000\n",
      "6/6 - 0s - loss: 42.3942 - val_loss: 384.6398\n",
      "Epoch 395/1000\n",
      "6/6 - 0s - loss: 42.2843 - val_loss: 383.5060\n",
      "Epoch 396/1000\n",
      "6/6 - 0s - loss: 42.1884 - val_loss: 384.2995\n",
      "Epoch 397/1000\n",
      "6/6 - 0s - loss: 42.0915 - val_loss: 383.0279\n",
      "Epoch 398/1000\n",
      "6/6 - 0s - loss: 41.9663 - val_loss: 383.1853\n",
      "Epoch 399/1000\n",
      "6/6 - 0s - loss: 41.8689 - val_loss: 382.4696\n",
      "Epoch 400/1000\n",
      "6/6 - 0s - loss: 41.7459 - val_loss: 382.0297\n",
      "Epoch 401/1000\n",
      "6/6 - 0s - loss: 41.6516 - val_loss: 381.8800\n",
      "Epoch 402/1000\n",
      "6/6 - 0s - loss: 41.5379 - val_loss: 381.2268\n",
      "Epoch 403/1000\n",
      "6/6 - 0s - loss: 41.4423 - val_loss: 381.2114\n",
      "Epoch 404/1000\n",
      "6/6 - 0s - loss: 41.3245 - val_loss: 380.6312\n",
      "Epoch 405/1000\n",
      "6/6 - 0s - loss: 41.2305 - val_loss: 380.4912\n",
      "Epoch 406/1000\n",
      "6/6 - 0s - loss: 41.1371 - val_loss: 380.1419\n",
      "Epoch 407/1000\n",
      "6/6 - 0s - loss: 41.0308 - val_loss: 379.5550\n",
      "Epoch 408/1000\n",
      "6/6 - 0s - loss: 40.9494 - val_loss: 379.8810\n",
      "Epoch 409/1000\n",
      "6/6 - 0s - loss: 40.8379 - val_loss: 378.6989\n",
      "Epoch 410/1000\n",
      "6/6 - 0s - loss: 40.7684 - val_loss: 379.4666\n",
      "Epoch 411/1000\n",
      "6/6 - 0s - loss: 40.6660 - val_loss: 378.2434\n",
      "Epoch 412/1000\n",
      "6/6 - 0s - loss: 40.5724 - val_loss: 378.5384\n",
      "Epoch 413/1000\n",
      "6/6 - 0s - loss: 40.4986 - val_loss: 377.8958\n",
      "Epoch 414/1000\n",
      "6/6 - 0s - loss: 40.3808 - val_loss: 377.8441\n",
      "Epoch 415/1000\n",
      "6/6 - 0s - loss: 40.3072 - val_loss: 377.6684\n",
      "Epoch 416/1000\n",
      "6/6 - 0s - loss: 40.2147 - val_loss: 376.9565\n",
      "Epoch 417/1000\n",
      "6/6 - 0s - loss: 40.1118 - val_loss: 377.0400\n",
      "Epoch 418/1000\n",
      "6/6 - 0s - loss: 40.0077 - val_loss: 376.3120\n",
      "Epoch 419/1000\n",
      "6/6 - 0s - loss: 39.9288 - val_loss: 376.5263\n",
      "Epoch 420/1000\n",
      "6/6 - 0s - loss: 39.8220 - val_loss: 375.9221\n",
      "Epoch 421/1000\n",
      "6/6 - 0s - loss: 39.7559 - val_loss: 375.7802\n",
      "Epoch 422/1000\n",
      "6/6 - 0s - loss: 39.6480 - val_loss: 375.6884\n",
      "Epoch 423/1000\n",
      "6/6 - 0s - loss: 39.5813 - val_loss: 374.6804\n",
      "Epoch 424/1000\n",
      "6/6 - 0s - loss: 39.4828 - val_loss: 375.2805\n",
      "Epoch 425/1000\n",
      "6/6 - 0s - loss: 39.3973 - val_loss: 374.2484\n",
      "Epoch 426/1000\n",
      "6/6 - 0s - loss: 39.3143 - val_loss: 374.3672\n",
      "Epoch 427/1000\n",
      "6/6 - 0s - loss: 39.2153 - val_loss: 374.1293\n",
      "Epoch 428/1000\n",
      "6/6 - 0s - loss: 39.1388 - val_loss: 373.3513\n",
      "Epoch 429/1000\n",
      "6/6 - 0s - loss: 39.0331 - val_loss: 373.8888\n",
      "Epoch 430/1000\n",
      "6/6 - 0s - loss: 38.9401 - val_loss: 372.6557\n",
      "Epoch 431/1000\n",
      "6/6 - 0s - loss: 38.8622 - val_loss: 373.0627\n",
      "Epoch 432/1000\n",
      "6/6 - 0s - loss: 38.7481 - val_loss: 372.4279\n",
      "Epoch 433/1000\n",
      "6/6 - 0s - loss: 38.6697 - val_loss: 372.1001\n",
      "Epoch 434/1000\n",
      "6/6 - 0s - loss: 38.5856 - val_loss: 371.9702\n",
      "Epoch 435/1000\n",
      "6/6 - 0s - loss: 38.4916 - val_loss: 371.1540\n",
      "Epoch 436/1000\n",
      "6/6 - 0s - loss: 38.4019 - val_loss: 371.6288\n",
      "Epoch 437/1000\n",
      "6/6 - 0s - loss: 38.3141 - val_loss: 370.7002\n",
      "Epoch 438/1000\n",
      "6/6 - 0s - loss: 38.2422 - val_loss: 370.7873\n",
      "Epoch 439/1000\n",
      "6/6 - 0s - loss: 38.1412 - val_loss: 370.3506\n",
      "Epoch 440/1000\n",
      "6/6 - 0s - loss: 38.0475 - val_loss: 369.8285\n",
      "Epoch 441/1000\n",
      "6/6 - 0s - loss: 37.9633 - val_loss: 369.9188\n",
      "Epoch 442/1000\n",
      "6/6 - 0s - loss: 37.8818 - val_loss: 369.1558\n",
      "Epoch 443/1000\n",
      "6/6 - 0s - loss: 37.7937 - val_loss: 369.2564\n",
      "Epoch 444/1000\n",
      "6/6 - 0s - loss: 37.7171 - val_loss: 369.0156\n",
      "Epoch 445/1000\n",
      "6/6 - 0s - loss: 37.6170 - val_loss: 368.1599\n",
      "Epoch 446/1000\n",
      "6/6 - 0s - loss: 37.5377 - val_loss: 368.2630\n",
      "Epoch 447/1000\n",
      "6/6 - 0s - loss: 37.4558 - val_loss: 367.9805\n",
      "Epoch 448/1000\n",
      "6/6 - 0s - loss: 37.3807 - val_loss: 366.9587\n",
      "Epoch 449/1000\n",
      "6/6 - 0s - loss: 37.2798 - val_loss: 367.6879\n",
      "Epoch 450/1000\n",
      "6/6 - 0s - loss: 37.2030 - val_loss: 366.8096\n",
      "Epoch 451/1000\n",
      "6/6 - 0s - loss: 37.1058 - val_loss: 365.8729\n",
      "Epoch 452/1000\n",
      "6/6 - 0s - loss: 37.0299 - val_loss: 366.9717\n",
      "Epoch 453/1000\n",
      "6/6 - 0s - loss: 36.9678 - val_loss: 365.4097\n",
      "Epoch 454/1000\n",
      "6/6 - 0s - loss: 36.9162 - val_loss: 365.0934\n",
      "Epoch 455/1000\n",
      "6/6 - 0s - loss: 36.8258 - val_loss: 366.4489\n",
      "Epoch 456/1000\n",
      "6/6 - 0s - loss: 36.7605 - val_loss: 364.1515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "6/6 - 0s - loss: 36.7199 - val_loss: 365.1140\n",
      "Epoch 458/1000\n",
      "6/6 - 0s - loss: 36.6032 - val_loss: 365.4896\n",
      "Epoch 459/1000\n",
      "6/6 - 0s - loss: 36.5288 - val_loss: 362.7649\n",
      "Epoch 460/1000\n",
      "6/6 - 0s - loss: 36.4359 - val_loss: 365.2953\n",
      "Epoch 461/1000\n",
      "6/6 - 0s - loss: 36.3882 - val_loss: 362.8704\n",
      "Epoch 462/1000\n",
      "6/6 - 0s - loss: 36.3065 - val_loss: 362.5165\n",
      "Epoch 463/1000\n",
      "6/6 - 0s - loss: 36.2456 - val_loss: 364.2705\n",
      "Epoch 464/1000\n",
      "6/6 - 0s - loss: 36.1926 - val_loss: 360.1162\n",
      "Epoch 465/1000\n",
      "6/6 - 0s - loss: 36.0640 - val_loss: 364.2599\n",
      "Epoch 466/1000\n",
      "6/6 - 0s - loss: 36.0005 - val_loss: 359.6137\n",
      "Epoch 467/1000\n",
      "6/6 - 0s - loss: 35.9536 - val_loss: 363.1787\n",
      "Epoch 468/1000\n",
      "6/6 - 0s - loss: 35.8496 - val_loss: 358.9374\n",
      "Epoch 469/1000\n",
      "6/6 - 0s - loss: 35.7080 - val_loss: 361.1078\n",
      "Epoch 470/1000\n",
      "6/6 - 0s - loss: 35.6454 - val_loss: 359.1718\n",
      "Epoch 471/1000\n",
      "6/6 - 0s - loss: 35.4978 - val_loss: 359.3982\n",
      "Epoch 00471: early stopping\n",
      "Score (MSE): 359.39821182877876\n",
      "Score(RMSE): 18.957800817309447\n",
      "\n",
      "Run  3\n",
      "Activation: Tanh\n",
      "Optimizer: Adam\n",
      "\n",
      "Epoch 1/1000\n",
      "6/6 - 0s - loss: 161.1001 - val_loss: 684.0082\n",
      "Epoch 2/1000\n",
      "6/6 - 0s - loss: 151.1160 - val_loss: 668.0916\n",
      "Epoch 3/1000\n",
      "6/6 - 0s - loss: 143.7462 - val_loss: 655.0040\n",
      "Epoch 4/1000\n",
      "6/6 - 0s - loss: 138.3931 - val_loss: 643.9540\n",
      "Epoch 5/1000\n",
      "6/6 - 0s - loss: 134.1513 - val_loss: 636.7288\n",
      "Epoch 6/1000\n",
      "6/6 - 0s - loss: 130.8796 - val_loss: 629.4088\n",
      "Epoch 7/1000\n",
      "6/6 - 0s - loss: 128.2981 - val_loss: 625.1192\n",
      "Epoch 8/1000\n",
      "6/6 - 0s - loss: 126.4465 - val_loss: 622.5284\n",
      "Epoch 9/1000\n",
      "6/6 - 0s - loss: 124.9413 - val_loss: 620.1035\n",
      "Epoch 10/1000\n",
      "6/6 - 0s - loss: 123.6846 - val_loss: 617.8648\n",
      "Epoch 11/1000\n",
      "6/6 - 0s - loss: 122.4917 - val_loss: 615.9694\n",
      "Epoch 12/1000\n",
      "6/6 - 0s - loss: 121.5517 - val_loss: 614.2198\n",
      "Epoch 13/1000\n",
      "6/6 - 0s - loss: 120.7309 - val_loss: 612.5304\n",
      "Epoch 14/1000\n",
      "6/6 - 0s - loss: 119.9832 - val_loss: 610.9822\n",
      "Epoch 15/1000\n",
      "6/6 - 0s - loss: 119.2134 - val_loss: 609.6118\n",
      "Epoch 16/1000\n",
      "6/6 - 0s - loss: 118.5632 - val_loss: 608.2934\n",
      "Epoch 17/1000\n",
      "6/6 - 0s - loss: 117.9034 - val_loss: 607.0449\n",
      "Epoch 18/1000\n",
      "6/6 - 0s - loss: 117.3058 - val_loss: 605.7708\n",
      "Epoch 19/1000\n",
      "6/6 - 0s - loss: 116.6536 - val_loss: 604.5432\n",
      "Epoch 20/1000\n",
      "6/6 - 0s - loss: 116.0347 - val_loss: 603.3135\n",
      "Epoch 21/1000\n",
      "6/6 - 0s - loss: 115.4508 - val_loss: 601.9724\n",
      "Epoch 22/1000\n",
      "6/6 - 0s - loss: 114.8039 - val_loss: 600.6949\n",
      "Epoch 23/1000\n",
      "6/6 - 0s - loss: 114.2256 - val_loss: 599.4691\n",
      "Epoch 24/1000\n",
      "6/6 - 0s - loss: 113.6709 - val_loss: 598.2596\n",
      "Epoch 25/1000\n",
      "6/6 - 0s - loss: 113.0294 - val_loss: 597.1528\n",
      "Epoch 26/1000\n",
      "6/6 - 0s - loss: 112.5281 - val_loss: 595.9753\n",
      "Epoch 27/1000\n",
      "6/6 - 0s - loss: 111.9532 - val_loss: 594.8635\n",
      "Epoch 28/1000\n",
      "6/6 - 0s - loss: 111.4182 - val_loss: 593.7545\n",
      "Epoch 29/1000\n",
      "6/6 - 0s - loss: 110.8940 - val_loss: 592.6475\n",
      "Epoch 30/1000\n",
      "6/6 - 0s - loss: 110.4240 - val_loss: 591.5262\n",
      "Epoch 31/1000\n",
      "6/6 - 0s - loss: 109.9086 - val_loss: 590.4617\n",
      "Epoch 32/1000\n",
      "6/6 - 0s - loss: 109.4357 - val_loss: 589.3967\n",
      "Epoch 33/1000\n",
      "6/6 - 0s - loss: 108.9540 - val_loss: 588.3247\n",
      "Epoch 34/1000\n",
      "6/6 - 0s - loss: 108.4919 - val_loss: 587.2515\n",
      "Epoch 35/1000\n",
      "6/6 - 0s - loss: 108.0366 - val_loss: 586.1882\n",
      "Epoch 36/1000\n",
      "6/6 - 0s - loss: 107.5529 - val_loss: 585.1895\n",
      "Epoch 37/1000\n",
      "6/6 - 0s - loss: 107.1092 - val_loss: 584.2073\n",
      "Epoch 38/1000\n",
      "6/6 - 0s - loss: 106.6713 - val_loss: 583.1531\n",
      "Epoch 39/1000\n",
      "6/6 - 0s - loss: 106.2132 - val_loss: 582.1006\n",
      "Epoch 40/1000\n",
      "6/6 - 0s - loss: 105.7734 - val_loss: 581.0353\n",
      "Epoch 41/1000\n",
      "6/6 - 0s - loss: 105.3015 - val_loss: 580.0115\n",
      "Epoch 42/1000\n",
      "6/6 - 0s - loss: 104.8934 - val_loss: 578.9804\n",
      "Epoch 43/1000\n",
      "6/6 - 0s - loss: 104.5148 - val_loss: 577.9596\n",
      "Epoch 44/1000\n",
      "6/6 - 0s - loss: 104.0675 - val_loss: 577.0405\n",
      "Epoch 45/1000\n",
      "6/6 - 0s - loss: 103.6858 - val_loss: 576.1260\n",
      "Epoch 46/1000\n",
      "6/6 - 0s - loss: 103.3060 - val_loss: 575.1880\n",
      "Epoch 47/1000\n",
      "6/6 - 0s - loss: 102.9248 - val_loss: 574.2695\n",
      "Epoch 48/1000\n",
      "6/6 - 0s - loss: 102.5314 - val_loss: 573.3979\n",
      "Epoch 49/1000\n",
      "6/6 - 0s - loss: 102.1668 - val_loss: 572.4929\n",
      "Epoch 50/1000\n",
      "6/6 - 0s - loss: 101.8046 - val_loss: 571.5991\n",
      "Epoch 51/1000\n",
      "6/6 - 0s - loss: 101.4499 - val_loss: 570.6804\n",
      "Epoch 52/1000\n",
      "6/6 - 0s - loss: 101.0753 - val_loss: 569.7227\n",
      "Epoch 53/1000\n",
      "6/6 - 0s - loss: 100.7034 - val_loss: 568.7862\n",
      "Epoch 54/1000\n",
      "6/6 - 0s - loss: 100.3146 - val_loss: 567.8825\n",
      "Epoch 55/1000\n",
      "6/6 - 0s - loss: 99.9726 - val_loss: 566.9711\n",
      "Epoch 56/1000\n",
      "6/6 - 0s - loss: 99.5990 - val_loss: 566.1035\n",
      "Epoch 57/1000\n",
      "6/6 - 0s - loss: 99.2599 - val_loss: 565.2303\n",
      "Epoch 58/1000\n",
      "6/6 - 0s - loss: 98.9417 - val_loss: 564.3011\n",
      "Epoch 59/1000\n",
      "6/6 - 0s - loss: 98.5616 - val_loss: 563.4391\n",
      "Epoch 60/1000\n",
      "6/6 - 0s - loss: 98.2343 - val_loss: 562.5322\n",
      "Epoch 61/1000\n",
      "6/6 - 0s - loss: 97.8765 - val_loss: 561.6661\n",
      "Epoch 62/1000\n",
      "6/6 - 0s - loss: 97.5097 - val_loss: 560.8325\n",
      "Epoch 63/1000\n",
      "6/6 - 0s - loss: 97.2053 - val_loss: 559.9330\n",
      "Epoch 64/1000\n",
      "6/6 - 0s - loss: 96.8538 - val_loss: 559.0608\n",
      "Epoch 65/1000\n",
      "6/6 - 0s - loss: 96.5170 - val_loss: 558.2286\n",
      "Epoch 66/1000\n",
      "6/6 - 0s - loss: 96.1937 - val_loss: 557.3906\n",
      "Epoch 67/1000\n",
      "6/6 - 0s - loss: 95.8748 - val_loss: 556.5626\n",
      "Epoch 68/1000\n",
      "6/6 - 0s - loss: 95.5574 - val_loss: 555.7226\n",
      "Epoch 69/1000\n",
      "6/6 - 0s - loss: 95.2114 - val_loss: 554.8771\n",
      "Epoch 70/1000\n",
      "6/6 - 0s - loss: 94.8809 - val_loss: 553.9863\n",
      "Epoch 71/1000\n",
      "6/6 - 0s - loss: 94.5675 - val_loss: 553.0759\n",
      "Epoch 72/1000\n",
      "6/6 - 0s - loss: 94.2593 - val_loss: 552.1921\n",
      "Epoch 73/1000\n",
      "6/6 - 0s - loss: 93.9019 - val_loss: 551.3845\n",
      "Epoch 74/1000\n",
      "6/6 - 0s - loss: 93.6220 - val_loss: 550.5704\n",
      "Epoch 75/1000\n",
      "6/6 - 0s - loss: 93.3121 - val_loss: 549.7754\n",
      "Epoch 76/1000\n",
      "6/6 - 0s - loss: 92.9918 - val_loss: 549.0117\n",
      "Epoch 77/1000\n",
      "6/6 - 0s - loss: 92.7116 - val_loss: 548.2217\n",
      "Epoch 78/1000\n",
      "6/6 - 0s - loss: 92.4188 - val_loss: 547.4265\n",
      "Epoch 79/1000\n",
      "6/6 - 0s - loss: 92.1068 - val_loss: 546.6523\n",
      "Epoch 80/1000\n",
      "6/6 - 0s - loss: 91.8157 - val_loss: 545.8638\n",
      "Epoch 81/1000\n",
      "6/6 - 0s - loss: 91.5273 - val_loss: 545.0987\n",
      "Epoch 82/1000\n",
      "6/6 - 0s - loss: 91.2297 - val_loss: 544.3563\n",
      "Epoch 83/1000\n",
      "6/6 - 0s - loss: 90.9592 - val_loss: 543.5380\n",
      "Epoch 84/1000\n",
      "6/6 - 0s - loss: 90.6577 - val_loss: 542.7636\n",
      "Epoch 85/1000\n",
      "6/6 - 0s - loss: 90.3924 - val_loss: 541.9547\n",
      "Epoch 86/1000\n",
      "6/6 - 0s - loss: 90.0826 - val_loss: 541.2083\n",
      "Epoch 87/1000\n",
      "6/6 - 0s - loss: 89.8120 - val_loss: 540.4425\n",
      "Epoch 88/1000\n",
      "6/6 - 0s - loss: 89.4978 - val_loss: 539.7490\n",
      "Epoch 89/1000\n",
      "6/6 - 0s - loss: 89.2499 - val_loss: 538.9525\n",
      "Epoch 90/1000\n",
      "6/6 - 0s - loss: 88.9838 - val_loss: 538.1968\n",
      "Epoch 91/1000\n",
      "6/6 - 0s - loss: 88.7095 - val_loss: 537.4894\n",
      "Epoch 92/1000\n",
      "6/6 - 0s - loss: 88.4544 - val_loss: 536.7714\n",
      "Epoch 93/1000\n",
      "6/6 - 0s - loss: 88.1932 - val_loss: 536.0493\n",
      "Epoch 94/1000\n",
      "6/6 - 0s - loss: 87.9259 - val_loss: 535.3320\n",
      "Epoch 95/1000\n",
      "6/6 - 0s - loss: 87.6557 - val_loss: 534.6363\n",
      "Epoch 96/1000\n",
      "6/6 - 0s - loss: 87.4080 - val_loss: 533.9119\n",
      "Epoch 97/1000\n",
      "6/6 - 0s - loss: 87.1713 - val_loss: 533.1794\n",
      "Epoch 98/1000\n",
      "6/6 - 0s - loss: 86.9185 - val_loss: 532.4710\n",
      "Epoch 99/1000\n",
      "6/6 - 0s - loss: 86.6557 - val_loss: 531.7527\n",
      "Epoch 100/1000\n",
      "6/6 - 0s - loss: 86.3956 - val_loss: 531.0616\n",
      "Epoch 101/1000\n",
      "6/6 - 0s - loss: 86.1372 - val_loss: 530.4527\n",
      "Epoch 102/1000\n",
      "6/6 - 0s - loss: 85.9124 - val_loss: 529.7939\n",
      "Epoch 103/1000\n",
      "6/6 - 0s - loss: 85.6817 - val_loss: 529.0853\n",
      "Epoch 104/1000\n",
      "6/6 - 0s - loss: 85.4091 - val_loss: 528.4070\n",
      "Epoch 105/1000\n",
      "6/6 - 0s - loss: 85.1990 - val_loss: 527.7018\n",
      "Epoch 106/1000\n",
      "6/6 - 0s - loss: 84.9329 - val_loss: 527.0014\n",
      "Epoch 107/1000\n",
      "6/6 - 0s - loss: 84.6963 - val_loss: 526.2877\n",
      "Epoch 108/1000\n",
      "6/6 - 0s - loss: 84.4478 - val_loss: 525.6109\n",
      "Epoch 109/1000\n",
      "6/6 - 0s - loss: 84.2277 - val_loss: 524.9052\n",
      "Epoch 110/1000\n",
      "6/6 - 0s - loss: 83.9373 - val_loss: 524.2739\n",
      "Epoch 111/1000\n",
      "6/6 - 0s - loss: 83.7737 - val_loss: 523.4763\n",
      "Epoch 112/1000\n",
      "6/6 - 0s - loss: 83.4691 - val_loss: 522.7927\n",
      "Epoch 113/1000\n",
      "6/6 - 0s - loss: 83.2303 - val_loss: 522.1353\n",
      "Epoch 114/1000\n",
      "6/6 - 0s - loss: 83.0017 - val_loss: 521.4691\n",
      "Epoch 115/1000\n",
      "6/6 - 0s - loss: 82.7987 - val_loss: 520.7828\n",
      "Epoch 116/1000\n",
      "6/6 - 0s - loss: 82.5683 - val_loss: 520.1091\n",
      "Epoch 117/1000\n",
      "6/6 - 0s - loss: 82.3287 - val_loss: 519.4284\n",
      "Epoch 118/1000\n",
      "6/6 - 0s - loss: 82.0802 - val_loss: 518.8095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/1000\n",
      "6/6 - 0s - loss: 81.8710 - val_loss: 518.1176\n",
      "Epoch 120/1000\n",
      "6/6 - 0s - loss: 81.6266 - val_loss: 517.3952\n",
      "Epoch 121/1000\n",
      "6/6 - 0s - loss: 81.4072 - val_loss: 516.6988\n",
      "Epoch 122/1000\n",
      "6/6 - 0s - loss: 81.1830 - val_loss: 515.9804\n",
      "Epoch 123/1000\n",
      "6/6 - 0s - loss: 80.9319 - val_loss: 515.3198\n",
      "Epoch 124/1000\n",
      "6/6 - 0s - loss: 80.6909 - val_loss: 514.6484\n",
      "Epoch 125/1000\n",
      "6/6 - 0s - loss: 80.4749 - val_loss: 514.0102\n",
      "Epoch 126/1000\n",
      "6/6 - 0s - loss: 80.2619 - val_loss: 513.2849\n",
      "Epoch 127/1000\n",
      "6/6 - 0s - loss: 80.0061 - val_loss: 512.6019\n",
      "Epoch 128/1000\n",
      "6/6 - 0s - loss: 79.7710 - val_loss: 511.9773\n",
      "Epoch 129/1000\n",
      "6/6 - 0s - loss: 79.6123 - val_loss: 511.2867\n",
      "Epoch 130/1000\n",
      "6/6 - 0s - loss: 79.3331 - val_loss: 510.6344\n",
      "Epoch 131/1000\n",
      "6/6 - 0s - loss: 79.1118 - val_loss: 510.0174\n",
      "Epoch 132/1000\n",
      "6/6 - 0s - loss: 78.9165 - val_loss: 509.3667\n",
      "Epoch 133/1000\n",
      "6/6 - 0s - loss: 78.6956 - val_loss: 508.6729\n",
      "Epoch 134/1000\n",
      "6/6 - 0s - loss: 78.4767 - val_loss: 508.0318\n",
      "Epoch 135/1000\n",
      "6/6 - 0s - loss: 78.2299 - val_loss: 507.4590\n",
      "Epoch 136/1000\n",
      "6/6 - 0s - loss: 78.0448 - val_loss: 506.7155\n",
      "Epoch 137/1000\n",
      "6/6 - 0s - loss: 77.8049 - val_loss: 506.0681\n",
      "Epoch 138/1000\n",
      "6/6 - 0s - loss: 77.5920 - val_loss: 505.3437\n",
      "Epoch 139/1000\n",
      "6/6 - 0s - loss: 77.3802 - val_loss: 504.6724\n",
      "Epoch 140/1000\n",
      "6/6 - 0s - loss: 77.1777 - val_loss: 503.9591\n",
      "Epoch 141/1000\n",
      "6/6 - 0s - loss: 76.9375 - val_loss: 503.3074\n",
      "Epoch 142/1000\n",
      "6/6 - 0s - loss: 76.7303 - val_loss: 502.6769\n",
      "Epoch 143/1000\n",
      "6/6 - 0s - loss: 76.5335 - val_loss: 502.0471\n",
      "Epoch 144/1000\n",
      "6/6 - 0s - loss: 76.3052 - val_loss: 501.4326\n",
      "Epoch 145/1000\n",
      "6/6 - 0s - loss: 76.1178 - val_loss: 500.7863\n",
      "Epoch 146/1000\n",
      "6/6 - 0s - loss: 75.8906 - val_loss: 500.1294\n",
      "Epoch 147/1000\n",
      "6/6 - 0s - loss: 75.6821 - val_loss: 499.4937\n",
      "Epoch 148/1000\n",
      "6/6 - 0s - loss: 75.4941 - val_loss: 498.7925\n",
      "Epoch 149/1000\n",
      "6/6 - 0s - loss: 75.2593 - val_loss: 498.2013\n",
      "Epoch 150/1000\n",
      "6/6 - 0s - loss: 75.0337 - val_loss: 497.5726\n",
      "Epoch 151/1000\n",
      "6/6 - 0s - loss: 74.8345 - val_loss: 496.8409\n",
      "Epoch 152/1000\n",
      "6/6 - 0s - loss: 74.6269 - val_loss: 496.2033\n",
      "Epoch 153/1000\n",
      "6/6 - 0s - loss: 74.4213 - val_loss: 495.5109\n",
      "Epoch 154/1000\n",
      "6/6 - 0s - loss: 74.2203 - val_loss: 494.9098\n",
      "Epoch 155/1000\n",
      "6/6 - 0s - loss: 73.9864 - val_loss: 494.3540\n",
      "Epoch 156/1000\n",
      "6/6 - 0s - loss: 73.8066 - val_loss: 493.7488\n",
      "Epoch 157/1000\n",
      "6/6 - 0s - loss: 73.6123 - val_loss: 493.1620\n",
      "Epoch 158/1000\n",
      "6/6 - 0s - loss: 73.4200 - val_loss: 492.4987\n",
      "Epoch 159/1000\n",
      "6/6 - 0s - loss: 73.2230 - val_loss: 491.8889\n",
      "Epoch 160/1000\n",
      "6/6 - 0s - loss: 73.0212 - val_loss: 491.2901\n",
      "Epoch 161/1000\n",
      "6/6 - 0s - loss: 72.8253 - val_loss: 490.6608\n",
      "Epoch 162/1000\n",
      "6/6 - 0s - loss: 72.6259 - val_loss: 490.1061\n",
      "Epoch 163/1000\n",
      "6/6 - 0s - loss: 72.4345 - val_loss: 489.3983\n",
      "Epoch 164/1000\n",
      "6/6 - 0s - loss: 72.2326 - val_loss: 488.8757\n",
      "Epoch 165/1000\n",
      "6/6 - 0s - loss: 72.0160 - val_loss: 488.2767\n",
      "Epoch 166/1000\n",
      "6/6 - 0s - loss: 71.8559 - val_loss: 487.6450\n",
      "Epoch 167/1000\n",
      "6/6 - 0s - loss: 71.6193 - val_loss: 487.0446\n",
      "Epoch 168/1000\n",
      "6/6 - 0s - loss: 71.4473 - val_loss: 486.3323\n",
      "Epoch 169/1000\n",
      "6/6 - 0s - loss: 71.2317 - val_loss: 485.7361\n",
      "Epoch 170/1000\n",
      "6/6 - 0s - loss: 71.0061 - val_loss: 485.1014\n",
      "Epoch 171/1000\n",
      "6/6 - 0s - loss: 70.8258 - val_loss: 484.5779\n",
      "Epoch 172/1000\n",
      "6/6 - 0s - loss: 70.6476 - val_loss: 483.9441\n",
      "Epoch 173/1000\n",
      "6/6 - 0s - loss: 70.4415 - val_loss: 483.3320\n",
      "Epoch 174/1000\n",
      "6/6 - 0s - loss: 70.2381 - val_loss: 482.7703\n",
      "Epoch 175/1000\n",
      "6/6 - 0s - loss: 70.0529 - val_loss: 482.0844\n",
      "Epoch 176/1000\n",
      "6/6 - 0s - loss: 69.8222 - val_loss: 481.5027\n",
      "Epoch 177/1000\n",
      "6/6 - 0s - loss: 69.6295 - val_loss: 480.8152\n",
      "Epoch 178/1000\n",
      "6/6 - 0s - loss: 69.4677 - val_loss: 480.1292\n",
      "Epoch 179/1000\n",
      "6/6 - 0s - loss: 69.2190 - val_loss: 479.4648\n",
      "Epoch 180/1000\n",
      "6/6 - 0s - loss: 69.0558 - val_loss: 478.9258\n",
      "Epoch 181/1000\n",
      "6/6 - 0s - loss: 68.8471 - val_loss: 478.3418\n",
      "Epoch 182/1000\n",
      "6/6 - 0s - loss: 68.6619 - val_loss: 477.7938\n",
      "Epoch 183/1000\n",
      "6/6 - 0s - loss: 68.4625 - val_loss: 477.1625\n",
      "Epoch 184/1000\n",
      "6/6 - 0s - loss: 68.2829 - val_loss: 476.4505\n",
      "Epoch 185/1000\n",
      "6/6 - 0s - loss: 68.0655 - val_loss: 475.9031\n",
      "Epoch 186/1000\n",
      "6/6 - 0s - loss: 67.8798 - val_loss: 475.2772\n",
      "Epoch 187/1000\n",
      "6/6 - 0s - loss: 67.6910 - val_loss: 474.7881\n",
      "Epoch 188/1000\n",
      "6/6 - 0s - loss: 67.5490 - val_loss: 474.2359\n",
      "Epoch 189/1000\n",
      "6/6 - 0s - loss: 67.3731 - val_loss: 473.6654\n",
      "Epoch 190/1000\n",
      "6/6 - 0s - loss: 67.2134 - val_loss: 473.1766\n",
      "Epoch 191/1000\n",
      "6/6 - 0s - loss: 67.0365 - val_loss: 472.6151\n",
      "Epoch 192/1000\n",
      "6/6 - 0s - loss: 66.8642 - val_loss: 472.2294\n",
      "Epoch 193/1000\n",
      "6/6 - 0s - loss: 66.7189 - val_loss: 471.5946\n",
      "Epoch 194/1000\n",
      "6/6 - 0s - loss: 66.5496 - val_loss: 471.0958\n",
      "Epoch 195/1000\n",
      "6/6 - 0s - loss: 66.3791 - val_loss: 470.4966\n",
      "Epoch 196/1000\n",
      "6/6 - 0s - loss: 66.1901 - val_loss: 470.0337\n",
      "Epoch 197/1000\n",
      "6/6 - 0s - loss: 66.0422 - val_loss: 469.4271\n",
      "Epoch 198/1000\n",
      "6/6 - 0s - loss: 65.9012 - val_loss: 468.8095\n",
      "Epoch 199/1000\n",
      "6/6 - 0s - loss: 65.7104 - val_loss: 468.3136\n",
      "Epoch 200/1000\n",
      "6/6 - 0s - loss: 65.5603 - val_loss: 467.7054\n",
      "Epoch 201/1000\n",
      "6/6 - 0s - loss: 65.4078 - val_loss: 467.1724\n",
      "Epoch 202/1000\n",
      "6/6 - 0s - loss: 65.2215 - val_loss: 466.6134\n",
      "Epoch 203/1000\n",
      "6/6 - 0s - loss: 65.0743 - val_loss: 466.0780\n",
      "Epoch 204/1000\n",
      "6/6 - 0s - loss: 64.9096 - val_loss: 465.4809\n",
      "Epoch 205/1000\n",
      "6/6 - 0s - loss: 64.7338 - val_loss: 464.8656\n",
      "Epoch 206/1000\n",
      "6/6 - 0s - loss: 64.5788 - val_loss: 464.2984\n",
      "Epoch 207/1000\n",
      "6/6 - 0s - loss: 64.3917 - val_loss: 463.8225\n",
      "Epoch 208/1000\n",
      "6/6 - 0s - loss: 64.2534 - val_loss: 463.2872\n",
      "Epoch 209/1000\n",
      "6/6 - 0s - loss: 64.0754 - val_loss: 462.7602\n",
      "Epoch 210/1000\n",
      "6/6 - 0s - loss: 63.9314 - val_loss: 462.2286\n",
      "Epoch 211/1000\n",
      "6/6 - 0s - loss: 63.7736 - val_loss: 461.6713\n",
      "Epoch 212/1000\n",
      "6/6 - 0s - loss: 63.6138 - val_loss: 461.1633\n",
      "Epoch 213/1000\n",
      "6/6 - 0s - loss: 63.4491 - val_loss: 460.5693\n",
      "Epoch 214/1000\n",
      "6/6 - 0s - loss: 63.2692 - val_loss: 460.2108\n",
      "Epoch 215/1000\n",
      "6/6 - 0s - loss: 63.1221 - val_loss: 459.5676\n",
      "Epoch 216/1000\n",
      "6/6 - 0s - loss: 62.9660 - val_loss: 459.0990\n",
      "Epoch 217/1000\n",
      "6/6 - 0s - loss: 62.8049 - val_loss: 458.4135\n",
      "Epoch 218/1000\n",
      "6/6 - 0s - loss: 62.6378 - val_loss: 458.0119\n",
      "Epoch 219/1000\n",
      "6/6 - 0s - loss: 62.4980 - val_loss: 457.3147\n",
      "Epoch 220/1000\n",
      "6/6 - 0s - loss: 62.3233 - val_loss: 456.9858\n",
      "Epoch 221/1000\n",
      "6/6 - 0s - loss: 62.1739 - val_loss: 456.2151\n",
      "Epoch 222/1000\n",
      "6/6 - 0s - loss: 62.0108 - val_loss: 456.0378\n",
      "Epoch 223/1000\n",
      "6/6 - 0s - loss: 61.8549 - val_loss: 455.2220\n",
      "Epoch 224/1000\n",
      "6/6 - 0s - loss: 61.7063 - val_loss: 455.0446\n",
      "Epoch 225/1000\n",
      "6/6 - 0s - loss: 61.5207 - val_loss: 454.0859\n",
      "Epoch 226/1000\n",
      "6/6 - 0s - loss: 61.3990 - val_loss: 454.0968\n",
      "Epoch 227/1000\n",
      "6/6 - 0s - loss: 61.2384 - val_loss: 453.0243\n",
      "Epoch 228/1000\n",
      "6/6 - 0s - loss: 61.0939 - val_loss: 453.2945\n",
      "Epoch 229/1000\n",
      "6/6 - 0s - loss: 60.9632 - val_loss: 452.1493\n",
      "Epoch 230/1000\n",
      "6/6 - 0s - loss: 60.8299 - val_loss: 452.3807\n",
      "Epoch 231/1000\n",
      "6/6 - 0s - loss: 60.6872 - val_loss: 451.0557\n",
      "Epoch 232/1000\n",
      "6/6 - 0s - loss: 60.5421 - val_loss: 451.4512\n",
      "Epoch 233/1000\n",
      "6/6 - 0s - loss: 60.4114 - val_loss: 450.2171\n",
      "Epoch 234/1000\n",
      "6/6 - 0s - loss: 60.2552 - val_loss: 450.4458\n",
      "Epoch 235/1000\n",
      "6/6 - 0s - loss: 60.1269 - val_loss: 449.2448\n",
      "Epoch 236/1000\n",
      "6/6 - 0s - loss: 59.9863 - val_loss: 449.2377\n",
      "Epoch 237/1000\n",
      "6/6 - 0s - loss: 59.8211 - val_loss: 448.4102\n",
      "Epoch 238/1000\n",
      "6/6 - 0s - loss: 59.6693 - val_loss: 448.0414\n",
      "Epoch 239/1000\n",
      "6/6 - 0s - loss: 59.5265 - val_loss: 447.4044\n",
      "Epoch 240/1000\n",
      "6/6 - 0s - loss: 59.3637 - val_loss: 446.8035\n",
      "Epoch 241/1000\n",
      "6/6 - 0s - loss: 59.2166 - val_loss: 446.6520\n",
      "Epoch 242/1000\n",
      "6/6 - 0s - loss: 59.0656 - val_loss: 445.5344\n",
      "Epoch 243/1000\n",
      "6/6 - 0s - loss: 58.9359 - val_loss: 445.6382\n",
      "Epoch 244/1000\n",
      "6/6 - 0s - loss: 58.7785 - val_loss: 444.5692\n",
      "Epoch 245/1000\n",
      "6/6 - 0s - loss: 58.6372 - val_loss: 444.5965\n",
      "Epoch 246/1000\n",
      "6/6 - 0s - loss: 58.4936 - val_loss: 443.4688\n",
      "Epoch 247/1000\n",
      "6/6 - 0s - loss: 58.3538 - val_loss: 443.3363\n",
      "Epoch 248/1000\n",
      "6/6 - 0s - loss: 58.1691 - val_loss: 442.6402\n",
      "Epoch 249/1000\n",
      "6/6 - 0s - loss: 58.0379 - val_loss: 442.3756\n",
      "Epoch 250/1000\n",
      "6/6 - 0s - loss: 57.9175 - val_loss: 441.8974\n",
      "Epoch 251/1000\n",
      "6/6 - 0s - loss: 57.8006 - val_loss: 441.3725\n",
      "Epoch 252/1000\n",
      "6/6 - 0s - loss: 57.6369 - val_loss: 441.0476\n",
      "Epoch 253/1000\n",
      "6/6 - 0s - loss: 57.5105 - val_loss: 440.4732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254/1000\n",
      "6/6 - 0s - loss: 57.3810 - val_loss: 440.1748\n",
      "Epoch 255/1000\n",
      "6/6 - 0s - loss: 57.2453 - val_loss: 439.5316\n",
      "Epoch 256/1000\n",
      "6/6 - 0s - loss: 57.1030 - val_loss: 439.3315\n",
      "Epoch 257/1000\n",
      "6/6 - 0s - loss: 56.9606 - val_loss: 438.5239\n",
      "Epoch 258/1000\n",
      "6/6 - 0s - loss: 56.8238 - val_loss: 438.3578\n",
      "Epoch 259/1000\n",
      "6/6 - 0s - loss: 56.7056 - val_loss: 437.5377\n",
      "Epoch 260/1000\n",
      "6/6 - 0s - loss: 56.5425 - val_loss: 437.4488\n",
      "Epoch 261/1000\n",
      "6/6 - 0s - loss: 56.4234 - val_loss: 436.6682\n",
      "Epoch 262/1000\n",
      "6/6 - 0s - loss: 56.2871 - val_loss: 436.4034\n",
      "Epoch 263/1000\n",
      "6/6 - 0s - loss: 56.1685 - val_loss: 435.6889\n",
      "Epoch 264/1000\n",
      "6/6 - 0s - loss: 56.0014 - val_loss: 435.4236\n",
      "Epoch 265/1000\n",
      "6/6 - 0s - loss: 55.8907 - val_loss: 434.7692\n",
      "Epoch 266/1000\n",
      "6/6 - 0s - loss: 55.7562 - val_loss: 434.4721\n",
      "Epoch 267/1000\n",
      "6/6 - 0s - loss: 55.6260 - val_loss: 433.6908\n",
      "Epoch 268/1000\n",
      "6/6 - 0s - loss: 55.5098 - val_loss: 433.4124\n",
      "Epoch 269/1000\n",
      "6/6 - 0s - loss: 55.3624 - val_loss: 432.8455\n",
      "Epoch 270/1000\n",
      "6/6 - 0s - loss: 55.2287 - val_loss: 432.5434\n",
      "Epoch 271/1000\n",
      "6/6 - 0s - loss: 55.1058 - val_loss: 431.9542\n",
      "Epoch 272/1000\n",
      "6/6 - 0s - loss: 54.9613 - val_loss: 431.6631\n",
      "Epoch 273/1000\n",
      "6/6 - 0s - loss: 54.8399 - val_loss: 430.9399\n",
      "Epoch 274/1000\n",
      "6/6 - 0s - loss: 54.6772 - val_loss: 430.7346\n",
      "Epoch 275/1000\n",
      "6/6 - 0s - loss: 54.5781 - val_loss: 429.9550\n",
      "Epoch 276/1000\n",
      "6/6 - 0s - loss: 54.4390 - val_loss: 429.8208\n",
      "Epoch 277/1000\n",
      "6/6 - 0s - loss: 54.3063 - val_loss: 428.9118\n",
      "Epoch 278/1000\n",
      "6/6 - 0s - loss: 54.1696 - val_loss: 428.9565\n",
      "Epoch 279/1000\n",
      "6/6 - 0s - loss: 54.0680 - val_loss: 427.9844\n",
      "Epoch 280/1000\n",
      "6/6 - 0s - loss: 53.9422 - val_loss: 428.1696\n",
      "Epoch 281/1000\n",
      "6/6 - 0s - loss: 53.8346 - val_loss: 426.8546\n",
      "Epoch 282/1000\n",
      "6/6 - 0s - loss: 53.7066 - val_loss: 427.1602\n",
      "Epoch 283/1000\n",
      "6/6 - 0s - loss: 53.5778 - val_loss: 425.8004\n",
      "Epoch 284/1000\n",
      "6/6 - 0s - loss: 53.4564 - val_loss: 426.1860\n",
      "Epoch 285/1000\n",
      "6/6 - 0s - loss: 53.3379 - val_loss: 424.7863\n",
      "Epoch 286/1000\n",
      "6/6 - 0s - loss: 53.2105 - val_loss: 425.4761\n",
      "Epoch 287/1000\n",
      "6/6 - 0s - loss: 53.1010 - val_loss: 423.7073\n",
      "Epoch 288/1000\n",
      "6/6 - 0s - loss: 52.9775 - val_loss: 424.7368\n",
      "Epoch 289/1000\n",
      "6/6 - 0s - loss: 52.8577 - val_loss: 422.6280\n",
      "Epoch 290/1000\n",
      "6/6 - 0s - loss: 52.7399 - val_loss: 423.7382\n",
      "Epoch 291/1000\n",
      "6/6 - 0s - loss: 52.6191 - val_loss: 421.6841\n",
      "Epoch 292/1000\n",
      "6/6 - 0s - loss: 52.5165 - val_loss: 422.9705\n",
      "Epoch 293/1000\n",
      "6/6 - 0s - loss: 52.4314 - val_loss: 420.7717\n",
      "Epoch 294/1000\n",
      "6/6 - 0s - loss: 52.2940 - val_loss: 421.8610\n",
      "Epoch 295/1000\n",
      "6/6 - 0s - loss: 52.2003 - val_loss: 420.2563\n",
      "Epoch 296/1000\n",
      "6/6 - 0s - loss: 52.0557 - val_loss: 420.6421\n",
      "Epoch 297/1000\n",
      "6/6 - 0s - loss: 51.9302 - val_loss: 419.8092\n",
      "Epoch 298/1000\n",
      "6/6 - 0s - loss: 51.8057 - val_loss: 419.2655\n",
      "Epoch 299/1000\n",
      "6/6 - 0s - loss: 51.6522 - val_loss: 419.3784\n",
      "Epoch 300/1000\n",
      "6/6 - 0s - loss: 51.5743 - val_loss: 418.4251\n",
      "Epoch 301/1000\n",
      "6/6 - 0s - loss: 51.4140 - val_loss: 418.4137\n",
      "Epoch 302/1000\n",
      "6/6 - 0s - loss: 51.2988 - val_loss: 417.4910\n",
      "Epoch 303/1000\n",
      "6/6 - 0s - loss: 51.1617 - val_loss: 417.6722\n",
      "Epoch 304/1000\n",
      "6/6 - 0s - loss: 51.0602 - val_loss: 416.7140\n",
      "Epoch 305/1000\n",
      "6/6 - 0s - loss: 50.9423 - val_loss: 416.7722\n",
      "Epoch 306/1000\n",
      "6/6 - 0s - loss: 50.8294 - val_loss: 415.8625\n",
      "Epoch 307/1000\n",
      "6/6 - 0s - loss: 50.7128 - val_loss: 415.9924\n",
      "Epoch 308/1000\n",
      "6/6 - 0s - loss: 50.6150 - val_loss: 415.2521\n",
      "Epoch 309/1000\n",
      "6/6 - 0s - loss: 50.4883 - val_loss: 415.1472\n",
      "Epoch 310/1000\n",
      "6/6 - 0s - loss: 50.3867 - val_loss: 414.5086\n",
      "Epoch 311/1000\n",
      "6/6 - 0s - loss: 50.2669 - val_loss: 414.2838\n",
      "Epoch 312/1000\n",
      "6/6 - 0s - loss: 50.1494 - val_loss: 413.8833\n",
      "Epoch 313/1000\n",
      "6/6 - 0s - loss: 50.0598 - val_loss: 413.3693\n",
      "Epoch 314/1000\n",
      "6/6 - 0s - loss: 49.9263 - val_loss: 412.9106\n",
      "Epoch 315/1000\n",
      "6/6 - 0s - loss: 49.8056 - val_loss: 412.4770\n",
      "Epoch 316/1000\n",
      "6/6 - 0s - loss: 49.6822 - val_loss: 412.0849\n",
      "Epoch 317/1000\n",
      "6/6 - 0s - loss: 49.5612 - val_loss: 411.5750\n",
      "Epoch 318/1000\n",
      "6/6 - 0s - loss: 49.4503 - val_loss: 411.2208\n",
      "Epoch 319/1000\n",
      "6/6 - 0s - loss: 49.3437 - val_loss: 410.7811\n",
      "Epoch 320/1000\n",
      "6/6 - 0s - loss: 49.2308 - val_loss: 410.2871\n",
      "Epoch 321/1000\n",
      "6/6 - 0s - loss: 49.1070 - val_loss: 409.8020\n",
      "Epoch 322/1000\n",
      "6/6 - 0s - loss: 48.9801 - val_loss: 409.3897\n",
      "Epoch 323/1000\n",
      "6/6 - 0s - loss: 48.8679 - val_loss: 408.9542\n",
      "Epoch 324/1000\n",
      "6/6 - 0s - loss: 48.7644 - val_loss: 408.4412\n",
      "Epoch 325/1000\n",
      "6/6 - 0s - loss: 48.6510 - val_loss: 408.0461\n",
      "Epoch 326/1000\n",
      "6/6 - 0s - loss: 48.5353 - val_loss: 407.4511\n",
      "Epoch 327/1000\n",
      "6/6 - 0s - loss: 48.4355 - val_loss: 407.1317\n",
      "Epoch 328/1000\n",
      "6/6 - 0s - loss: 48.3061 - val_loss: 406.6109\n",
      "Epoch 329/1000\n",
      "6/6 - 0s - loss: 48.2033 - val_loss: 406.2420\n",
      "Epoch 330/1000\n",
      "6/6 - 0s - loss: 48.0910 - val_loss: 405.7356\n",
      "Epoch 331/1000\n",
      "6/6 - 0s - loss: 47.9672 - val_loss: 405.5170\n",
      "Epoch 332/1000\n",
      "6/6 - 0s - loss: 47.8698 - val_loss: 404.9721\n",
      "Epoch 333/1000\n",
      "6/6 - 0s - loss: 47.7507 - val_loss: 404.7580\n",
      "Epoch 334/1000\n",
      "6/6 - 0s - loss: 47.6504 - val_loss: 404.1367\n",
      "Epoch 335/1000\n",
      "6/6 - 0s - loss: 47.5401 - val_loss: 403.9918\n",
      "Epoch 336/1000\n",
      "6/6 - 0s - loss: 47.4461 - val_loss: 403.3347\n",
      "Epoch 337/1000\n",
      "6/6 - 0s - loss: 47.3409 - val_loss: 403.2180\n",
      "Epoch 338/1000\n",
      "6/6 - 0s - loss: 47.2312 - val_loss: 402.4876\n",
      "Epoch 339/1000\n",
      "6/6 - 0s - loss: 47.1273 - val_loss: 402.4774\n",
      "Epoch 340/1000\n",
      "6/6 - 0s - loss: 47.0264 - val_loss: 401.6491\n",
      "Epoch 341/1000\n",
      "6/6 - 0s - loss: 46.9429 - val_loss: 401.7279\n",
      "Epoch 342/1000\n",
      "6/6 - 0s - loss: 46.8352 - val_loss: 400.6706\n",
      "Epoch 343/1000\n",
      "6/6 - 0s - loss: 46.7094 - val_loss: 400.8935\n",
      "Epoch 344/1000\n",
      "6/6 - 0s - loss: 46.6054 - val_loss: 399.6919\n",
      "Epoch 345/1000\n",
      "6/6 - 0s - loss: 46.4736 - val_loss: 400.0353\n",
      "Epoch 346/1000\n",
      "6/6 - 0s - loss: 46.3581 - val_loss: 399.0244\n",
      "Epoch 347/1000\n",
      "6/6 - 0s - loss: 46.2471 - val_loss: 399.4070\n",
      "Epoch 348/1000\n",
      "6/6 - 0s - loss: 46.1422 - val_loss: 398.2629\n",
      "Epoch 349/1000\n",
      "6/6 - 0s - loss: 46.0260 - val_loss: 398.7437\n",
      "Epoch 350/1000\n",
      "6/6 - 0s - loss: 45.9116 - val_loss: 397.3963\n",
      "Epoch 351/1000\n",
      "6/6 - 0s - loss: 45.8071 - val_loss: 398.0315\n",
      "Epoch 352/1000\n",
      "6/6 - 0s - loss: 45.6988 - val_loss: 396.7743\n",
      "Epoch 353/1000\n",
      "6/6 - 0s - loss: 45.6005 - val_loss: 397.2618\n",
      "Epoch 354/1000\n",
      "6/6 - 0s - loss: 45.4917 - val_loss: 395.9559\n",
      "Epoch 355/1000\n",
      "6/6 - 0s - loss: 45.3970 - val_loss: 396.7740\n",
      "Epoch 356/1000\n",
      "6/6 - 0s - loss: 45.2958 - val_loss: 395.0945\n",
      "Epoch 357/1000\n",
      "6/6 - 0s - loss: 45.1951 - val_loss: 395.9665\n",
      "Epoch 358/1000\n",
      "6/6 - 0s - loss: 45.0562 - val_loss: 394.2570\n",
      "Epoch 359/1000\n",
      "6/6 - 0s - loss: 44.9877 - val_loss: 395.1942\n",
      "Epoch 360/1000\n",
      "6/6 - 0s - loss: 44.8786 - val_loss: 393.3945\n",
      "Epoch 361/1000\n",
      "6/6 - 0s - loss: 44.7636 - val_loss: 394.4406\n",
      "Epoch 362/1000\n",
      "6/6 - 0s - loss: 44.6664 - val_loss: 392.7520\n",
      "Epoch 363/1000\n",
      "6/6 - 0s - loss: 44.5619 - val_loss: 393.6027\n",
      "Epoch 364/1000\n",
      "6/6 - 0s - loss: 44.5061 - val_loss: 392.0727\n",
      "Epoch 365/1000\n",
      "6/6 - 0s - loss: 44.3799 - val_loss: 392.9096\n",
      "Epoch 366/1000\n",
      "6/6 - 0s - loss: 44.3072 - val_loss: 391.1692\n",
      "Epoch 367/1000\n",
      "6/6 - 0s - loss: 44.1974 - val_loss: 392.2740\n",
      "Epoch 368/1000\n",
      "6/6 - 0s - loss: 44.1033 - val_loss: 390.3252\n",
      "Epoch 369/1000\n",
      "6/6 - 0s - loss: 44.0107 - val_loss: 391.9330\n",
      "Epoch 370/1000\n",
      "6/6 - 0s - loss: 43.9253 - val_loss: 389.3136\n",
      "Epoch 371/1000\n",
      "6/6 - 0s - loss: 43.8143 - val_loss: 390.9930\n",
      "Epoch 372/1000\n",
      "6/6 - 0s - loss: 43.7297 - val_loss: 388.6888\n",
      "Epoch 373/1000\n",
      "6/6 - 0s - loss: 43.6165 - val_loss: 390.1309\n",
      "Epoch 374/1000\n",
      "6/6 - 0s - loss: 43.5122 - val_loss: 387.9440\n",
      "Epoch 375/1000\n",
      "6/6 - 0s - loss: 43.3940 - val_loss: 389.4345\n",
      "Epoch 376/1000\n",
      "6/6 - 0s - loss: 43.3216 - val_loss: 386.9970\n",
      "Epoch 377/1000\n",
      "6/6 - 0s - loss: 43.2315 - val_loss: 388.5062\n",
      "Epoch 378/1000\n",
      "6/6 - 0s - loss: 43.1119 - val_loss: 386.0081\n",
      "Epoch 379/1000\n",
      "6/6 - 0s - loss: 43.0222 - val_loss: 387.9688\n",
      "Epoch 380/1000\n",
      "6/6 - 0s - loss: 42.9366 - val_loss: 385.4204\n",
      "Epoch 381/1000\n",
      "6/6 - 0s - loss: 42.8400 - val_loss: 387.1670\n",
      "Epoch 382/1000\n",
      "6/6 - 0s - loss: 42.7521 - val_loss: 384.4574\n",
      "Epoch 383/1000\n",
      "6/6 - 0s - loss: 42.6529 - val_loss: 386.4024\n",
      "Epoch 384/1000\n",
      "6/6 - 0s - loss: 42.5723 - val_loss: 383.7124\n",
      "Epoch 385/1000\n",
      "6/6 - 0s - loss: 42.4792 - val_loss: 385.3786\n",
      "Epoch 386/1000\n",
      "6/6 - 0s - loss: 42.3771 - val_loss: 382.8193\n",
      "Epoch 387/1000\n",
      "6/6 - 0s - loss: 42.2804 - val_loss: 384.4435\n",
      "Epoch 388/1000\n",
      "6/6 - 0s - loss: 42.1837 - val_loss: 382.3877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389/1000\n",
      "6/6 - 0s - loss: 42.0617 - val_loss: 383.4753\n",
      "Epoch 390/1000\n",
      "6/6 - 0s - loss: 41.9629 - val_loss: 381.7650\n",
      "Epoch 391/1000\n",
      "6/6 - 0s - loss: 41.8659 - val_loss: 382.6151\n",
      "Epoch 392/1000\n",
      "6/6 - 0s - loss: 41.7526 - val_loss: 381.4079\n",
      "Epoch 393/1000\n",
      "6/6 - 0s - loss: 41.6480 - val_loss: 381.8971\n",
      "Epoch 394/1000\n",
      "6/6 - 0s - loss: 41.5429 - val_loss: 380.8767\n",
      "Epoch 395/1000\n",
      "6/6 - 0s - loss: 41.4412 - val_loss: 380.9841\n",
      "Epoch 396/1000\n",
      "6/6 - 0s - loss: 41.3408 - val_loss: 380.3255\n",
      "Epoch 397/1000\n",
      "6/6 - 0s - loss: 41.2323 - val_loss: 380.1755\n",
      "Epoch 398/1000\n",
      "6/6 - 0s - loss: 41.1390 - val_loss: 379.6302\n",
      "Epoch 399/1000\n",
      "6/6 - 0s - loss: 41.0302 - val_loss: 379.3964\n",
      "Epoch 400/1000\n",
      "6/6 - 0s - loss: 40.9303 - val_loss: 378.8750\n",
      "Epoch 401/1000\n",
      "6/6 - 0s - loss: 40.8118 - val_loss: 378.6944\n",
      "Epoch 402/1000\n",
      "6/6 - 0s - loss: 40.7267 - val_loss: 378.1230\n",
      "Epoch 403/1000\n",
      "6/6 - 0s - loss: 40.6132 - val_loss: 377.9943\n",
      "Epoch 404/1000\n",
      "6/6 - 0s - loss: 40.5283 - val_loss: 377.4940\n",
      "Epoch 405/1000\n",
      "6/6 - 0s - loss: 40.4263 - val_loss: 377.3065\n",
      "Epoch 406/1000\n",
      "6/6 - 0s - loss: 40.3261 - val_loss: 376.8556\n",
      "Epoch 407/1000\n",
      "6/6 - 0s - loss: 40.2367 - val_loss: 376.6169\n",
      "Epoch 408/1000\n",
      "6/6 - 0s - loss: 40.1499 - val_loss: 376.1559\n",
      "Epoch 409/1000\n",
      "6/6 - 0s - loss: 40.0459 - val_loss: 375.9577\n",
      "Epoch 410/1000\n",
      "6/6 - 0s - loss: 39.9492 - val_loss: 375.4931\n",
      "Epoch 411/1000\n",
      "6/6 - 0s - loss: 39.8630 - val_loss: 375.2956\n",
      "Epoch 412/1000\n",
      "6/6 - 0s - loss: 39.7891 - val_loss: 374.7669\n",
      "Epoch 413/1000\n",
      "6/6 - 0s - loss: 39.6833 - val_loss: 374.6022\n",
      "Epoch 414/1000\n",
      "6/6 - 0s - loss: 39.5741 - val_loss: 374.1458\n",
      "Epoch 415/1000\n",
      "6/6 - 0s - loss: 39.4970 - val_loss: 373.9679\n",
      "Epoch 416/1000\n",
      "6/6 - 0s - loss: 39.3946 - val_loss: 373.4724\n",
      "Epoch 417/1000\n",
      "6/6 - 0s - loss: 39.3053 - val_loss: 373.3039\n",
      "Epoch 418/1000\n",
      "6/6 - 0s - loss: 39.2142 - val_loss: 372.8056\n",
      "Epoch 419/1000\n",
      "6/6 - 0s - loss: 39.1165 - val_loss: 372.6396\n",
      "Epoch 420/1000\n",
      "6/6 - 0s - loss: 39.0215 - val_loss: 372.1549\n",
      "Epoch 421/1000\n",
      "6/6 - 0s - loss: 38.9376 - val_loss: 371.9886\n",
      "Epoch 422/1000\n",
      "6/6 - 0s - loss: 38.8561 - val_loss: 371.4246\n",
      "Epoch 423/1000\n",
      "6/6 - 0s - loss: 38.7509 - val_loss: 371.2802\n",
      "Epoch 424/1000\n",
      "6/6 - 0s - loss: 38.6578 - val_loss: 370.8141\n",
      "Epoch 425/1000\n",
      "6/6 - 0s - loss: 38.5769 - val_loss: 370.7218\n",
      "Epoch 426/1000\n",
      "6/6 - 0s - loss: 38.4988 - val_loss: 370.1295\n",
      "Epoch 427/1000\n",
      "6/6 - 0s - loss: 38.3978 - val_loss: 370.1379\n",
      "Epoch 428/1000\n",
      "6/6 - 0s - loss: 38.3104 - val_loss: 369.5034\n",
      "Epoch 429/1000\n",
      "6/6 - 0s - loss: 38.2224 - val_loss: 369.4900\n",
      "Epoch 430/1000\n",
      "6/6 - 0s - loss: 38.1454 - val_loss: 368.8011\n",
      "Epoch 431/1000\n",
      "6/6 - 0s - loss: 38.0396 - val_loss: 368.8485\n",
      "Epoch 432/1000\n",
      "6/6 - 0s - loss: 37.9618 - val_loss: 368.0843\n",
      "Epoch 433/1000\n",
      "6/6 - 0s - loss: 37.8603 - val_loss: 368.1559\n",
      "Epoch 434/1000\n",
      "6/6 - 0s - loss: 37.7738 - val_loss: 367.3768\n",
      "Epoch 435/1000\n",
      "6/6 - 0s - loss: 37.6981 - val_loss: 367.4660\n",
      "Epoch 436/1000\n",
      "6/6 - 0s - loss: 37.6031 - val_loss: 366.6910\n",
      "Epoch 437/1000\n",
      "6/6 - 0s - loss: 37.5151 - val_loss: 366.8620\n",
      "Epoch 438/1000\n",
      "6/6 - 0s - loss: 37.4247 - val_loss: 365.8633\n",
      "Epoch 439/1000\n",
      "6/6 - 0s - loss: 37.3389 - val_loss: 366.2774\n",
      "Epoch 440/1000\n",
      "6/6 - 0s - loss: 37.2728 - val_loss: 365.3549\n",
      "Epoch 441/1000\n",
      "6/6 - 0s - loss: 37.1869 - val_loss: 365.6165\n",
      "Epoch 442/1000\n",
      "6/6 - 0s - loss: 37.0920 - val_loss: 364.6140\n",
      "Epoch 443/1000\n",
      "6/6 - 0s - loss: 37.0072 - val_loss: 365.0738\n",
      "Epoch 444/1000\n",
      "6/6 - 0s - loss: 36.9384 - val_loss: 364.2691\n",
      "Epoch 445/1000\n",
      "6/6 - 0s - loss: 36.8538 - val_loss: 364.3926\n",
      "Epoch 446/1000\n",
      "6/6 - 0s - loss: 36.7673 - val_loss: 363.8361\n",
      "Epoch 447/1000\n",
      "6/6 - 0s - loss: 36.6877 - val_loss: 363.8034\n",
      "Epoch 448/1000\n",
      "6/6 - 0s - loss: 36.6115 - val_loss: 363.1381\n",
      "Epoch 449/1000\n",
      "6/6 - 0s - loss: 36.5243 - val_loss: 363.1837\n",
      "Epoch 450/1000\n",
      "6/6 - 0s - loss: 36.4311 - val_loss: 362.6914\n",
      "Epoch 451/1000\n",
      "6/6 - 0s - loss: 36.3567 - val_loss: 362.4876\n",
      "Epoch 452/1000\n",
      "6/6 - 0s - loss: 36.2587 - val_loss: 362.1651\n",
      "Epoch 453/1000\n",
      "6/6 - 0s - loss: 36.1755 - val_loss: 361.7520\n",
      "Epoch 454/1000\n",
      "6/6 - 0s - loss: 36.0797 - val_loss: 361.5223\n",
      "Epoch 455/1000\n",
      "6/6 - 0s - loss: 35.9931 - val_loss: 361.2297\n",
      "Epoch 456/1000\n",
      "6/6 - 0s - loss: 35.9069 - val_loss: 360.8477\n",
      "Epoch 457/1000\n",
      "6/6 - 0s - loss: 35.8077 - val_loss: 360.6129\n",
      "Epoch 458/1000\n",
      "6/6 - 0s - loss: 35.7217 - val_loss: 360.1924\n",
      "Epoch 459/1000\n",
      "6/6 - 0s - loss: 35.6513 - val_loss: 359.9531\n",
      "Epoch 460/1000\n",
      "6/6 - 0s - loss: 35.5480 - val_loss: 359.6533\n",
      "Epoch 461/1000\n",
      "6/6 - 0s - loss: 35.4793 - val_loss: 359.3158\n",
      "Epoch 462/1000\n",
      "6/6 - 0s - loss: 35.3865 - val_loss: 359.0531\n",
      "Epoch 463/1000\n",
      "6/6 - 0s - loss: 35.3056 - val_loss: 358.7349\n",
      "Epoch 464/1000\n",
      "6/6 - 0s - loss: 35.2314 - val_loss: 358.4564\n",
      "Epoch 465/1000\n",
      "6/6 - 0s - loss: 35.1444 - val_loss: 358.2125\n",
      "Epoch 466/1000\n",
      "6/6 - 0s - loss: 35.0548 - val_loss: 357.8870\n",
      "Epoch 467/1000\n",
      "6/6 - 0s - loss: 34.9888 - val_loss: 357.6447\n",
      "Epoch 468/1000\n",
      "6/6 - 0s - loss: 34.8970 - val_loss: 357.2637\n",
      "Epoch 469/1000\n",
      "6/6 - 0s - loss: 34.8004 - val_loss: 356.9890\n",
      "Epoch 470/1000\n",
      "6/6 - 0s - loss: 34.7262 - val_loss: 356.6313\n",
      "Epoch 471/1000\n",
      "6/6 - 0s - loss: 34.6244 - val_loss: 356.3741\n",
      "Epoch 472/1000\n",
      "6/6 - 0s - loss: 34.5514 - val_loss: 356.0511\n",
      "Epoch 473/1000\n",
      "6/6 - 0s - loss: 34.4708 - val_loss: 355.8215\n",
      "Epoch 474/1000\n",
      "6/6 - 0s - loss: 34.4053 - val_loss: 355.4041\n",
      "Epoch 475/1000\n",
      "6/6 - 0s - loss: 34.3115 - val_loss: 355.2587\n",
      "Epoch 476/1000\n",
      "6/6 - 0s - loss: 34.2267 - val_loss: 354.8829\n",
      "Epoch 477/1000\n",
      "6/6 - 0s - loss: 34.1559 - val_loss: 354.5928\n",
      "Epoch 478/1000\n",
      "6/6 - 0s - loss: 34.0673 - val_loss: 354.4552\n",
      "Epoch 479/1000\n",
      "6/6 - 0s - loss: 34.0072 - val_loss: 353.8701\n",
      "Epoch 480/1000\n",
      "6/6 - 0s - loss: 33.9147 - val_loss: 353.8247\n",
      "Epoch 481/1000\n",
      "6/6 - 0s - loss: 33.8314 - val_loss: 353.3806\n",
      "Epoch 482/1000\n",
      "6/6 - 0s - loss: 33.7651 - val_loss: 352.9644\n",
      "Epoch 483/1000\n",
      "6/6 - 0s - loss: 33.6721 - val_loss: 352.8190\n",
      "Epoch 484/1000\n",
      "6/6 - 0s - loss: 33.5907 - val_loss: 352.3994\n",
      "Epoch 485/1000\n",
      "6/6 - 0s - loss: 33.5344 - val_loss: 351.9340\n",
      "Epoch 486/1000\n",
      "6/6 - 0s - loss: 33.4268 - val_loss: 351.6840\n",
      "Epoch 487/1000\n",
      "6/6 - 0s - loss: 33.3289 - val_loss: 351.2040\n",
      "Epoch 488/1000\n",
      "6/6 - 0s - loss: 33.2493 - val_loss: 351.0317\n",
      "Epoch 489/1000\n",
      "6/6 - 0s - loss: 33.1434 - val_loss: 350.5494\n",
      "Epoch 490/1000\n",
      "6/6 - 0s - loss: 33.0546 - val_loss: 350.5134\n",
      "Epoch 491/1000\n",
      "6/6 - 0s - loss: 32.9795 - val_loss: 349.9280\n",
      "Epoch 492/1000\n",
      "6/6 - 0s - loss: 32.8873 - val_loss: 349.7917\n",
      "Epoch 493/1000\n",
      "6/6 - 0s - loss: 32.8129 - val_loss: 349.5956\n",
      "Epoch 494/1000\n",
      "6/6 - 0s - loss: 32.7304 - val_loss: 349.2514\n",
      "Epoch 495/1000\n",
      "6/6 - 0s - loss: 32.6429 - val_loss: 349.0164\n",
      "Epoch 496/1000\n",
      "6/6 - 0s - loss: 32.5701 - val_loss: 348.8769\n",
      "Epoch 497/1000\n",
      "6/6 - 0s - loss: 32.4960 - val_loss: 348.5090\n",
      "Epoch 498/1000\n",
      "6/6 - 0s - loss: 32.4340 - val_loss: 348.1621\n",
      "Epoch 499/1000\n",
      "6/6 - 0s - loss: 32.3520 - val_loss: 348.2240\n",
      "Epoch 500/1000\n",
      "6/6 - 0s - loss: 32.2773 - val_loss: 347.7806\n",
      "Epoch 501/1000\n",
      "6/6 - 0s - loss: 32.2191 - val_loss: 347.5963\n",
      "Epoch 502/1000\n",
      "6/6 - 0s - loss: 32.1348 - val_loss: 347.3883\n",
      "Epoch 503/1000\n",
      "6/6 - 0s - loss: 32.0716 - val_loss: 347.0864\n",
      "Epoch 504/1000\n",
      "6/6 - 0s - loss: 31.9958 - val_loss: 346.9349\n",
      "Epoch 505/1000\n",
      "6/6 - 0s - loss: 31.9202 - val_loss: 346.5429\n",
      "Epoch 506/1000\n",
      "6/6 - 0s - loss: 31.8485 - val_loss: 346.4200\n",
      "Epoch 507/1000\n",
      "6/6 - 0s - loss: 31.7764 - val_loss: 346.1703\n",
      "Epoch 508/1000\n",
      "6/6 - 0s - loss: 31.7065 - val_loss: 345.9468\n",
      "Epoch 509/1000\n",
      "6/6 - 0s - loss: 31.6482 - val_loss: 345.4605\n",
      "Epoch 510/1000\n",
      "6/6 - 0s - loss: 31.5727 - val_loss: 345.6064\n",
      "Epoch 511/1000\n",
      "6/6 - 0s - loss: 31.4950 - val_loss: 345.3018\n",
      "Epoch 512/1000\n",
      "6/6 - 0s - loss: 31.4227 - val_loss: 344.6040\n",
      "Epoch 513/1000\n",
      "6/6 - 0s - loss: 31.3597 - val_loss: 345.0472\n",
      "Epoch 514/1000\n",
      "6/6 - 0s - loss: 31.2927 - val_loss: 344.3891\n",
      "Epoch 515/1000\n",
      "6/6 - 0s - loss: 31.2300 - val_loss: 344.0657\n",
      "Epoch 516/1000\n",
      "6/6 - 0s - loss: 31.1704 - val_loss: 344.5988\n",
      "Epoch 517/1000\n",
      "6/6 - 0s - loss: 31.0991 - val_loss: 343.4286\n",
      "Epoch 518/1000\n",
      "6/6 - 0s - loss: 31.0368 - val_loss: 343.1059\n",
      "Epoch 519/1000\n",
      "6/6 - 0s - loss: 30.9600 - val_loss: 344.2015\n",
      "Epoch 520/1000\n",
      "6/6 - 0s - loss: 30.9200 - val_loss: 341.8051\n",
      "Epoch 521/1000\n",
      "6/6 - 0s - loss: 30.8581 - val_loss: 342.7927\n",
      "Epoch 522/1000\n",
      "6/6 - 0s - loss: 30.8354 - val_loss: 344.3814\n",
      "Epoch 523/1000\n",
      "6/6 - 0s - loss: 30.7862 - val_loss: 339.9153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 524/1000\n",
      "6/6 - 0s - loss: 30.8424 - val_loss: 343.0297\n",
      "Epoch 525/1000\n",
      "6/6 - 0s - loss: 30.7228 - val_loss: 341.3410\n",
      "Epoch 526/1000\n",
      "6/6 - 0s - loss: 30.6332 - val_loss: 339.3778\n",
      "Epoch 527/1000\n",
      "6/6 - 0s - loss: 30.5574 - val_loss: 342.6246\n",
      "Epoch 528/1000\n",
      "6/6 - 0s - loss: 30.4861 - val_loss: 338.7022\n",
      "Epoch 529/1000\n",
      "6/6 - 0s - loss: 30.4278 - val_loss: 340.2429\n",
      "Epoch 530/1000\n",
      "6/6 - 0s - loss: 30.3225 - val_loss: 340.0227\n",
      "Epoch 531/1000\n",
      "6/6 - 0s - loss: 30.2379 - val_loss: 337.7647\n",
      "Epoch 532/1000\n",
      "6/6 - 0s - loss: 30.1697 - val_loss: 340.4486\n",
      "Epoch 533/1000\n",
      "6/6 - 0s - loss: 30.1021 - val_loss: 337.0526\n",
      "Epoch 534/1000\n",
      "6/6 - 0s - loss: 30.0350 - val_loss: 339.5278\n",
      "Epoch 535/1000\n",
      "6/6 - 0s - loss: 29.9362 - val_loss: 336.6404\n",
      "Epoch 536/1000\n",
      "6/6 - 0s - loss: 29.8555 - val_loss: 338.8051\n",
      "Epoch 537/1000\n",
      "6/6 - 0s - loss: 29.7979 - val_loss: 336.1462\n",
      "Epoch 538/1000\n",
      "6/6 - 0s - loss: 29.7283 - val_loss: 337.8380\n",
      "Epoch 539/1000\n",
      "6/6 - 0s - loss: 29.6579 - val_loss: 336.3480\n",
      "Epoch 540/1000\n",
      "6/6 - 0s - loss: 29.5650 - val_loss: 336.5483\n",
      "Epoch 00540: early stopping\n",
      "Score (MSE): 336.54833039216805\n",
      "Score(RMSE): 18.345253620273777\n"
     ]
    }
   ],
   "source": [
    "#Fully Connected Neural Network\n",
    "for i in range (3):\n",
    "    print(\"\\nRun \", i+1)\n",
    "    print(\"Activation: Tanh\")\n",
    "    print(\"Optimizer: Adam\\n\")\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(25, input_dim = x.shape[1], activation = 'tanh'))\n",
    "    model.add(Dense(10, activation = 'tanh'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "    monitor = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 3, verbose = 1, mode = 'auto')\n",
    "    model.fit(x_array_train, y_array_train, validation_data = (x_array_test, y_array_test), callbacks = [monitor], verbose = 2, epochs = 1000)\n",
    "\n",
    "    pred = model.predict(x_test)\n",
    "    score_mse = metrics.mean_squared_error(pred, y_test)\n",
    "    print(\"Score (MSE): {}\".format(score_mse))\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    score_rmse = np.sqrt(metrics.mean_squared_error(pred, y_test))\n",
    "    print(\"Score(RMSE): {}\".format(score_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1c3322f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chart_regression(pred.flatten(), y_test, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5a39f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>recommended</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>7.919253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.774385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>9.348271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>217</td>\n",
       "      <td>55</td>\n",
       "      <td>26.696650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>9.840070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>7.223465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>144</td>\n",
       "      <td>2</td>\n",
       "      <td>8.623423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>141</td>\n",
       "      <td>3</td>\n",
       "      <td>3.966254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>151</td>\n",
       "      <td>17</td>\n",
       "      <td>22.386215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>213</td>\n",
       "      <td>3</td>\n",
       "      <td>5.963391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>6.919714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.019911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.382558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.185403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>170</td>\n",
       "      <td>4</td>\n",
       "      <td>8.156186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>5.508265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>11.686196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94</td>\n",
       "      <td>10</td>\n",
       "      <td>16.453907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>149</td>\n",
       "      <td>36</td>\n",
       "      <td>26.708561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>98</td>\n",
       "      <td>26</td>\n",
       "      <td>25.788099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>135</td>\n",
       "      <td>127</td>\n",
       "      <td>26.730299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>6.302971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.993819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>3.225045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>7.058402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>26.719448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>8.444865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>9.735729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>97</td>\n",
       "      <td>11</td>\n",
       "      <td>12.069556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.562045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>1.955842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>69</td>\n",
       "      <td>5</td>\n",
       "      <td>17.664097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.883340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>10.746184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>95</td>\n",
       "      <td>26</td>\n",
       "      <td>22.290554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>4.806716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>2.334086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>146</td>\n",
       "      <td>5</td>\n",
       "      <td>11.705888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>15.753333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>26.609747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>127</td>\n",
       "      <td>6</td>\n",
       "      <td>9.039700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>139</td>\n",
       "      <td>4</td>\n",
       "      <td>7.062377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>13.415094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>4.403850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    app_id  recommended  Prediction\n",
       "0       73            0    7.919253\n",
       "1      202            1   -0.774385\n",
       "2       36            5    9.348271\n",
       "3      217           55   26.696650\n",
       "4       60            6    9.840070\n",
       "5      112            3    7.223465\n",
       "6      144            2    8.623423\n",
       "7      141            3    3.966254\n",
       "8      151           17   22.386215\n",
       "9      213            3    5.963391\n",
       "10     108            4    6.919714\n",
       "11     181            0   -0.019911\n",
       "12     165            1   -3.382558\n",
       "13     148            0   -3.185403\n",
       "14     170            4    8.156186\n",
       "15     115            0    5.508265\n",
       "16     120            4   11.686196\n",
       "17      94           10   16.453907\n",
       "18     149           36   26.708561\n",
       "19      98           26   25.788099\n",
       "20     135          127   26.730299\n",
       "21      46            5    6.302971\n",
       "22       3            0    5.993819\n",
       "23      22            3    3.225045\n",
       "24      33            5    7.058402\n",
       "25       2           72   26.719448\n",
       "26      53            5    8.444865\n",
       "27      14            1    9.735729\n",
       "28      97           11   12.069556\n",
       "29      16            0    0.562045\n",
       "30      41            3    1.955842\n",
       "31      69            5   17.664097\n",
       "32       0            1   -0.883340\n",
       "33      56            9   10.746184\n",
       "34      95           26   22.290554\n",
       "35      63            3    4.806716\n",
       "36     169            0    2.334086\n",
       "37     146            5   11.705888\n",
       "38     180            1   15.753333\n",
       "39      52           54   26.609747\n",
       "40     127            6    9.039700\n",
       "41     139            4    7.062377\n",
       "42      29            5   13.415094\n",
       "43      25            2    4.403850"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(pred, columns = ['Prediction'])\n",
    "df_x = pd.DataFrame(x_test).sort_index().reset_index()\n",
    "true_recommended = y_test.reset_index()\n",
    "\n",
    "result = pd.concat([df_x, true_recommended, predictions], axis = 1)\n",
    "show = result\n",
    "show = show.drop(show.loc[:, ~show.columns.isin(['index', 'recommended', 'Prediction'])], axis = 1)\n",
    "show.columns = ['index', 'app_id', 'recommended', 'Prediction']\n",
    "show = show.drop(['index'], axis = 1)\n",
    "show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762f0811",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b040aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(219, 3505)\n",
      "(219,)\n",
      "(175, 3505)\n",
      "(44, 3505)\n",
      "(175, 1, 3505, 1)\n",
      "(44, 1, 3505, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "x_train = x_train.reshape(x_train.shape[0],1, x_train.shape[1],1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, x_test.shape[1],1)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603ecc17",
   "metadata": {},
   "source": [
    "**Activation = Relu**<br>\n",
    "**Optimizer = Adam**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2c2727f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6/6 [==============================] - 1s 96ms/step - loss: 148.3600 - val_loss: 540.4648\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 116.3927 - val_loss: 585.1346\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 107.9687 - val_loss: 532.9860\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 100.4199 - val_loss: 561.6334\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 98.0259 - val_loss: 517.5493\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 91.8185 - val_loss: 534.3575\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 91.8106 - val_loss: 508.1587\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 73.7518 - val_loss: 459.0289\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 62.8715 - val_loss: 460.5863\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 53.2214 - val_loss: 454.9558\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 45.6417 - val_loss: 395.9661\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 35.6725 - val_loss: 445.4533\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 25.0039 - val_loss: 390.7680\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 15.5968 - val_loss: 402.8683\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 11.7115 - val_loss: 360.1360\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 8.9396 - val_loss: 423.3240\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 4.8248 - val_loss: 377.4633\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 3.4510 - val_loss: 407.9868\n",
      "Epoch 00018: early stopping\n",
      "Score (MSE): 407.9868398549552\n",
      "Score(RMSE): 20.198684111965193\n"
     ]
    }
   ],
   "source": [
    "cnn = Sequential()\n",
    "\n",
    "cnn.add(Conv2D(16, kernel_size=(1, 3), strides=(1, 1), activation='relu', input_shape=(1, x_train.shape[2],1)))\n",
    "cnn.add(MaxPooling2D(pool_size=(1,2)))\n",
    "cnn.add(Conv2D(32, kernel_size=(1, 3), strides=(1, 1), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(1,2))) \n",
    "cnn.add(Conv2D(64, kernel_size=(1, 3), strides=(1, 1), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(1,2))) \n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(500, activation=\"relu\"))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(1))\n",
    "\n",
    "cnn.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "monitor = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 3, verbose = 1, mode = 'auto')\n",
    "cnn.fit(x_train, y_train,epochs = 1000, validation_data = (x_test, y_test), callbacks = [monitor])\n",
    "\n",
    "\n",
    "pred = cnn.predict(x_test)\n",
    "score_mse = metrics.mean_squared_error(pred, y_test)\n",
    "print(\"Score (MSE): {}\".format(score_mse))\n",
    "    \n",
    "pred = cnn.predict(x_test)\n",
    "score_rmse = np.sqrt(metrics.mean_squared_error(pred, y_test))\n",
    "print(\"Score(RMSE): {}\".format(score_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0e84329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chart_regression(pred.flatten(), y_test, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a06503f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>recommended</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.034826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.773683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>217.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>15.549053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.291526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>112.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.181770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>144.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.136844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>141.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.112465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>151.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.386092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>213.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.314644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>108.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.989813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.547285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>165.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.458561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>170.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.017376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.270311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>120.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.288650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.901091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>149.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>20.975763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>98.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.936842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>135.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>14.883229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>46.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.399611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.713737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.275032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>33.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.299699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>34.372524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>53.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.779623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.172594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>97.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.316595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>41.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.030513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>69.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.473499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.493385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>56.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.648546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>95.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.489280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>63.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.066384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.469926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>146.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.399676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.848299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>52.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>19.261412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>127.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.581464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>139.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.237542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.582266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.497646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    app_id  recommended  Prediction\n",
       "0     73.0          0.0    0.203737\n",
       "1    202.0          1.0    0.034826\n",
       "2     36.0          5.0    2.773683\n",
       "3    217.0         55.0   15.549053\n",
       "4     60.0          6.0    3.291526\n",
       "5    112.0          3.0    3.181770\n",
       "6    144.0          2.0    6.136844\n",
       "7    141.0          3.0   11.112465\n",
       "8    151.0         17.0   13.386092\n",
       "9    213.0          3.0    8.314644\n",
       "10   108.0          4.0    7.989813\n",
       "11   181.0          0.0    1.547285\n",
       "12   165.0          1.0    2.458561\n",
       "13   148.0          0.0    0.160739\n",
       "14   170.0          4.0   12.017376\n",
       "15   115.0          0.0    7.270311\n",
       "16   120.0          4.0    2.288650\n",
       "17    94.0         10.0    2.901091\n",
       "18   149.0         36.0   20.975763\n",
       "19    98.0         26.0   27.936842\n",
       "20   135.0        127.0   14.883229\n",
       "21    46.0          5.0   18.399611\n",
       "22     3.0          0.0    1.713737\n",
       "23    22.0          3.0    1.275032\n",
       "24    33.0          5.0    5.299699\n",
       "25     2.0         72.0   34.372524\n",
       "26    53.0          5.0    3.779623\n",
       "27    14.0          1.0   11.172594\n",
       "28    97.0         11.0   15.316595\n",
       "29    16.0          0.0    0.496045\n",
       "30    41.0          3.0    0.030513\n",
       "31    69.0          5.0   10.473499\n",
       "32     0.0          1.0    0.493385\n",
       "33    56.0          9.0   12.648546\n",
       "34    95.0         26.0   10.489280\n",
       "35    63.0          3.0    0.066384\n",
       "36   169.0          0.0    2.469926\n",
       "37   146.0          5.0    5.399676\n",
       "38   180.0          1.0    1.848299\n",
       "39    52.0         54.0   19.261412\n",
       "40   127.0          6.0    6.581464\n",
       "41   139.0          4.0    0.237542\n",
       "42    29.0          5.0    1.582266\n",
       "43    25.0          2.0    1.497646"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(pred, columns = ['Prediction'])\n",
    "df_x = pd.DataFrame(x_test.flatten()).sort_index().reset_index()\n",
    "true_recommended = y_test.reset_index()\n",
    "\n",
    "result = pd.concat([df_x, true_recommended, predictions], axis = 1)\n",
    "show = result\n",
    "show = show.drop(show.loc[:, ~show.columns.isin(['index', 'recommended', 'Prediction'])], axis = 1)\n",
    "show.columns = ['index', 'app_id', 'recommended', 'Prediction']\n",
    "show = show.drop(['index'], axis = 1)\n",
    "show = show.dropna()\n",
    "show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db0a6a",
   "metadata": {},
   "source": [
    "**Activation = Sigmoid**<br>\n",
    "**Optimizer = Adam**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fce7691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6/6 [==============================] - 1s 96ms/step - loss: 150.9865 - val_loss: 555.3881\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 131.7059 - val_loss: 558.2314\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 124.3390 - val_loss: 563.2990\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 118.7777 - val_loss: 569.5635\n",
      "Epoch 00004: early stopping\n",
      "Score (MSE): 569.5635304360013\n",
      "Score(RMSE): 23.865530172950304\n"
     ]
    }
   ],
   "source": [
    "cnn = Sequential()\n",
    "\n",
    "cnn.add(Conv2D(16, kernel_size=(1, 3), strides=(1, 1), activation='sigmoid', input_shape=(1, x_train.shape[2],1)))\n",
    "cnn.add(MaxPooling2D(pool_size=(1,2)))\n",
    "cnn.add(Conv2D(32, kernel_size=(1, 3), strides=(1, 1), activation='sigmoid'))\n",
    "cnn.add(MaxPooling2D(pool_size=(1,2))) \n",
    "cnn.add(Conv2D(64, kernel_size=(1, 3), strides=(1, 1), activation='sigmoid'))\n",
    "cnn.add(MaxPooling2D(pool_size=(1,2))) \n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(500, activation='sigmoid'))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(1))\n",
    "\n",
    "cnn.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "monitor = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 3, verbose = 1, mode = 'auto')\n",
    "cnn.fit(x_train, y_train,epochs = 1000, validation_data = (x_test, y_test), callbacks = [monitor])\n",
    "\n",
    "\n",
    "pred = cnn.predict(x_test)\n",
    "score_mse = metrics.mean_squared_error(pred, y_test)\n",
    "print(\"Score (MSE): {}\".format(score_mse))\n",
    "    \n",
    "pred = cnn.predict(x_test)\n",
    "score_rmse = np.sqrt(metrics.mean_squared_error(pred, y_test))\n",
    "print(\"Score(RMSE): {}\".format(score_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d491c0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chart_regression(pred.flatten(), y_test, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa60f7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>recommended</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>217.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>112.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>144.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>141.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>151.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>213.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>108.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>165.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>170.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>120.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>149.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>98.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>135.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>46.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>33.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>53.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>97.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>41.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>69.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>56.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>95.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>63.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>146.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>52.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>127.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>139.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.280872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    app_id  recommended  Prediction\n",
       "0     73.0          0.0    8.280872\n",
       "1    202.0          1.0    8.280872\n",
       "2     36.0          5.0    8.280872\n",
       "3    217.0         55.0    8.280872\n",
       "4     60.0          6.0    8.280872\n",
       "5    112.0          3.0    8.280872\n",
       "6    144.0          2.0    8.280872\n",
       "7    141.0          3.0    8.280872\n",
       "8    151.0         17.0    8.280872\n",
       "9    213.0          3.0    8.280872\n",
       "10   108.0          4.0    8.280872\n",
       "11   181.0          0.0    8.280872\n",
       "12   165.0          1.0    8.280872\n",
       "13   148.0          0.0    8.280872\n",
       "14   170.0          4.0    8.280872\n",
       "15   115.0          0.0    8.280872\n",
       "16   120.0          4.0    8.280872\n",
       "17    94.0         10.0    8.280872\n",
       "18   149.0         36.0    8.280872\n",
       "19    98.0         26.0    8.280872\n",
       "20   135.0        127.0    8.280872\n",
       "21    46.0          5.0    8.280872\n",
       "22     3.0          0.0    8.280872\n",
       "23    22.0          3.0    8.280872\n",
       "24    33.0          5.0    8.280872\n",
       "25     2.0         72.0    8.280872\n",
       "26    53.0          5.0    8.280872\n",
       "27    14.0          1.0    8.280872\n",
       "28    97.0         11.0    8.280872\n",
       "29    16.0          0.0    8.280872\n",
       "30    41.0          3.0    8.280872\n",
       "31    69.0          5.0    8.280872\n",
       "32     0.0          1.0    8.280872\n",
       "33    56.0          9.0    8.280872\n",
       "34    95.0         26.0    8.280872\n",
       "35    63.0          3.0    8.280872\n",
       "36   169.0          0.0    8.280872\n",
       "37   146.0          5.0    8.280872\n",
       "38   180.0          1.0    8.280872\n",
       "39    52.0         54.0    8.280872\n",
       "40   127.0          6.0    8.280872\n",
       "41   139.0          4.0    8.280872\n",
       "42    29.0          5.0    8.280872\n",
       "43    25.0          2.0    8.280872"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(pred, columns = ['Prediction'])\n",
    "df_x = pd.DataFrame(x_test.flatten()).sort_index().reset_index()\n",
    "true_recommended = y_test.reset_index()\n",
    "\n",
    "result = pd.concat([df_x, true_recommended, predictions], axis = 1)\n",
    "show = result\n",
    "show = show.drop(show.loc[:, ~show.columns.isin(['index', 'recommended', 'Prediction'])], axis = 1)\n",
    "show.columns = ['index', 'app_id', 'recommended', 'Prediction']\n",
    "show = show.drop(['index'], axis = 1)\n",
    "show = show.dropna()\n",
    "show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc94b4a4",
   "metadata": {},
   "source": [
    "**Activation = Tanh**<br>\n",
    "**Optimizer = Adam**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b001d8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 141.1484 - val_loss: 551.9664\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 111.1650 - val_loss: 534.5278\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 93.5252 - val_loss: 548.8591\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 87.2059 - val_loss: 491.2534\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 73.9224 - val_loss: 534.6770\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 75.3614 - val_loss: 444.9722\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 65.3345 - val_loss: 488.8123\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 51.5574 - val_loss: 442.1779\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 44.6825 - val_loss: 453.0862\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 39.3688 - val_loss: 417.2306\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 33.4451 - val_loss: 428.4719\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 28.7092 - val_loss: 418.5048\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 23.2389 - val_loss: 424.1988\n",
      "Epoch 00013: early stopping\n",
      "Score (MSE): 424.1987875068475\n",
      "Score(RMSE): 20.596086703712615\n"
     ]
    }
   ],
   "source": [
    "cnn = Sequential()\n",
    "\n",
    "cnn.add(Conv2D(16, kernel_size=(1, 3), strides=(1, 1), activation='tanh', input_shape=(1, x_train.shape[2],1)))\n",
    "cnn.add(MaxPooling2D(pool_size=(1,2)))\n",
    "cnn.add(Conv2D(32, kernel_size=(1, 3), strides=(1, 1), activation='tanh'))\n",
    "cnn.add(MaxPooling2D(pool_size=(1,2))) \n",
    "cnn.add(Conv2D(64, kernel_size=(1, 3), strides=(1, 1), activation='tanh'))\n",
    "cnn.add(MaxPooling2D(pool_size=(1,2))) \n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(500, activation='tanh'))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(1))\n",
    "\n",
    "cnn.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "monitor = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 3, verbose = 1, mode = 'auto')\n",
    "cnn.fit(x_train, y_train,epochs = 1000, validation_data = (x_test, y_test), callbacks = [monitor])\n",
    "\n",
    "\n",
    "pred = cnn.predict(x_test)\n",
    "score_mse = metrics.mean_squared_error(pred, y_test)\n",
    "print(\"Score (MSE): {}\".format(score_mse))\n",
    "    \n",
    "pred = cnn.predict(x_test)\n",
    "score_rmse = np.sqrt(metrics.mean_squared_error(pred, y_test))\n",
    "print(\"Score(RMSE): {}\".format(score_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c52579e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chart_regression(pred.flatten(), y_test, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ee7b41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>recommended</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.643751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.407143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.049886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>217.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>20.047983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.016015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>112.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.602962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>144.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.023526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>141.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.254622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>151.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.790262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>213.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.522188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>108.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.394448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.208730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>165.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.024344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.638425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>170.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.116130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.279056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>120.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.276124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.971521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>149.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.104349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>98.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22.756342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>135.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>16.316744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>46.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.700112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.990887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.556046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>33.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.579461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>25.271418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>53.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.968672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.044744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>97.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.237938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.464204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>41.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.032222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>69.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.786455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.549083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>56.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.852057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>95.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>14.135966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>63.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-4.139933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.738732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>146.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.282112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.342755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>52.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>18.853153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>127.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.837361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>139.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.596471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.615990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.331227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    app_id  recommended  Prediction\n",
       "0     73.0          0.0   -6.643751\n",
       "1    202.0          1.0   -7.407143\n",
       "2     36.0          5.0    7.049886\n",
       "3    217.0         55.0   20.047983\n",
       "4     60.0          6.0    6.016015\n",
       "5    112.0          3.0    5.602962\n",
       "6    144.0          2.0    9.023526\n",
       "7    141.0          3.0   14.254622\n",
       "8    151.0         17.0   15.790262\n",
       "9    213.0          3.0   10.522188\n",
       "10   108.0          4.0   10.394448\n",
       "11   181.0          0.0    1.208730\n",
       "12   165.0          1.0   -0.024344\n",
       "13   148.0          0.0   -1.638425\n",
       "14   170.0          4.0   12.116130\n",
       "15   115.0          0.0   10.279056\n",
       "16   120.0          4.0    5.276124\n",
       "17    94.0         10.0    4.971521\n",
       "18   149.0         36.0   22.104349\n",
       "19    98.0         26.0   22.756342\n",
       "20   135.0        127.0   16.316744\n",
       "21    46.0          5.0   13.700112\n",
       "22     3.0          0.0   -0.990887\n",
       "23    22.0          3.0   -0.556046\n",
       "24    33.0          5.0    4.579461\n",
       "25     2.0         72.0   25.271418\n",
       "26    53.0          5.0    5.968672\n",
       "27    14.0          1.0   14.044744\n",
       "28    97.0         11.0   13.237938\n",
       "29    16.0          0.0   -0.464204\n",
       "30    41.0          3.0   -9.032222\n",
       "31    69.0          5.0   16.786455\n",
       "32     0.0          1.0    0.549083\n",
       "33    56.0          9.0   16.852057\n",
       "34    95.0         26.0   14.135966\n",
       "35    63.0          3.0   -4.139933\n",
       "36   169.0          0.0    1.738732\n",
       "37   146.0          5.0   10.282112\n",
       "38   180.0          1.0    3.342755\n",
       "39    52.0         54.0   18.853153\n",
       "40   127.0          6.0    9.837361\n",
       "41   139.0          4.0   -5.596471\n",
       "42    29.0          5.0    5.615990\n",
       "43    25.0          2.0    6.331227"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(pred, columns = ['Prediction'])\n",
    "df_x = pd.DataFrame(x_test.flatten()).sort_index().reset_index()\n",
    "true_recommended = y_test.reset_index()\n",
    "\n",
    "result = pd.concat([df_x, true_recommended, predictions], axis = 1)\n",
    "show = result\n",
    "show = show.drop(show.loc[:, ~show.columns.isin(['index', 'recommended', 'Prediction'])], axis = 1)\n",
    "show.columns = ['index', 'app_id', 'recommended', 'Prediction']\n",
    "show = show.drop(['index'], axis = 1)\n",
    "show = show.dropna()\n",
    "show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6c0888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
